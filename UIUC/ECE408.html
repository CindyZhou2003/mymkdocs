
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="CindyÁöÑÁ¨îËÆ∞Êú¨">
      
      
      
        <link rel="canonical" href="https://cindyzhou2003.github.io/mymkdocs/UIUC/ECE408.html">
      
      
        <link rel="prev" href="../ZJU/%E4%B9%A0%E6%A6%82.html">
      
      
        <link rel="next" href="ECE448.html">
      
      
        
      
      
      <link rel="icon" href="../assets/images/favcion.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>ECE408/CS483 Applied Parallel Programming - CindyÁöÑÁ¨îËÆ∞Êú¨</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=LXGW+WenKai:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"LXGW WenKai";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css">
    
      <link rel="stylesheet" href="../css/extra.css">
    
      <link rel="stylesheet" href="../css/neoteroi-mkdocs.css">
    
      <link rel="stylesheet" href="../css/style.css">
    
      <link rel="stylesheet" href="../css/font.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="forest" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ece408cs483-applied-parallel-programming" class="md-skip">
          Ë∑≥ËΩ¨Ëá≥
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="È°µÁúâ">
    <a href=".." title="CindyÁöÑÁ¨îËÆ∞Êú¨" class="md-header__button md-logo" aria-label="CindyÁöÑÁ¨îËÆ∞Êú¨" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M384 512H96c-53 0-96-43-96-96V96C0 43 43 0 96 0h304c26.5 0 48 21.5 48 48v288c0 20.9-13.4 38.7-32 45.3V448c17.7 0 32 14.3 32 32s-14.3 32-32 32zM96 384c-17.7 0-32 14.3-32 32s14.3 32 32 32h256v-64zm32-232c0 13.3 10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24H152c-13.3 0-24 10.7-24 24m24 72c-13.3 0-24 10.7-24 24s10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CindyÁöÑÁ¨îËÆ∞Êú¨
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ECE408/CS483 Applied Parallel Programming
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="forest" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="forest-dark" data-md-color-primary="Brown" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="ÊêúÁ¥¢" placeholder="ÊêúÁ¥¢" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Êü•Êâæ">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="ÂàÜ‰∫´" aria-label="ÂàÜ‰∫´" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Ê∏ÖÁ©∫ÂΩìÂâçÂÜÖÂÆπ" aria-label="Ê∏ÖÁ©∫ÂΩìÂâçÂÜÖÂÆπ" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Ê≠£Âú®ÂàùÂßãÂåñÊêúÁ¥¢ÂºïÊìé
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/CindyZhou2003/mymkdocs" title="ÂâçÂæÄ‰ªìÂ∫ì" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Cindy's notebook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Ê†áÁ≠æ" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../index.html" class="md-tabs__link">
          
  
  
    
  
  ‰∏ªÈ°µü§ñ

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../ZJU/DM.html" class="md-tabs__link">
          
  
  
    
  
  ZJU-SEËØæÁ®ãüìù

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="ECE408.html" class="md-tabs__link">
          
  
  
    
  
  UIUC-MEng coursesüìö

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../skills/Algorithm.html" class="md-tabs__link">
          
  
  
    
  
  ÊäÄËÉΩ‚öôÔ∏è

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../abroad/IELTs_speaking1.html" class="md-tabs__link">
          
  
  
    
  
  Âá∫ÂõΩ‚úàÔ∏è

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../work/Interview.html" class="md-tabs__link">
          
  
  
    
  
  ÊâæÂ∑•

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../other/test.html" class="md-tabs__link">
          
  
  
    
  
  ÂÖ∂‰ªñüéä

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="ÂØºËà™Ê†è" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="CindyÁöÑÁ¨îËÆ∞Êú¨" class="md-nav__button md-logo" aria-label="CindyÁöÑÁ¨îËÆ∞Êú¨" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M384 512H96c-53 0-96-43-96-96V96C0 43 43 0 96 0h304c26.5 0 48 21.5 48 48v288c0 20.9-13.4 38.7-32 45.3V448c17.7 0 32 14.3 32 32s-14.3 32-32 32zM96 384c-17.7 0-32 14.3-32 32s14.3 32 32 32h256v-64zm32-232c0 13.3 10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24H152c-13.3 0-24 10.7-24 24m24 72c-13.3 0-24 10.7-24 24s10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24z"/></svg>

    </a>
    CindyÁöÑÁ¨îËÆ∞Êú¨
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/CindyZhou2003/mymkdocs" title="ÂâçÂæÄ‰ªìÂ∫ì" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Cindy's notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    ‰∏ªÈ°µü§ñ
  

    
  </span>
  
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    ‰∏ªÈ°µü§ñ
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ZJU-SEËØæÁ®ãüìù
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    ZJU-SEËØæÁ®ãüìù
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Â§ß‰∏ÄÊò•Â§è
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Â§ß‰∏ÄÊò•Â§è
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/DM.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Á¶ªÊï£Êï∞Â≠¶ÂèäÂÖ∂Â∫îÁî®
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Â§ß‰∫åÁßãÂÜ¨
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Â§ß‰∫åÁßãÂÜ¨
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/OOP.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Èù¢ÂêëÂØπË±°Á®ãÂ∫èËÆæËÆ°
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/FDS.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Êï∞ÊçÆÁªìÊûÑÂü∫Á°Ä
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Â§ß‰∫åÊò•Â§è
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Â§ß‰∫åÊò•Â§è
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/ADS.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    È´òÁ∫ßÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ïÂàÜÊûê
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/DB.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Êï∞ÊçÆÂ∫ìÁ≥ªÁªü
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/ML.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Êú∫Âô®Â≠¶‰π†ÔºàÂõΩÈôÖÂåñÔºâ
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/PIS.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‰ø°ÊÅØÂÆâÂÖ®ÂéüÁêÜ
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Â§ß‰∏âÁßãÂÜ¨
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Â§ß‰∏âÁßãÂÜ¨
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/OS.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Êìç‰ΩúÁ≥ªÁªü
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/CN.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ËÆ°ÁÆóÊú∫ÁΩëÁªú
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/%E6%AF%9B%E6%A6%82.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ÊØõÊ¶Ç
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/IoT.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Áâ©ËÅîÁΩëÊäÄÊúØÂü∫Á°Ä‰∏éÂ∫îÁî®ÂºÄÂèë
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/SQAT.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ËΩØ‰ª∂Ë¥®Èáè‰∏é‰øùËØÅÊµãËØï
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Â§ß‰∏âÊò•Â§è
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Â§ß‰∏âÊò•Â§è
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/CLDF.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Êï∞Â≠óÈÄªËæëËÆæËÆ°
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZJU/%E4%B9%A0%E6%A6%82.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‰π†Ê¶Ç
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    UIUC-MEng coursesüìö
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    UIUC-MEng coursesüìö
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Fall 2025
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Fall 2025
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    ECE408/CS483 Applied Parallel Programming
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="ECE408.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    ECE408/CS483 Applied Parallel Programming
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="ÁõÆÂΩï">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ÁõÆÂΩï
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        1 Introduction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1 Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#post-dennard-technology-pivot-parallelism-and-heterogeneity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Post-Dennard technology pivot ‚Äì parallelism and heterogeneity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cpu-vs-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      
        CPU vs GPU
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-programming-frameworks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Programming Frameworks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parallel Programming Frameworks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-computing-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Computing Challenges
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-computing-pitfall" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Computing PitfallÔºàÈô∑Èò±Ôºâ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#amdahls-law" class="md-nav__link">
    <span class="md-ellipsis">
      
        Amdahl's Law
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-introduction-to-cuda-c-and-data-parallel-programming" class="md-nav__link">
    <span class="md-ellipsis">
      
        2 Introduction to CUDA C and Data Parallel Programming
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 Introduction to CUDA C and Data Parallel Programming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#types-of-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      
        Types of Parallelism
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cudaopencl-execution-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA/OpenCL Execution Mode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#threads" class="md-nav__link">
    <span class="md-ellipsis">
      
        Threads
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-addition" class="md-nav__link">
    <span class="md-ellipsis">
      
        Vector Addition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vector Addition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#system-organization" class="md-nav__link">
    <span class="md-ellipsis">
      
        System Organization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-vector-addition-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        A vector addition kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device-memory-management-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Device Memory Management API
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA Device Memory Management API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api-for-managing-device-global-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        API for managing device global memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#launching-a-grid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Launching a Grid
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-addition-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        Vector Addition Kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiling-a-cuda-program" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compiling A CUDA Program
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compiling A CUDA Program">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#function-declarations-in-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Function Declarations in CUDA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#more-on-function-declarations" class="md-nav__link">
    <span class="md-ellipsis">
      
        More on Function Declarations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#asynchronous-kernel-calls" class="md-nav__link">
    <span class="md-ellipsis">
      
        Asynchronous Kernel Calls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-checking" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error Checking
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problems
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-cuda-parallel-execution-model-multidimensional-grids-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        3 CUDA Parallel Execution Model: Multidimensional Grids &amp; Data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 CUDA Parallel Execution Model: Multidimensional Grids &amp; Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-thread-grids-are-multi-dimensional" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Thread Grids are Multi-Dimensional
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA Thread Grids are Multi-Dimensional">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#one-dimensional-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      
        One Dimensional Indexing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multidimensional-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multidimensional Indexing
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuring-multidimensional-grids" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuring Multidimensional Grids
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuring Multidimensional Grids">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#use-built-in-dim3-type" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use built-in dim3 type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layout-of-multidimensional-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Layout of Multidimensional Data
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rgb-to-gray-scale-kernel-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        RGB to Gray-Scale Kernel Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#blur-kernel-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Blur Kernel Implementation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-matrix-multiplication" class="md-nav__link">
    <span class="md-ellipsis">
      
        Matrix-Matrix Multiplication
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-compute-architecture-and-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        4 Compute Architecture and Scheduling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 Compute Architecture and Scheduling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#executing-thread-blocks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Executing Thread Blocks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Executing Thread Blocks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpu-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPU Architecture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#assigning-blocks-to-sms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Assigning Blocks to SMs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#synchronization-across-thread-blocks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Synchronization across Thread Blocks
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sm-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        SM Scheduling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SM Scheduling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#warps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Warps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thread-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thread Scheduling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#control-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Control Divergence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avoiding-branch-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Avoiding Branch Divergence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lantency-hiding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lantency hiding Âª∂ËøüÈöêËóè
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#occupancy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Occupancy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#block-granularity-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Block Granularity Considerations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-cuda-memory-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        5 CUDA Memory Model
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5 CUDA Memory Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-von-neumann-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Von-Neumann Model ÂÜØËØ∫‰æùÊõº
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programmers-view-of-cuda-memories" class="md-nav__link">
    <span class="md-ellipsis">
      
        Programmer‚Äôs View of CUDA Memories
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#registers-vs-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Registers vs Memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelize-elements-of-p" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallelize Elements of P
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parallelize Elements of P">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compute-using-2d-blocks-in-a-2d-grid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compute Using 2D Blocks in a 2D Grid
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-invocation-host-side-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kernel Invocation (Host-side Code)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kernel Function
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kernel Function">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#matrix-multiplication-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        Matrix Multiplication Kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-data-locality-and-tiled-matrix-multiply" class="md-nav__link">
    <span class="md-ellipsis">
      
        6 Data Locality and Tiled Matrix Multiply
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6 Data Locality and Tiled Matrix Multiply">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-bound-and-the-roofline-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Bound and the Roofline Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-common-programming-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Common Programming Strategy
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A Common Programming Strategy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiled-multiply" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled Multiply
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiled-matrix-matrix-multiplication" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled Matrix-Matrix Multiplication
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bulk-synchronous-steps-based-on-barriers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bulk Synchronous Steps Based on Barriers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boundary-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Boundary Conditions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bottleneck" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bottleneck Áì∂È¢à
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Bottleneck Áì∂È¢à">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-and-occupancy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory and Occupancy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dynamic-shared-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Shared Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiling-on-cpu" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiling on CPU
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-dram-bandwidth-and-other-performance-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        7 DRAM Bandwidth and other Performance Considerations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7 DRAM Bandwidth and other Performance Considerations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dram" class="md-nav__link">
    <span class="md-ellipsis">
      
        DRAM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-coalescing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Coalescing ÂÜÖÂ≠òÂêàÂπ∂
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Memory Coalescing ÂÜÖÂ≠òÂêàÂπ∂">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#matrix-matrix-multiplication_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Matrix-matrix multiplication
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#use-of-shared-memory-enables-coalescing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use of Shared Memory Enables Coalescing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#latency-hiding-with-multiple-banks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latency Hiding with Multiple Banks
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-grain-thread-granularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fine-Grain Thread Granularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Fine-Grain Thread Granularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#thread-coarsening" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thread Coarsening Á≤óÂåñ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loop-unrolling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Loop unrolling Âæ™ÁéØÂ±ïÂºÄ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instruction-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Instruction Scheduling Êåá‰ª§Ë∞ÉÂ∫¶
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#double-buffering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Buffering ÂèåÁºìÂÜ≤
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#checklist-of-common-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Checklist of Common Optimizations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Checklist of Common Optimizations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trade-off-between-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Trade-off Between Optimizations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-convolution-concept-constant-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        8 Convolution Concept; Constant Cache
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8 Convolution Concept; Constant Cache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        Convolution Applications
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Convolution Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1d-kernel-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        1D kernel convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2d-convolution-with-boundary-condition-handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        2D Convolution with boundary condition handling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programmer-view-of-cuda-memories" class="md-nav__link">
    <span class="md-ellipsis">
      
        Programmer View of CUDA Memories
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-hierarchies" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Hierarchies
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Memory Hierarchies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-2d-convolution-kernel-using-constant-memory-for-f" class="md-nav__link">
    <span class="md-ellipsis">
      
        A 2D convolution kernel using constant memory for F
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cache
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#caches-and-locality" class="md-nav__link">
    <span class="md-ellipsis">
      
        Caches and Locality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#caches-cant-hold-everything" class="md-nav__link">
    <span class="md-ellipsis">
      
        Caches Can‚Äôt Hold Everything
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shared-memory-vs-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Shared Memory vs. Cache
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constant-cache-in-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constant cache in GPUs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-constant-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Constant Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiled-convolution-with-halo-cells" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled convolution with halo cells
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tiled convolution with halo cells">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiled-1d-convolution-basic-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled 1D Convolution Basic Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#three-tiling-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      
        Three Tiling Strategies
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-2d-tiled-convolution-kernel-reuse-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        9 2D Tiled Convolution Kernel; Reuse Analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9 2D Tiled Convolution Kernel; Reuse Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stencil-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stencil Algorithms
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strategy-2-parallelize-loading-of-a-tile" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strategy 2: Parallelize Loading of a Tile
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Strategy 2: Parallelize Loading of a Tile">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelizing-tile-loading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallelizing Tile Loading
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setting-block-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Setting Block Dimensions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2d-tiled-convolution-kernel-with-constant-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        2D Tiled Convolution Kernel (with constant memory)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reuse-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reuse Analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reuse Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-small-1d-convolution-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Small 1D Convolution Example
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-2d-convolution-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example of 2D Convolution Example
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2bflop-for-untiled-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        2B/FLOP for Untiled Convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-hierarchy-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Hierarchy Considerations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-introduction-to-ml-inference-and-training-in-dnns" class="md-nav__link">
    <span class="md-ellipsis">
      
        10 Introduction to ML; Inference and Training in DNNs
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10 Introduction to ML; Inference and Training in DNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#machine-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Machine Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-classificationperceptron" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Classification(perceptronÊÑüÁü•Âô®)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-layer-perceptron-mlp-for-digit-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Layer Perceptron (MLP) for Digit Recognition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-Layer Perceptron (MLP) for Digit Recognition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-do-we-determine-the-weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        How Do We Determine the Weights?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-and-backward-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Forward and Backward Propagation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoidlogistic-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sigmoid/Logistic Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reluactivation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        ReLU(Activation Functions)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#use-softmax-to-produce-probabilities" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use Softmax to Produce Probabilities
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stochastic-gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stochastic Gradient Descent ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôç
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-gradient-update-with-one-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example: Gradient Update with One Layer
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-computation-in-cnns-and-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      
        11 Computation in CNNs and Transformers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11 Computation in CNNs and Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-convolution-inputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example convolution Inputs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Convolution
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Why Convolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-vs-multi-layer-perceptron" class="md-nav__link">
    <span class="md-ellipsis">
      
        Convolution vs Multi-Layer Perceptron
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anatomy-of-a-convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Anatomy of a Convolution Layer Âç∑ÁßØÂ±ÇÂâñÊûê
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-d-pooling-subsampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        2-D Pooling (Subsampling)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Forward Propagation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Forward Propagation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequential-code-forward-pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sequential Code: Forward Pooling Layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#host-code-for-a-basic-kernel-cuda-grid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Host Code for a Basic Kernel: CUDA Grid
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-convolutional-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Forward Convolutional Layer Âç∑ÁßØÂâçÂêë‰º†Êí≠
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-atomic-operations-and-histogramming" class="md-nav__link">
    <span class="md-ellipsis">
      
        13 Atomic Operations and Histogramming
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13 Atomic Operations and Histogramming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-races" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Races
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mutual-exclusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mutual Exclusion ‰∫íÊñ•
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Operations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Atomic Operations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementing-atomic-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementing Atomic Operations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomicity-enforced-by-microarchitecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomicity Enforced by Microarchitecture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-compare-and-swap-cas" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Compare and Swap (CAS)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-operations-in-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Operations in CUDA
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Atomic Operations in CUDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#code-with-atomic-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code with Atomic Operations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#histogramming" class="md-nav__link">
    <span class="md-ellipsis">
      
        Histogramming Áõ¥ÊñπÂõæ
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Histogramming Áõ¥ÊñπÂõæ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-histogram-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Histogram Kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-operations-on-dram" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Operations on DRAM
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Atomic Operations on DRAM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#high-latency" class="md-nav__link">
    <span class="md-ellipsis">
      
        High Latency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardware-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hardware Improvements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#privatizing-the-histogram" class="md-nav__link">
    <span class="md-ellipsis">
      
        Privatizing the Histogram
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-parallel-computation-patterns-reduction-trees" class="md-nav__link">
    <span class="md-ellipsis">
      
        14 Parallel Computation Patterns ‚Äì Reduction Trees
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="14 Parallel Computation Patterns ‚Äì Reduction Trees">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reduction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-reduction-in-logn-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Reduction in \(\log(N)\) Steps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#segmented-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Segmented Reduction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-strategy-for-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Strategy for CUDA
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parallel Strategy for CUDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-reduction-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Reduction Algorithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-simple-mapping-of-data-to-threads" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Simple Mapping of Data to Threads
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#control-divergence-reduced" class="md-nav__link">
    <span class="md-ellipsis">
      
        Control Divergence Reduced
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-reuse" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Reuse
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-shared-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using shared Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reducing-synchronization-with-warp-level-primitives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reducing Synchronization with Warp-level Primitives
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reducing Synchronization with Warp-level Primitives">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#code-for-reduction-with-warp-shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code for Reduction with Warp Shuffle
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warp-level-programming-with-cooperative-groups" class="md-nav__link">
    <span class="md-ellipsis">
      
        Warp-level Programming with Cooperative Groups
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduction-with-warp-shuffle-code-using-cooperative-groups" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reduction with Warp Shuffle Code using Cooperative Groups
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-for-reduction-with-two-stage-warp-reductions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code for Reduction with Two-Stage Warp Reductions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#divergence-in-reduction-with-two-stage-warp-reductions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Divergence in Reduction with Two-Stage Warp Reductions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thread-coarsening_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thread Coarsening
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coarsening-benefits" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coarsening Benefits
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-parallel-computation-patterns-parallel-scan-prefix-sum" class="md-nav__link">
    <span class="md-ellipsis">
      
        15 Parallel Computation Patterns ‚Äì Parallel Scan (Prefix Sum)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="15 Parallel Computation Patterns ‚Äì Parallel Scan (Prefix Sum)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scan Êâ´Êèè
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Scan Êâ´Êèè">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequential-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sequential scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#segmented-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Segmented scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thee-kernel-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thee-Kernel Scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-global-memory-contents-in-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Global Memory Contents in CUDA
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kogge-stone-parallel-inclusive-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kogge-Stone Parallel (Inclusive) Scan
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kogge-Stone Parallel (Inclusive) Scan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-inclusive-scan-using-reduction-trees" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Inclusive Scan using Reduction Trees
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-inclusive-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel (Inclusive) Scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kogge-stone-parallel-inclusive-scan_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kogge-Stone Parallel (Inclusive) Scan
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#double-buffering_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Buffering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Double Buffering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#double-buffering-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Buffering Code
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-for-scan-with-warp-level-primitives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code for Scan with Warp-level Primitives
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#work-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Work Efficiency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#improve-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Improve Efficiency
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#brent-kung-parallel-scan-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        Brent-Kung Parallel Scan Step
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Brent-Kung Parallel Scan Step">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#work-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Work Analysis
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kogge-stone-vs-brent-kung" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kogge-Stone vs. Brent-Kung
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overall-flow-of-complete-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overall Flow of Complete Scan
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Overall Flow of Complete Scan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scan-of-arbitrary-length-input" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scan of Arbitrary Length Input
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-bandwidth-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Bandwidth Considerations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#single-kernel-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Single-Kernel Scan
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-advanced-optimizations-for-projects" class="md-nav__link">
    <span class="md-ellipsis">
      
        16 Advanced Optimizations for Projects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="16 Advanced Optimizations for Projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#where-we-left-off-basic-shared-memory-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where We Left Off: Basic Shared Memory Tiling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Where We Left Off: Basic Shared Memory Tiling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameter-tuning-in-basic-shared-memory-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameter Tuning in Basic Shared Memory Tiling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basic-shared-memory-tiling-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Shared Memory Tiling Efficiency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#better-than-shared-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Better Than Shared Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#joint-register-and-shared-memory-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Joint Register and Shared Memory Tiling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-corestf32" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tensor cores‚Äî‚ÄîTF32
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wmma-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        WMMA API
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WMMA API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spilt-k" class="md-nav__link">
    <span class="md-ellipsis">
      
        Spilt-K
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pointer-aliasing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pointer Aliasing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiler-optimizations-the-restrict-keyword" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compiler Optimizations ‚Äì The Restrict Keyword
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-profiling-on-nvidia-gpu-profiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        17 Profiling on Nvidia GPU Profiling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="17 Profiling on Nvidia GPU Profiling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpu-hardware" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPU hardware
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cache_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cache
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-gpu-systems-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        18 GPU Systems Architecture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="18 GPU Systems Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-structurte" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA structurte
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#peripheral-component-interconnect-pci" class="md-nav__link">
    <span class="md-ellipsis">
      
        Peripheral Component Interconnect (PCI)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Peripheral Component Interconnect (PCI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pci" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCI
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pcie" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCIe
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pcie-data-transfer-using-dma" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCIe Data Transfer using DMA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinned-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pinned Memory
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pinned Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deltas-nvidia-a40-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Delta‚Äôs NVIDIA A40 GPUs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-acclerating-matrix-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        19 Acclerating Matrix Operations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="19 Acclerating Matrix Operations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor-cores" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tensor Cores
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensor Cores">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-the-motivation-deep-learning-scale" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. The Motivation: Deep Learning Scale
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-the-hardware-tensor-cores" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. The Hardware: Tensor Cores
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-the-software-wmma-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. The Software: WMMA API
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-tiling-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Tiling Constraints
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-data-transfer-and-cuda-streams-task-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      
        20 Data Transfer and CUDA Streams (Task Parallelism)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="20 Data Transfer and CUDA Streams (Task Parallelism)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#serialized-data-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Serialized Data Transfer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device-overlap" class="md-nav__link">
    <span class="md-ellipsis">
      
        Device Overlap
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-streams" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Streams
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-parallel-sparse-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        21 Parallel Sparse Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="21 Parallel Sparse Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sparse-matrix-storage-formats" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sparse Matrix Storage Formats
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sparse Matrix Storage Formats">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coordinate-format-coo" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coordinate Format (COO)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compressed-sparse-row-csr" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compressed Sparse Row (CSR)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compressed-sparse-column-csc" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compressed Sparse Column (CSC)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ellpack-format-ell" class="md-nav__link">
    <span class="md-ellipsis">
      
        ELLPACK Format (ELL)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jagged-diagonal-storage-jds" class="md-nav__link">
    <span class="md-ellipsis">
      
        Jagged Diagonal Storage (JDS)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-format-should-we-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        What format should we use?
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#22-other-acceleration-apisalternatives-to-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        22 Other Acceleration APIs(Alternatives to CUDA)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="22 Other Acceleration APIs(Alternatives to CUDA)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hardware-traits" class="md-nav__link">
    <span class="md-ellipsis">
      
        ‚öôÔ∏è Hardware Traits
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#software-traits" class="md-nav__link">
    <span class="md-ellipsis">
      
        üíª Software Traits
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-cuda-dynamic-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      
        23 CUDA Dynamic Parallelism
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="23 CUDA Dynamic Parallelism">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#important-exam-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Exam Concepts ÈáçË¶ÅËÄÉËØïÊ¶ÇÂøµ
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      
        24
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#25-advanced-optimizations-improving-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        25 Advanced Optimizations-Improving Attention
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="25 Advanced Optimizations-Improving Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overview-why-optimize-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview: Why Optimize Attention?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-flash-attention-kernel-fusion-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Flash Attention (Kernel Fusion &amp; Tiling)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-algorithmic-simplification-windowed-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Algorithmic Simplification: Windowed Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-inference-optimization-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Inference Optimization: KV Cache
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-memory-management-pagedattention" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Memory Management: PagedAttention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-precision-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Precision: Quantization ÈáèÂåñ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#important-knowledge-points" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Knowledge Points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#26" class="md-nav__link">
    <span class="md-ellipsis">
      
        26
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cnn-project" class="md-nav__link">
    <span class="md-ellipsis">
      
        CNN Project
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quiz" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quiz
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quiz">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mt1" class="md-nav__link">
    <span class="md-ellipsis">
      
        MT1
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mt2" class="md-nav__link">
    <span class="md-ellipsis">
      
        MT2
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#midterm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Midterm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Midterm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-code-for-2d-convolution-tiled-matrix-operation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cuda code for 2D convolution tiled matrix operation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cuda code for 2D convolution tiled matrix operation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#host-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Host code
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-kernel-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cuda kernel code
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3d-tiled-matrix-operation-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        3D tiled matrix operation Convolution
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="ECE448.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ECE448/CS440 Artificial Intelligence
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="ECE598.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ECE498/598 Deep Generative Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Spring 2026
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Spring 2026
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="CS498.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CS498 Machine Learning Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="ECE478.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CS477/ECE478 Formal Software Development Methods
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="ECE544.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ECE544 Pattern Recognition
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ÊäÄËÉΩ‚öôÔ∏è
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    ÊäÄËÉΩ‚öôÔ∏è
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../skills/Algorithm.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ÁÆóÊ≥ï
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../skills/deeplearning.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ê∑±Â∫¶Â≠¶‰π†
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Âá∫ÂõΩ‚úàÔ∏è
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Âá∫ÂõΩ‚úàÔ∏è
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ÈõÖÊÄùÂè£ËØ≠
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    ÈõÖÊÄùÂè£ËØ≠
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../abroad/IELTs_speaking1.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Á¨¨‰∏ÄÊ¨°
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../abroad/IELTs_speaking2.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Á¨¨‰∫åÊ¨°
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../abroad/IELTs_writing.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ÈõÖÊÄù‰ΩúÊñá
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ÊâæÂ∑•
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    ÊâæÂ∑•
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../work/Interview.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Èù¢ËØï
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ÂÖ∂‰ªñüéä
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    ÂÖ∂‰ªñüéä
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../other/test.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Test
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../other/Debug_issue.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ÈÉ®ÁΩ≤ÁΩëÁ´ôÊó∂ÁöÑÈóÆÈ¢ò
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="ÁõÆÂΩï">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ÁõÆÂΩï
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        1 Introduction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1 Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#post-dennard-technology-pivot-parallelism-and-heterogeneity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Post-Dennard technology pivot ‚Äì parallelism and heterogeneity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cpu-vs-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      
        CPU vs GPU
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-programming-frameworks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Programming Frameworks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parallel Programming Frameworks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-computing-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Computing Challenges
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-computing-pitfall" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Computing PitfallÔºàÈô∑Èò±Ôºâ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#amdahls-law" class="md-nav__link">
    <span class="md-ellipsis">
      
        Amdahl's Law
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-introduction-to-cuda-c-and-data-parallel-programming" class="md-nav__link">
    <span class="md-ellipsis">
      
        2 Introduction to CUDA C and Data Parallel Programming
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 Introduction to CUDA C and Data Parallel Programming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#types-of-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      
        Types of Parallelism
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cudaopencl-execution-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA/OpenCL Execution Mode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#threads" class="md-nav__link">
    <span class="md-ellipsis">
      
        Threads
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-addition" class="md-nav__link">
    <span class="md-ellipsis">
      
        Vector Addition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vector Addition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#system-organization" class="md-nav__link">
    <span class="md-ellipsis">
      
        System Organization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-vector-addition-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        A vector addition kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device-memory-management-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Device Memory Management API
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA Device Memory Management API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api-for-managing-device-global-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        API for managing device global memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#launching-a-grid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Launching a Grid
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-addition-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        Vector Addition Kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiling-a-cuda-program" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compiling A CUDA Program
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compiling A CUDA Program">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#function-declarations-in-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Function Declarations in CUDA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#more-on-function-declarations" class="md-nav__link">
    <span class="md-ellipsis">
      
        More on Function Declarations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#asynchronous-kernel-calls" class="md-nav__link">
    <span class="md-ellipsis">
      
        Asynchronous Kernel Calls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-checking" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error Checking
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problems
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-cuda-parallel-execution-model-multidimensional-grids-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        3 CUDA Parallel Execution Model: Multidimensional Grids &amp; Data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 CUDA Parallel Execution Model: Multidimensional Grids &amp; Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-thread-grids-are-multi-dimensional" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Thread Grids are Multi-Dimensional
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA Thread Grids are Multi-Dimensional">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#one-dimensional-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      
        One Dimensional Indexing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multidimensional-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multidimensional Indexing
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuring-multidimensional-grids" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuring Multidimensional Grids
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuring Multidimensional Grids">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#use-built-in-dim3-type" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use built-in dim3 type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layout-of-multidimensional-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Layout of Multidimensional Data
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rgb-to-gray-scale-kernel-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        RGB to Gray-Scale Kernel Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#blur-kernel-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Blur Kernel Implementation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-matrix-multiplication" class="md-nav__link">
    <span class="md-ellipsis">
      
        Matrix-Matrix Multiplication
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-compute-architecture-and-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        4 Compute Architecture and Scheduling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 Compute Architecture and Scheduling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#executing-thread-blocks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Executing Thread Blocks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Executing Thread Blocks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpu-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPU Architecture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#assigning-blocks-to-sms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Assigning Blocks to SMs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#synchronization-across-thread-blocks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Synchronization across Thread Blocks
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sm-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        SM Scheduling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SM Scheduling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#warps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Warps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thread-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thread Scheduling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#control-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Control Divergence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avoiding-branch-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Avoiding Branch Divergence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lantency-hiding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lantency hiding Âª∂ËøüÈöêËóè
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#occupancy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Occupancy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#block-granularity-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Block Granularity Considerations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-cuda-memory-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        5 CUDA Memory Model
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5 CUDA Memory Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-von-neumann-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Von-Neumann Model ÂÜØËØ∫‰æùÊõº
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programmers-view-of-cuda-memories" class="md-nav__link">
    <span class="md-ellipsis">
      
        Programmer‚Äôs View of CUDA Memories
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#registers-vs-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Registers vs Memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelize-elements-of-p" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallelize Elements of P
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parallelize Elements of P">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compute-using-2d-blocks-in-a-2d-grid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compute Using 2D Blocks in a 2D Grid
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-invocation-host-side-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kernel Invocation (Host-side Code)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kernel Function
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kernel Function">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#matrix-multiplication-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        Matrix Multiplication Kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-data-locality-and-tiled-matrix-multiply" class="md-nav__link">
    <span class="md-ellipsis">
      
        6 Data Locality and Tiled Matrix Multiply
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6 Data Locality and Tiled Matrix Multiply">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-bound-and-the-roofline-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Bound and the Roofline Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-common-programming-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Common Programming Strategy
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A Common Programming Strategy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiled-multiply" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled Multiply
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiled-matrix-matrix-multiplication" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled Matrix-Matrix Multiplication
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bulk-synchronous-steps-based-on-barriers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bulk Synchronous Steps Based on Barriers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boundary-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Boundary Conditions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bottleneck" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bottleneck Áì∂È¢à
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Bottleneck Áì∂È¢à">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-and-occupancy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory and Occupancy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dynamic-shared-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Shared Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiling-on-cpu" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiling on CPU
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-dram-bandwidth-and-other-performance-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        7 DRAM Bandwidth and other Performance Considerations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7 DRAM Bandwidth and other Performance Considerations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dram" class="md-nav__link">
    <span class="md-ellipsis">
      
        DRAM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-coalescing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Coalescing ÂÜÖÂ≠òÂêàÂπ∂
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Memory Coalescing ÂÜÖÂ≠òÂêàÂπ∂">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#matrix-matrix-multiplication_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Matrix-matrix multiplication
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#use-of-shared-memory-enables-coalescing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use of Shared Memory Enables Coalescing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#latency-hiding-with-multiple-banks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latency Hiding with Multiple Banks
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-grain-thread-granularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fine-Grain Thread Granularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Fine-Grain Thread Granularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#thread-coarsening" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thread Coarsening Á≤óÂåñ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loop-unrolling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Loop unrolling Âæ™ÁéØÂ±ïÂºÄ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instruction-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Instruction Scheduling Êåá‰ª§Ë∞ÉÂ∫¶
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#double-buffering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Buffering ÂèåÁºìÂÜ≤
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#checklist-of-common-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Checklist of Common Optimizations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Checklist of Common Optimizations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trade-off-between-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Trade-off Between Optimizations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-convolution-concept-constant-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        8 Convolution Concept; Constant Cache
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8 Convolution Concept; Constant Cache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        Convolution Applications
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Convolution Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1d-kernel-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        1D kernel convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2d-convolution-with-boundary-condition-handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        2D Convolution with boundary condition handling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programmer-view-of-cuda-memories" class="md-nav__link">
    <span class="md-ellipsis">
      
        Programmer View of CUDA Memories
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-hierarchies" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Hierarchies
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Memory Hierarchies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-2d-convolution-kernel-using-constant-memory-for-f" class="md-nav__link">
    <span class="md-ellipsis">
      
        A 2D convolution kernel using constant memory for F
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cache
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#caches-and-locality" class="md-nav__link">
    <span class="md-ellipsis">
      
        Caches and Locality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#caches-cant-hold-everything" class="md-nav__link">
    <span class="md-ellipsis">
      
        Caches Can‚Äôt Hold Everything
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shared-memory-vs-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Shared Memory vs. Cache
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constant-cache-in-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constant cache in GPUs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-constant-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Constant Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiled-convolution-with-halo-cells" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled convolution with halo cells
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tiled convolution with halo cells">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiled-1d-convolution-basic-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tiled 1D Convolution Basic Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#three-tiling-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      
        Three Tiling Strategies
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-2d-tiled-convolution-kernel-reuse-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        9 2D Tiled Convolution Kernel; Reuse Analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9 2D Tiled Convolution Kernel; Reuse Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stencil-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stencil Algorithms
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strategy-2-parallelize-loading-of-a-tile" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strategy 2: Parallelize Loading of a Tile
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Strategy 2: Parallelize Loading of a Tile">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelizing-tile-loading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallelizing Tile Loading
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setting-block-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Setting Block Dimensions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2d-tiled-convolution-kernel-with-constant-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        2D Tiled Convolution Kernel (with constant memory)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reuse-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reuse Analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reuse Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-small-1d-convolution-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Small 1D Convolution Example
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-2d-convolution-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example of 2D Convolution Example
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2bflop-for-untiled-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        2B/FLOP for Untiled Convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-hierarchy-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Hierarchy Considerations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-introduction-to-ml-inference-and-training-in-dnns" class="md-nav__link">
    <span class="md-ellipsis">
      
        10 Introduction to ML; Inference and Training in DNNs
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10 Introduction to ML; Inference and Training in DNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#machine-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Machine Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-classificationperceptron" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Classification(perceptronÊÑüÁü•Âô®)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-layer-perceptron-mlp-for-digit-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Layer Perceptron (MLP) for Digit Recognition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-Layer Perceptron (MLP) for Digit Recognition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-do-we-determine-the-weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        How Do We Determine the Weights?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-and-backward-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Forward and Backward Propagation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoidlogistic-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sigmoid/Logistic Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reluactivation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        ReLU(Activation Functions)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#use-softmax-to-produce-probabilities" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use Softmax to Produce Probabilities
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stochastic-gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stochastic Gradient Descent ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôç
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-gradient-update-with-one-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example: Gradient Update with One Layer
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-computation-in-cnns-and-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      
        11 Computation in CNNs and Transformers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11 Computation in CNNs and Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-convolution-inputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example convolution Inputs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Convolution
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Why Convolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-vs-multi-layer-perceptron" class="md-nav__link">
    <span class="md-ellipsis">
      
        Convolution vs Multi-Layer Perceptron
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anatomy-of-a-convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Anatomy of a Convolution Layer Âç∑ÁßØÂ±ÇÂâñÊûê
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-d-pooling-subsampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        2-D Pooling (Subsampling)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Forward Propagation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Forward Propagation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequential-code-forward-pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sequential Code: Forward Pooling Layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#host-code-for-a-basic-kernel-cuda-grid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Host Code for a Basic Kernel: CUDA Grid
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-convolutional-layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Forward Convolutional Layer Âç∑ÁßØÂâçÂêë‰º†Êí≠
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-atomic-operations-and-histogramming" class="md-nav__link">
    <span class="md-ellipsis">
      
        13 Atomic Operations and Histogramming
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13 Atomic Operations and Histogramming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-races" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Races
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mutual-exclusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mutual Exclusion ‰∫íÊñ•
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Operations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Atomic Operations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementing-atomic-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementing Atomic Operations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomicity-enforced-by-microarchitecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomicity Enforced by Microarchitecture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-compare-and-swap-cas" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Compare and Swap (CAS)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-operations-in-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Operations in CUDA
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Atomic Operations in CUDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#code-with-atomic-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code with Atomic Operations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#histogramming" class="md-nav__link">
    <span class="md-ellipsis">
      
        Histogramming Áõ¥ÊñπÂõæ
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Histogramming Áõ¥ÊñπÂõæ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-histogram-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Histogram Kernel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#atomic-operations-on-dram" class="md-nav__link">
    <span class="md-ellipsis">
      
        Atomic Operations on DRAM
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Atomic Operations on DRAM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#high-latency" class="md-nav__link">
    <span class="md-ellipsis">
      
        High Latency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardware-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hardware Improvements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#privatizing-the-histogram" class="md-nav__link">
    <span class="md-ellipsis">
      
        Privatizing the Histogram
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-parallel-computation-patterns-reduction-trees" class="md-nav__link">
    <span class="md-ellipsis">
      
        14 Parallel Computation Patterns ‚Äì Reduction Trees
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="14 Parallel Computation Patterns ‚Äì Reduction Trees">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reduction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-reduction-in-logn-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Reduction in \(\log(N)\) Steps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#segmented-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Segmented Reduction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-strategy-for-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Strategy for CUDA
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parallel Strategy for CUDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-reduction-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Reduction Algorithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-simple-mapping-of-data-to-threads" class="md-nav__link">
    <span class="md-ellipsis">
      
        A Simple Mapping of Data to Threads
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#control-divergence-reduced" class="md-nav__link">
    <span class="md-ellipsis">
      
        Control Divergence Reduced
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-reuse" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Reuse
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-shared-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using shared Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reducing-synchronization-with-warp-level-primitives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reducing Synchronization with Warp-level Primitives
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reducing Synchronization with Warp-level Primitives">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#code-for-reduction-with-warp-shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code for Reduction with Warp Shuffle
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warp-level-programming-with-cooperative-groups" class="md-nav__link">
    <span class="md-ellipsis">
      
        Warp-level Programming with Cooperative Groups
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduction-with-warp-shuffle-code-using-cooperative-groups" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reduction with Warp Shuffle Code using Cooperative Groups
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-for-reduction-with-two-stage-warp-reductions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code for Reduction with Two-Stage Warp Reductions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#divergence-in-reduction-with-two-stage-warp-reductions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Divergence in Reduction with Two-Stage Warp Reductions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thread-coarsening_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thread Coarsening
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coarsening-benefits" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coarsening Benefits
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-parallel-computation-patterns-parallel-scan-prefix-sum" class="md-nav__link">
    <span class="md-ellipsis">
      
        15 Parallel Computation Patterns ‚Äì Parallel Scan (Prefix Sum)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="15 Parallel Computation Patterns ‚Äì Parallel Scan (Prefix Sum)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scan Êâ´Êèè
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Scan Êâ´Êèè">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequential-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sequential scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#segmented-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Segmented scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thee-kernel-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Thee-Kernel Scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-global-memory-contents-in-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Global Memory Contents in CUDA
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kogge-stone-parallel-inclusive-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kogge-Stone Parallel (Inclusive) Scan
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kogge-Stone Parallel (Inclusive) Scan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-inclusive-scan-using-reduction-trees" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel Inclusive Scan using Reduction Trees
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-inclusive-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parallel (Inclusive) Scan
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kogge-stone-parallel-inclusive-scan_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kogge-Stone Parallel (Inclusive) Scan
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#double-buffering_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Buffering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Double Buffering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#double-buffering-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Buffering Code
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-for-scan-with-warp-level-primitives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code for Scan with Warp-level Primitives
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#work-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Work Efficiency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#improve-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Improve Efficiency
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#brent-kung-parallel-scan-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        Brent-Kung Parallel Scan Step
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Brent-Kung Parallel Scan Step">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#work-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Work Analysis
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kogge-stone-vs-brent-kung" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kogge-Stone vs. Brent-Kung
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overall-flow-of-complete-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overall Flow of Complete Scan
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Overall Flow of Complete Scan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scan-of-arbitrary-length-input" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scan of Arbitrary Length Input
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-bandwidth-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Bandwidth Considerations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#single-kernel-scan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Single-Kernel Scan
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-advanced-optimizations-for-projects" class="md-nav__link">
    <span class="md-ellipsis">
      
        16 Advanced Optimizations for Projects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="16 Advanced Optimizations for Projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#where-we-left-off-basic-shared-memory-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where We Left Off: Basic Shared Memory Tiling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Where We Left Off: Basic Shared Memory Tiling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameter-tuning-in-basic-shared-memory-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameter Tuning in Basic Shared Memory Tiling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basic-shared-memory-tiling-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Shared Memory Tiling Efficiency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#better-than-shared-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Better Than Shared Memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#joint-register-and-shared-memory-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Joint Register and Shared Memory Tiling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-corestf32" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tensor cores‚Äî‚ÄîTF32
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wmma-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        WMMA API
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WMMA API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spilt-k" class="md-nav__link">
    <span class="md-ellipsis">
      
        Spilt-K
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pointer-aliasing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pointer Aliasing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiler-optimizations-the-restrict-keyword" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compiler Optimizations ‚Äì The Restrict Keyword
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-profiling-on-nvidia-gpu-profiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        17 Profiling on Nvidia GPU Profiling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="17 Profiling on Nvidia GPU Profiling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpu-hardware" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPU hardware
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cache_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cache
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-gpu-systems-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        18 GPU Systems Architecture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="18 GPU Systems Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-structurte" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA structurte
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#peripheral-component-interconnect-pci" class="md-nav__link">
    <span class="md-ellipsis">
      
        Peripheral Component Interconnect (PCI)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Peripheral Component Interconnect (PCI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pci" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCI
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pcie" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCIe
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pcie-data-transfer-using-dma" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCIe Data Transfer using DMA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinned-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pinned Memory
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pinned Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deltas-nvidia-a40-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Delta‚Äôs NVIDIA A40 GPUs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-solving_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Problem Solving
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-acclerating-matrix-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        19 Acclerating Matrix Operations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="19 Acclerating Matrix Operations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor-cores" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tensor Cores
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensor Cores">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-the-motivation-deep-learning-scale" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. The Motivation: Deep Learning Scale
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-the-hardware-tensor-cores" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. The Hardware: Tensor Cores
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-the-software-wmma-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. The Software: WMMA API
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-tiling-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Tiling Constraints
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-data-transfer-and-cuda-streams-task-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      
        20 Data Transfer and CUDA Streams (Task Parallelism)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="20 Data Transfer and CUDA Streams (Task Parallelism)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#serialized-data-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Serialized Data Transfer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device-overlap" class="md-nav__link">
    <span class="md-ellipsis">
      
        Device Overlap
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-streams" class="md-nav__link">
    <span class="md-ellipsis">
      
        CUDA Streams
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-parallel-sparse-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        21 Parallel Sparse Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="21 Parallel Sparse Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sparse-matrix-storage-formats" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sparse Matrix Storage Formats
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sparse Matrix Storage Formats">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coordinate-format-coo" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coordinate Format (COO)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compressed-sparse-row-csr" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compressed Sparse Row (CSR)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compressed-sparse-column-csc" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compressed Sparse Column (CSC)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ellpack-format-ell" class="md-nav__link">
    <span class="md-ellipsis">
      
        ELLPACK Format (ELL)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jagged-diagonal-storage-jds" class="md-nav__link">
    <span class="md-ellipsis">
      
        Jagged Diagonal Storage (JDS)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-format-should-we-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        What format should we use?
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#22-other-acceleration-apisalternatives-to-cuda" class="md-nav__link">
    <span class="md-ellipsis">
      
        22 Other Acceleration APIs(Alternatives to CUDA)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="22 Other Acceleration APIs(Alternatives to CUDA)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hardware-traits" class="md-nav__link">
    <span class="md-ellipsis">
      
        ‚öôÔ∏è Hardware Traits
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#software-traits" class="md-nav__link">
    <span class="md-ellipsis">
      
        üíª Software Traits
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-cuda-dynamic-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      
        23 CUDA Dynamic Parallelism
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="23 CUDA Dynamic Parallelism">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#important-exam-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Exam Concepts ÈáçË¶ÅËÄÉËØïÊ¶ÇÂøµ
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      
        24
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#25-advanced-optimizations-improving-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        25 Advanced Optimizations-Improving Attention
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="25 Advanced Optimizations-Improving Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overview-why-optimize-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview: Why Optimize Attention?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-flash-attention-kernel-fusion-tiling" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Flash Attention (Kernel Fusion &amp; Tiling)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-algorithmic-simplification-windowed-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Algorithmic Simplification: Windowed Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-inference-optimization-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Inference Optimization: KV Cache
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-memory-management-pagedattention" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Memory Management: PagedAttention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-precision-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Precision: Quantization ÈáèÂåñ
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#important-knowledge-points" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Knowledge Points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#26" class="md-nav__link">
    <span class="md-ellipsis">
      
        26
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cnn-project" class="md-nav__link">
    <span class="md-ellipsis">
      
        CNN Project
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quiz" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quiz
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quiz">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mt1" class="md-nav__link">
    <span class="md-ellipsis">
      
        MT1
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mt2" class="md-nav__link">
    <span class="md-ellipsis">
      
        MT2
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#midterm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Midterm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Midterm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-code-for-2d-convolution-tiled-matrix-operation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cuda code for 2D convolution tiled matrix operation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cuda code for 2D convolution tiled matrix operation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#host-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Host code
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-kernel-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cuda kernel code
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3d-tiled-matrix-operation-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        3D tiled matrix operation Convolution
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="ece408cs483-applied-parallel-programming">ECE408/CS483 Applied Parallel Programming<a class="headerlink" href="#ece408cs483-applied-parallel-programming" title="Permanent link">&para;</a></h1>
<div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;">
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"/></svg></span> Á∫¶ 20249 ‰∏™Â≠ó <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M360.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6m64.6 136.1c-12.5 12.5-12.5 32.8 0 45.3l73.4 73.4-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l96-96c12.5-12.5 12.5-32.8 0-45.3l-96-96c-12.5-12.5-32.8-12.5-45.3 0zm-274.7 0c-12.5-12.5-32.8-12.5-45.3 0l-96 96c-12.5 12.5-12.5 32.8 0 45.3l96 96c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l73.3-73.4c12.5-12.5 12.5-32.8 0-45.3z"/></svg></span> 1190 Ë°å‰ª£Á†Å <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 17H7V3h14m0-2H7a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2M3 5H1v16a2 2 0 0 0 2 2h16v-2H3m12.96-10.71-2.75 3.54-1.96-2.36L8.5 15h11z"/></svg></span> 176 Âº†ÂõæÁâá <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"/></svg></span> È¢ÑËÆ°ÈòÖËØªÊó∂Èó¥ 82 ÂàÜÈíü</p>
</div>
<blockquote>
<p><a href="https://canvas.illinois.edu/courses/60979/assignments/syllabus">https://canvas.illinois.edu/courses/60979/assignments/syllabus</a> </p>
<p><a href="https://uiuc.chat/ECE408FA25/chat">https://uiuc.chat/ECE408FA25/chat</a></p>
</blockquote>
<h2 id="1-introduction">1 Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">&para;</a></h2>
<p>CPU(central processing unit)</p>
<p>GPU(graphical processing unit)</p>
<h3 id="post-dennard-technology-pivot-parallelism-and-heterogeneity">Post-Dennard technology pivot ‚Äì parallelism and heterogeneity<a class="headerlink" href="#post-dennard-technology-pivot-parallelism-and-heterogeneity" title="Permanent link">&para;</a></h3>
<p><strong>The Moore‚Äôs Law</strong> (Imperative) drove feature sizes down, doubling the number of transistors/unit area every 18-24 months</p>
<ul>
<li>Exponential increase in clock speed</li>
</ul>
<p><strong>Dennard Scaling</strong> (based on physics) drove clock speeds up</p>
<ul>
<li>ended around 2005-2006</li>
</ul>
<p><strong>multicore</strong>: execution speed of sequential programs</p>
<p><strong>many-thread</strong>: execution throughput of parallel applications</p>
<h3 id="cpu-vs-gpu">CPU vs GPU<a class="headerlink" href="#cpu-vs-gpu" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250828093148709.png" alt="image-20250828093148709" style="zoom:50%;" /></p>
<table>
<thead>
<tr>
<th style="text-align: center;">CPU</th>
<th style="text-align: center;">GPU</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">A few powerful <strong>ALUs</strong>(Arithmetic Logic Unit)</td>
<td style="text-align: center;">Many small ALUs</td>
</tr>
<tr>
<td style="text-align: center;">Reduced operation latency</td>
<td style="text-align: center;">Long latency, high throughput</td>
</tr>
<tr>
<td style="text-align: center;">Large <strong>caches</strong></td>
<td style="text-align: center;">Heavily pipelined for further throughput</td>
</tr>
<tr>
<td style="text-align: center;">Convert long latency memory accesses to short latency cache accesses</td>
<td style="text-align: center;">Small <strong>caches</strong></td>
</tr>
<tr>
<td style="text-align: center;">Sophisticated <strong>control</strong></td>
<td style="text-align: center;">More area dedicated to computation</td>
</tr>
<tr>
<td style="text-align: center;">Branch prediction to reduce control hazards</td>
<td style="text-align: center;">Simple <strong>control</strong></td>
</tr>
<tr>
<td style="text-align: center;">Data forwarding to reduce data hazards</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Modest multithreading to hide short latency</td>
<td style="text-align: center;">A massive number of threads to hide the very high latency!</td>
</tr>
<tr>
<td style="text-align: center;"><strong>High clock frequency</strong></td>
<td style="text-align: center;">Moderate clock frequency</td>
</tr>
<tr>
<td style="text-align: center;"><strong>latency-oriented</strong> Âª∂ËøüÂØºÂêë</td>
<td style="text-align: center;"><strong>throughput-oriented</strong> ÂêûÂêêÈáèÂØºÂêë</td>
</tr>
</tbody>
</table>
<p>CPUs for <strong>sequential parts</strong> where latency hurts</p>
<ul>
<li>CPUs can be 10+X faster than GPUs for sequential code</li>
</ul>
<p>GPUs for <strong>parallel parts</strong> where throughput wins</p>
<ul>
<li>GPUs can be 10+X faster than CPUs for parallel code</li>
</ul>
<h3 id="parallel-programming-frameworks">Parallel Programming Frameworks<a class="headerlink" href="#parallel-programming-frameworks" title="Permanent link">&para;</a></h3>
<blockquote>
<p>[!NOTE]</p>
<p>Why GPUs?</p>
<p>Why repurpose a graphics processing architecture instead of designing a throughput-oriented architecture from scratch?</p>
<ul>
<li>Chips are expensive to build and require a large volume of sales to amortize the cost</li>
<li>This makes the chip market very difficult to penetrate</li>
<li>When parallel computing became mainstream, GPUs already had (and still have) a large installed base from the gaming sector</li>
</ul>
</blockquote>
<h4 id="parallel-computing-challenges">Parallel Computing Challenges<a class="headerlink" href="#parallel-computing-challenges" title="Permanent link">&para;</a></h4>
<p>Massive Parallelism demands Regularity -&gt; Load Balance</p>
<p>Global Memory Bandwidth -&gt; Ideal vs. Reality</p>
<p>Conflicting Data Accesses Cause Serialization and Delays </p>
<ul>
<li>Massively parallel execution cannot afford serialization</li>
<li>Contentions in accessing critical data causes serialization</li>
</ul>
<h4 id="parallel-computing-pitfall">Parallel Computing PitfallÔºàÈô∑Èò±Ôºâ<a class="headerlink" href="#parallel-computing-pitfall" title="Permanent link">&para;</a></h4>
<p>Consider an application where:</p>
<ol>
<li>The sequential execution time is 100s</li>
<li>The fraction of execution that is parallelizable is 90%</li>
<li>The speedup achieved on the parallelizable part is 1000√ó</li>
</ol>
<p>What is the overall speedup of the application?
$$
t_{parallel}=(1-0.9)\times 100s +\frac{0.9 \times 100s}{1000}=10.09s\
speedup=\frac{t_{sequential}}{t_{parallel}}=\frac{100s}{10.09s}=9.91\times \text{Ôºà9.91‰∏∫ÂÄçÊï∞Ôºâ}
$$</p>
<h4 id="amdahls-law">Amdahl's Law<a class="headerlink" href="#amdahls-law" title="Permanent link">&para;</a></h4>
<p><strong>ÈòøÂßÜËææÂ∞îÂÆöÂæã</strong>Ôºö<a href="https://zh.wikipedia.org/wiki/‰∏≠Â§ÆËôïÁêÜÂô®">Â§ÑÁêÜÂô®</a><a href="https://zh.wikipedia.org/wiki/‰∏¶Ë°åÈÅãÁÆó">Âπ∂Ë°åËøêÁÆó</a>‰πãÂêéÊïàÁéáÊèêÂçáÁöÑËÉΩÂäõ</p>
<p><img src="./assets/image-20250828153730248.png" alt="image-20250828153730248" style="zoom: 33%;" /></p>
<p>The maximum speedup of a parallel program is limited by the fraction of execution that is parallelizable, namely, <span class="arithmatex">\(speedup&lt;\frac{1}{1-p}\)</span></p>
<h2 id="2-introduction-to-cuda-c-and-data-parallel-programming">2 Introduction to CUDA C and Data Parallel Programming<a class="headerlink" href="#2-introduction-to-cuda-c-and-data-parallel-programming" title="Permanent link">&para;</a></h2>
<h3 id="types-of-parallelism">Types of Parallelism<a class="headerlink" href="#types-of-parallelism" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th style="text-align: center;">Task Parallelism</th>
<th style="text-align: center;">Data Parallelism</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Different operations performed on same or different data</td>
<td style="text-align: center;">Same operations performed on different data</td>
</tr>
<tr>
<td style="text-align: center;">Usually, a modest number of tasks unleashing a modest amount of parallelism</td>
<td style="text-align: center;">Potentially massive amounts of data unleashing massive amounts of parallelism(Most suitable for GPUs)</td>
</tr>
<tr>
<td style="text-align: center;"><img src="./assets/image-20250828185000905.png" alt="image-20250828185000905" style="zoom:40%;" /></td>
<td style="text-align: center;"><img src="./assets/image-20250828185016719.png" alt="image-20250828185016719" style="zoom:40%;" /></td>
</tr>
</tbody>
</table>
<h3 id="cudaopencl-execution-mode">CUDA/OpenCL Execution Mode<a class="headerlink" href="#cudaopencl-execution-mode" title="Permanent link">&para;</a></h3>
<p><strong>Integrated Host +Device Application(C Program)</strong></p>
<ol>
<li>The execution starts with <em>host code</em> (CPU serial code). ‰∏ªÊú∫‰ª£Á†ÅÂú®CPU‰∏äËøêË°å</li>
<li>When a kernel function is called, a large number of <em>threads</em> are launched on a device to execute the kernel. All the threads that are launched by a kernel call are collectively called a <strong>grid</strong>. </li>
<li>These threads are the primary vehicle of parallel execution in a CUDA platform</li>
<li>When all threads of a grid have completed their execution, the grid terminates, and the execution continues on the host until another grid is launched</li>
</ol>
<ul>
<li><strong>Host Code (C):</strong> Handles serial or modestly parallel tasks</li>
<li><strong>Device Kernel (C,SPMD Model):</strong> Executes highly parallel sections of the program GPU‰∏äËøêË°åËÆæÂ§á‰ª£Á†Å</li>
</ul>
<h3 id="threads">Threads<a class="headerlink" href="#threads" title="Permanent link">&para;</a></h3>
<p>A CUDA <strong>kernel</strong> is executed as a grid(array) of threads</p>
<ul>
<li>All threads in the same grid run the <strong>same kernel</strong></li>
<li>Single Program Multiple Data (SPMD model)</li>
<li>Each thread has a <strong>unique index</strong> that it uses to compute memory addresses and make control decisions</li>
</ul>
<p>Thread as a basic unit of computing</p>
<ul>
<li>Threads within a block cooperate via <strong>shared memory, atomic operations</strong> and <strong>barrier synchronization</strong>.  ÂùóÂÜÖÁöÑÁ∫øÁ®ãÈÄöËøá<strong>ÂÖ±‰∫´ÂÜÖÂ≠ò„ÄÅÂéüÂ≠êÊìç‰Ωú</strong>Âíå<strong>Â±èÈöúÂêåÊ≠•</strong>ËøõË°åÂçè‰Ωú„ÄÇ</li>
<li>Threads in different blocks cooperate less.</li>
</ul>
<p><img src="./assets/image-20250828201313613.png" alt="image-20250828201313613" style="zoom: 40%;" /><img src="./assets/image-20250828201435041.png" alt="image-20250828201435041" style="zoom:33%;" /></p>
<ul>
<li>Thread block and thread organization simplify memory addressing when processing multidimensional data</li>
<li><code>i = blockIdx.x * blockDim.x + threadIdx.x; C[i] = A[i] + B[i];</code></li>
</ul>
<h3 id="vector-addition">Vector Addition<a class="headerlink" href="#vector-addition" title="Permanent link">&para;</a></h3>
<p>We use vector addition to demonstrate the CUDA C program structure.</p>
<p>A simple traditional vector addition C code example.</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="c1">// Compute vector sum C = A+B</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="kt">void</span><span class="w"> </span><span class="nf">vecAdd</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="p">}</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="w">    </span><span class="c1">// Memory allocation for A_h, B_h, and C_h</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="w">    </span><span class="c1">// I/O to read A_h and B_h, N elements...</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="w">    </span><span class="n">vecAdd</span><span class="p">(</span><span class="n">A_h</span><span class="p">,</span><span class="w"> </span><span class="n">B_h</span><span class="p">,</span><span class="w"> </span><span class="n">C_h</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>‰∏ªÊú∫ÁöÑÂèòÈáèÂêçÁß∞ÂêéÁºÄ‰∏∫<code>_h</code>Ôºå‰ΩøÁî®ËÆæÂ§áÁöÑÂèòÈáèÂêçÁß∞ÂêéÁºÄ‰∏∫<code>_d</code></p>
<h4 id="system-organization">System Organization<a class="headerlink" href="#system-organization" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250828095258922.png" alt="image-20250828095258922" style="zoom:40%;" /></p>
<p>The CPU and GPU have <strong>separate memories</strong> and <strong>cannot access</strong> each others' memories</p>
<ul>
<li>Need to <strong>transfer</strong> data between themÔºà‰∏ãÂõæ‰∫îÊ≠•Êìç‰ΩúÔºâ</li>
</ul>
<p><img src="./assets/image-20250828095329700.png" alt="image-20250828095329700" style="zoom:40%;" /></p>
<h4 id="a-vector-addition-kernel">A vector addition kernel<a class="headerlink" href="#a-vector-addition-kernel" title="Permanent link">&para;</a></h4>
<p>Outline of a revised vecAdd function that moves the work to a device.</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-1-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-1-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-1-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-1-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-1-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-1-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-1-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-1-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-1-10">10</a></span>
<span class="normal"><a href="#__codelineno-1-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda.h&gt;</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="kt">void</span><span class="w"> </span><span class="nf">vecAdd</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span><span class="w"> </span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4"></a><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">C_d</span><span class="p">;</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="err">‚Ä¶</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6"></a><span class="mf">1.</span><span class="w"> </span><span class="c1">// Allocate device memory for A, B, and C</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7"></a><span class="c1">// copy A and B to device memory </span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8"></a><span class="mf">2.</span><span class="w"> </span><span class="c1">// Kernel launch code ‚Äì to have the device</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9"></a><span class="c1">// to perform the actual vector addition</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10"></a><span class="mf">3.</span><span class="w"> </span><span class="c1">// copy C from the device memory</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11"></a><span class="c1">// Free device vectors</span>
</span></code></pre></div></td></tr></table></div>
<p><code>vector A + B = vector C</code></p>
<p>Device code can:</p>
<ul>
<li>R/W per-thread registers</li>
<li>R/W per-grid global memory</li>
</ul>
<p>Host code can transfer data to/from per grid global memory</p>
<h3 id="cuda-device-memory-management-api">CUDA Device Memory Management API<a class="headerlink" href="#cuda-device-memory-management-api" title="Permanent link">&para;</a></h3>
<h4 id="api-for-managing-device-global-memory">API for managing device global memory<a class="headerlink" href="#api-for-managing-device-global-memory" title="Permanent link">&para;</a></h4>
<p><strong>Allocating memory</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1">1</a></span>
<span class="normal"><a href="#__codelineno-2-2">2</a></span>
<span class="normal"><a href="#__codelineno-2-3">3</a></span>
<span class="normal"><a href="#__codelineno-2-4">4</a></span>
<span class="normal"><a href="#__codelineno-2-5">5</a></span>
<span class="normal"><a href="#__codelineno-2-6">6</a></span>
<span class="normal"><a href="#__codelineno-2-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="cm">/*Allocating memory*/</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="n">cudaError_t</span><span class="w"> </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="n">devPtr</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="p">)</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="c1">//devPtr: Pointer to pointer to allocated device memory</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="c1">//size: Requested allocation size in byte</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5"></a>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6"></a><span class="cm">/*VecAdd Host Code*/</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="c1">//ËØ¶ËßÅ‰∏ãÈù¢</span>
</span></code></pre></div></td></tr></table></div>
<p><strong>Deallocating memory</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1">1</a></span>
<span class="normal"><a href="#__codelineno-3-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="n">cudaError_t</span><span class="w"> </span><span class="n">cudaFree</span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">devPtr</span><span class="p">)</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="c1">//devPtr: Pointer to device memory to free</span>
</span></code></pre></div></td></tr></table></div>
<p><img src="./assets/image-20250902150849141.png" alt="image-20250902150849141" style="zoom:33%;" /></p>
<ul>
<li>ÊåáÂêëËÆæÂ§áÂÖ®Â±ÄÂÜÖÂ≠ò‰∏≠ÂØπË±°ÁöÑÊåáÈíàÂèòÈáèÂêéÁºÄ‰∏∫<code>_d</code></li>
<li><code>A_d</code>, <code>B_d</code> Âíå <code>C_d</code> ‰∏≠ÁöÑÂú∞ÂùÄÊåáÂêëËÆæÂ§áÂÖ®Â±ÄÂÜÖÂ≠ò device global memory ‰∏≠ÁöÑ‰ΩçÁΩÆ„ÄÇËøô‰∫õÂú∞ÂùÄ‰∏çÂ∫îÂú®‰∏ªÊú∫‰ª£Á†Å‰∏≠Èó¥Êé•ÂºïÁî®„ÄÇÂÆÉ‰ª¨Â∫îËØ•Âú®Ë∞ÉÁî® API ÂáΩÊï∞ÂíåÂÜÖÊ†∏ÂáΩÊï∞Êó∂‰ΩøÁî®„ÄÇ</li>
</ul>
<p><strong>Copying memory</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1">1</a></span>
<span class="normal"><a href="#__codelineno-4-2">2</a></span>
<span class="normal"><a href="#__codelineno-4-3">3</a></span>
<span class="normal"><a href="#__codelineno-4-4">4</a></span>
<span class="normal"><a href="#__codelineno-4-5">5</a></span>
<span class="normal"><a href="#__codelineno-4-6">6</a></span>
<span class="normal"><a href="#__codelineno-4-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="n">cudaError_t</span><span class="w"> </span><span class="nf">cudaMemcpy</span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="n">cudaMemcpyKind</span><span class="w"> </span><span class="n">kind</span><span class="p">)</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2"></a>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="c1">//Example</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4"></a><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">A_h</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">B_h</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6"></a><span class="p">.</span><span class="w"> </span><span class="p">.</span><span class="w"> </span><span class="p">.</span><span class="w"> </span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7"></a><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">C_h</span><span class="p">,</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li><code>dst</code>: Destination memory address</li>
<li><code>src</code>: Source memory address</li>
<li><code>count</code>: Size in bytes to copy</li>
<li><code>kind</code>: Type of transfer<ul>
<li><code>cudaMemcpyHostToHost</code></li>
<li><code>cudaMemcpyHostToDevice</code></li>
<li><code>cudaMemcpyDeviceToHost</code></li>
<li><code>cudaMemcpyDeviceToDevice</code></li>
</ul>
</li>
</ul>
<p><strong>Return type</strong>: <code>cudaError_t</code></p>
<ul>
<li>Helps with error checking (discussed later)</li>
</ul>
<p><strong>vecAdd Host Code</strong></p>
<p>ÂÆåÊï¥ÁâàÊú¨</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-5-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-5-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-5-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-5-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-5-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-5-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-5-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-5-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-5-10">10</a></span>
<span class="normal"><a href="#__codelineno-5-11">11</a></span>
<span class="normal"><a href="#__codelineno-5-12">12</a></span>
<span class="normal"><a href="#__codelineno-5-13">13</a></span>
<span class="normal"><a href="#__codelineno-5-14">14</a></span>
<span class="normal"><a href="#__codelineno-5-15">15</a></span>
<span class="normal"><a href="#__codelineno-5-16">16</a></span>
<span class="normal"><a href="#__codelineno-5-17">17</a></span>
<span class="normal"><a href="#__codelineno-5-18">18</a></span>
<span class="normal"><a href="#__codelineno-5-19">19</a></span>
<span class="normal"><a href="#__codelineno-5-20">20</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="kt">void</span><span class="w"> </span><span class="nf">vecAdd</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span><span class="w"> </span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">C_d</span><span class="p">;</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4"></a><span class="w">    </span><span class="c1">// Transfer A and B to device memory (error-checking omitted)</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9"></a><span class="w">    </span><span class="c1">// Allocate device memory for</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11"></a><span class="w">    </span><span class="c1">// Kernel invocation code ‚Äì to be shown later</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12"></a><span class="w">        </span><span class="err">‚Ä¶</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13"></a>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14"></a><span class="w">    </span><span class="c1">// Transfer C from device to host</span>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16"></a><span class="w">    </span><span class="c1">// Free device memory for A, B, C</span>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17"></a><span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">A_d</span><span class="p">);</span><span class="w"> </span>
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18"></a><span class="w">        </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">B_d</span><span class="p">);</span><span class="w"> </span>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19"></a><span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">C_d</span><span class="p">);</span>
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>Simple strategy of <strong>Parallel Vector Addition</strong>: assign one GPU <strong>thread</strong> per vector element</p>
<h4 id="launching-a-grid">Launching a Grid<a class="headerlink" href="#launching-a-grid" title="Permanent link">&para;</a></h4>
<p>Threads in the same grid execute the same function known as a <strong>kernel</strong></p>
<p>A grid can be launched by calling a kernel and configuring it with appropriate grid and block sizes:</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1">1</a></span>
<span class="normal"><a href="#__codelineno-6-2">2</a></span>
<span class="normal"><a href="#__codelineno-6-3">3</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">512</span><span class="p">;</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2"></a><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">numBlocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="o">/</span><span class="n">numThreadsPerBlock</span><span class="p">;</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3"></a><span class="n">vecAddKernel</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="n">numBlocks</span><span class="p">,</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<p>If n is not a multiple of <code>numThreadsPerBlock</code>, fewer threads will be launched than desired</p>
<ul>
<li>Solution: use the ceiling to launch extra threads then omit the threads after the boundary:</li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="n">vecAddKernel</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="n">ceil</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mf">256.0</span><span class="p">),</span><span class="w"> </span><span class="mi">256</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<p><strong>More Ways to Compute Grid Dimensions</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-8-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-8-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-8-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-8-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-8-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-8-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-8-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-8-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-8-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-8-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="c1">// Example #1</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2"></a><span class="n">dim3</span><span class="w"> </span><span class="nf">DimGrid</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="n">numThreadsPerBlock</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">DimGrid</span><span class="p">.</span><span class="n">x</span><span class="o">++</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4"></a><span class="n">dim3</span><span class="w"> </span><span class="n">DimBlock</span><span class="p">(</span><span class="n">numThreadsPerBlock</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5"></a><span class="n">vecAddKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">DimGrid</span><span class="p">,</span><span class="w"> </span><span class="n">DimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6"></a>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7"></a><span class="c1">// Example #2</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8"></a><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">numBlocks</span><span class="p">;</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9"></a><span class="n">numBlocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">numThreadsPerBlock</span><span class="p">;</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10"></a><span class="n">vecAddKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">numBlocks</span><span class="p">,</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="vector-addition-kernel">Vector Addition Kernel<a class="headerlink" href="#vector-addition-kernel" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-9-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-9-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-9-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-9-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-9-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-9-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-9-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-9-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-9-10">10</a></span>
<span class="normal"><a href="#__codelineno-9-11">11</a></span>
<span class="normal"><a href="#__codelineno-9-12">12</a></span>
<span class="normal"><a href="#__codelineno-9-13">13</a></span>
<span class="normal"><a href="#__codelineno-9-14">14</a></span>
<span class="normal"><a href="#__codelineno-9-15">15</a></span>
<span class="normal"><a href="#__codelineno-9-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="c1">// Compute vector sum C = A+B</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2"></a><span class="c1">// Each thread performs one pair-wise addition</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3"></a><span class="n">__global__</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="n">vecAddKernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5"></a><span class="p">{</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="o">&lt;</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">C_d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A_d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B_d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8"></a><span class="p">}</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9"></a><span class="kt">int</span><span class="w"> </span><span class="n">vecAdd</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10"></a><span class="p">{</span>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11"></a><span class="w">    </span><span class="c1">// A_d, B_d, C_d allocations and copies omitted </span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12"></a><span class="w">    </span><span class="c1">// Run ceil(n/256) blocks of 256 threads each</span>
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13"></a><span class="w">    </span><span class="n">dim3</span><span class="w"> </span><span class="nf">DimGrid</span><span class="p">(</span><span class="n">ceil</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14"></a><span class="w">    </span><span class="n">dim3</span><span class="w"> </span><span class="nf">DimBlock</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15"></a><span class="w">    </span><span class="n">vecAddKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">DimGrid</span><span class="p">,</span><span class="n">DimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A_d</span><span class="p">,</span><span class="w"> </span><span class="n">B_d</span><span class="p">,</span><span class="w"> </span><span class="n">C_d</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li><code>DimBlock</code>: number of threads in a block</li>
<li><code>DimGrid</code>: number of blocks in a grid</li>
</ul>
<p><img src="./assets/image-20250828222306765.png" alt="image-20250828222306765" style="zoom:40%;" /></p>
<h3 id="compiling-a-cuda-program">Compiling A CUDA Program<a class="headerlink" href="#compiling-a-cuda-program" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250828222359260.png" alt="image-20250828222359260" style="zoom:40%;" /></p>
<h4 id="function-declarations-in-cuda">Function Declarations in CUDA<a class="headerlink" href="#function-declarations-in-cuda" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250828102908799.png" alt="image-20250828102908799" style="zoom:50%;" /></p>
<p><code>__global__</code> defines a kernel function</p>
<p><code>__device__</code> and <code>__host__</code> can be used together</p>
<h4 id="more-on-function-declarations">More on Function Declarations<a class="headerlink" href="#more-on-function-declarations" title="Permanent link">&para;</a></h4>
<p>The keyword <code>__host__</code> is useful when needing to mark a function as executable on both the host and the device</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-10-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-10-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-10-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-10-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-10-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-10-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-10-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-10-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-10-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-10-10">10</a></span>
<span class="normal"><a href="#__codelineno-10-11">11</a></span>
<span class="normal"><a href="#__codelineno-10-12">12</a></span>
<span class="normal"><a href="#__codelineno-10-13">13</a></span>
<span class="normal"><a href="#__codelineno-10-14">14</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">;</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3"></a><span class="p">}</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4"></a><span class="kt">void</span><span class="w"> </span><span class="n">vecadd</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5"></a><span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6"></a><span class="w">        </span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8"></a><span class="p">}</span>
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">vecadd_kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-10-12"><a id="__codelineno-10-12" name="__codelineno-10-12"></a><span class="w">        </span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span><span id="__span-10-13"><a id="__codelineno-10-13" name="__codelineno-10-13"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-10-14"><a id="__codelineno-10-14" name="__codelineno-10-14"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="asynchronous-kernel-calls">Asynchronous Kernel Calls<a class="headerlink" href="#asynchronous-kernel-calls" title="Permanent link">&para;</a></h4>
<p>By default, kernel calls are <strong>asynchronous</strong> ÂºÇÊ≠•</p>
<ul>
<li>Useful for overlapping GPU computations with CPU computations</li>
</ul>
<p>Use the following API function to wait for the kernel to finish</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-11-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="n">cudaError_t</span><span class="w"> </span><span class="n">cudaDeviceSynchronize</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>Blocks until the device has completed all preceding requested tasks</li>
</ul>
<h4 id="error-checking">Error Checking<a class="headerlink" href="#error-checking" title="Permanent link">&para;</a></h4>
<p>All CUDA API calls return an error code <code>cudaError_t</code> that can be used to check if any errors occurred</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-12-1">1</a></span>
<span class="normal"><a href="#__codelineno-12-2">2</a></span>
<span class="normal"><a href="#__codelineno-12-3">3</a></span>
<span class="normal"><a href="#__codelineno-12-4">4</a></span>
<span class="normal"><a href="#__codelineno-12-5">5</a></span>
<span class="normal"><a href="#__codelineno-12-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1"></a><span class="n">cudaError_t</span><span class="w"> </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">err</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3"></a><span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Error: %s</span><span class="se">\n</span><span class="s">&quot;</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4"></a><span class="w">           </span><span class="p">,</span><span class="w"> </span><span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">err</span><span class="p">));</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5"></a><span class="w">    </span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>For kernel calls, one can check the error returned by <code>cudaDeviceSynchronize()</code> or call the following API function:<code>cudaError_t cudaGetLastError()</code></p>
<h3 id="problems">Problems<a class="headerlink" href="#problems" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250828223539044.png" alt="image-20250828223539044" style="zoom: 33%;" /></p>
<p><img src="./assets/image-20250828223600508.png" alt="image-20250828223600508" style="zoom: 33%;" /></p>
<p><img src="./assets/image-20250828223617074.png" alt="image-20250828223617074" style="zoom: 33%;" /></p>
<h2 id="3-cuda-parallel-execution-model-multidimensional-grids-data">3 CUDA Parallel Execution Model: Multidimensional Grids &amp; Data<a class="headerlink" href="#3-cuda-parallel-execution-model-multidimensional-grids-data" title="Permanent link">&para;</a></h2>
<h3 id="cuda-thread-grids-are-multi-dimensional">CUDA Thread Grids are Multi-Dimensional<a class="headerlink" href="#cuda-thread-grids-are-multi-dimensional" title="Permanent link">&para;</a></h3>
<p>CUDA supports multidimensional grids (<mark>up to 3D</mark>)</p>
<p>Each CUDA kernel is executed by a grid,</p>
<ul>
<li>a 3D array of thread blocks, which are 3D arrays of threads.</li>
<li>Each thread executes the same program on distinct data inputs, a <strong>single-program, multiple-data (SPMD) model</strong></li>
</ul>
<p><strong>Â§ßÂ∞èÂÖ≥Á≥ªÔºöGrid - block - warp - thread</strong></p>
<ul>
<li><code>gridDim</code> - <code>blockIdx</code> - <code>threadIdx</code></li>
</ul>
<p><img src="./assets/image-20250902094030975.png" alt="image-20250902094030975" style="zoom:25%;" /></p>
<p><img src="./assets/image-20250902094119251.png" alt="image-20250902094119251" style="zoom:25%;" /></p>
<ul>
<li>Thread block and thread organization <strong>simplifies memory addressing</strong> when processing multidimensional data</li>
</ul>
<h4 id="one-dimensional-indexing">One Dimensional Indexing<a class="headerlink" href="#one-dimensional-indexing" title="Permanent link">&para;</a></h4>
<p>Defining a working set for a thread</p>
<ul>
<li><code>i = blockIdx.x * blockDim.x + threadIdx.x;</code></li>
<li><img src="./assets/image-20250902094513248.png" alt="image-20250902094513248" style="zoom:25%;" /></li>
</ul>
<h4 id="multidimensional-indexing">Multidimensional Indexing<a class="headerlink" href="#multidimensional-indexing" title="Permanent link">&para;</a></h4>
<p>Defining a working set for a thread</p>
<ul>
<li><code>row = blockIdx.y * blockDim.y + threadIdx.y;</code></li>
<li><code>col = blockIdx.x * blockDim.x + threadIdx.x;</code></li>
<li><img src="./assets/image-20250902094812094.png" alt="image-20250902094812094" style="zoom:25%;" /></li>
</ul>
<h3 id="configuring-multidimensional-grids">Configuring Multidimensional Grids<a class="headerlink" href="#configuring-multidimensional-grids" title="Permanent link">&para;</a></h3>
<h4 id="use-built-in-dim3-type">Use built-in <code>dim3</code> type<a class="headerlink" href="#use-built-in-dim3-type" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-13-1">1</a></span>
<span class="normal"><a href="#__codelineno-13-2">2</a></span>
<span class="normal"><a href="#__codelineno-13-3">3</a></span>
<span class="normal"><a href="#__codelineno-13-4">4</a></span>
<span class="normal"><a href="#__codelineno-13-5">5</a></span>
<span class="normal"><a href="#__codelineno-13-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="n">dim3</span><span class="w"> </span><span class="nf">numThreadsPerBlock</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">);</span><span class="w"> </span><span class="c1">// 2D</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2"></a><span class="n">dim3</span><span class="w"> </span><span class="n">numBlocks</span><span class="p">(</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3"></a><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="p">.</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4"></a><span class="p">(</span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="p">);</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5"></a>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6"></a><span class="n">kernel</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="n">numBlocks</span><span class="p">,</span><span class="w"> </span><span class="n">numThreadsPerBlock</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="p">(</span><span class="err">‚Ä¶</span><span class="n">kernel</span><span class="w"> </span><span class="n">args</span><span class="err">‚Ä¶</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="layout-of-multidimensional-data">Layout of Multidimensional Data<a class="headerlink" href="#layout-of-multidimensional-data" title="Permanent link">&para;</a></h4>
<ul>
<li>Convention is C is to store data in <strong>row</strong> major order</li>
<li>Elements in the <strong>same row</strong> are <strong>contiguous</strong> in memory</li>
<li><code>index = row * width + col</code></li>
</ul>
<h4 id="rgb-to-gray-scale-kernel-implementation">RGB to Gray-Scale Kernel Implementation<a class="headerlink" href="#rgb-to-gray-scale-kernel-implementation" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-14-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-14-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-14-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-14-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-14-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-14-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-14-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-14-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-14-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-14-10">10</a></span>
<span class="normal"><a href="#__codelineno-14-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1"></a><span class="n">__global__</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2"></a><span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">rgb2gray_kernel</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">red</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">green</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">blue</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">gray</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3"></a><span class="p">{</span>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6"></a>
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7"></a><span class="w">  </span><span class="c1">// Convert the pixel</span>
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9"></a><span class="w">    </span><span class="n">gray</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">red</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="o">/</span><span class="mi">10</span>
</span><span id="__span-14-10"><a id="__codelineno-14-10" name="__codelineno-14-10"></a><span class="w">      </span><span class="o">+</span><span class="w"> </span><span class="n">green</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="o">*</span><span class="mi">6</span><span class="o">/</span><span class="mi">10</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blue</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">;}</span>
</span><span id="__span-14-11"><a id="__codelineno-14-11" name="__codelineno-14-11"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="blur-kernel-implementation">Blur Kernel Implementation<a class="headerlink" href="#blur-kernel-implementation" title="Permanent link">&para;</a></h4>
<p>Output pixel is the average of the corresponding input pixel and the pixels around it</p>
<p><strong>Parallelization approach</strong>: assign one thread to each output pixel, and have it read multiple input pixels</p>
<ul>
<li>Given two N √ó N matrices, A and B, we can multiply A by B to compute a third N √ó N matrix, P: P = AB</li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-15-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-15-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-15-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-15-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-15-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-15-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-15-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-15-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-15-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-15-10">10</a></span>
<span class="normal"><a href="#__codelineno-15-11">11</a></span>
<span class="normal"><a href="#__codelineno-15-12">12</a></span>
<span class="normal"><a href="#__codelineno-15-13">13</a></span>
<span class="normal"><a href="#__codelineno-15-14">14</a></span>
<span class="normal"><a href="#__codelineno-15-15">15</a></span>
<span class="normal"><a href="#__codelineno-15-16">16</a></span>
<span class="normal"><a href="#__codelineno-15-17">17</a></span>
<span class="normal"><a href="#__codelineno-15-18">18</a></span>
<span class="normal"><a href="#__codelineno-15-19">19</a></span>
<span class="normal"><a href="#__codelineno-15-20">20</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">blur_kernel</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">blurred</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2"></a><span class="w">                            </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3"></a><span class="p">{</span>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">outRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">outCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">outRow</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">outCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7"></a><span class="w">  </span><span class="p">{</span>
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8"></a><span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">average</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9"></a><span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">inRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outRow</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">BLUR_SIZE</span><span class="p">;</span><span class="w"> </span><span class="n">inRow</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">outRow</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">BLUR_SIZE</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">inRow</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-15-10"><a id="__codelineno-15-10" name="__codelineno-15-10"></a><span class="w">      </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outCol</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">BLUR_SIZE</span><span class="p">;</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">outCol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">BLUR_SIZE</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">inCol</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-15-11"><a id="__codelineno-15-11" name="__codelineno-15-11"></a><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inRow</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inRow</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// add this to deal with boundary conditions</span>
</span><span id="__span-15-12"><a id="__codelineno-15-12" name="__codelineno-15-12"></a>
</span><span id="__span-15-13"><a id="__codelineno-15-13" name="__codelineno-15-13"></a><span class="n">average</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">image</span><span class="p">[</span><span class="n">inRow</span><span class="o">*</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">inCol</span><span class="p">];</span>
</span><span id="__span-15-14"><a id="__codelineno-15-14" name="__codelineno-15-14"></a><span class="w">                </span><span class="p">}</span>
</span><span id="__span-15-15"><a id="__codelineno-15-15" name="__codelineno-15-15"></a><span class="w">      </span><span class="p">}</span>
</span><span id="__span-15-16"><a id="__codelineno-15-16" name="__codelineno-15-16"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-15-17"><a id="__codelineno-15-17" name="__codelineno-15-17"></a><span class="w">    </span><span class="n">blurred</span><span class="p">[</span><span class="n">outRow</span><span class="o">*</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">outCol</span><span class="p">]</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-15-18"><a id="__codelineno-15-18" name="__codelineno-15-18"></a><span class="w">      </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="p">)(</span><span class="n">average</span><span class="o">/</span><span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">BLUR_SIZE</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">BLUR_SIZE</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)));</span>
</span><span id="__span-15-19"><a id="__codelineno-15-19" name="__codelineno-15-19"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-15-20"><a id="__codelineno-15-20" name="__codelineno-15-20"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<blockquote>
<p>[!NOTE]</p>
<p><strong>Rule of thumb:</strong> every memory access must have a corresponding guard that compares its indexes to the array dimensions</p>
</blockquote>
<h3 id="matrix-matrix-multiplication">Matrix-Matrix Multiplication<a class="headerlink" href="#matrix-matrix-multiplication" title="Permanent link">&para;</a></h3>
<p>Given two N √ó N matrices, A and B, we can multiply A by B to compute a third N √ó N matrix, P: <span class="arithmatex">\(P = AB\)</span></p>
<ul>
<li><img src="./assets/image-20250902144507954.png" alt="image-20250902144507954" style="zoom:25%;" />Áü©ÈòµÁõ∏‰πòÔºå‰∏ÄË°å‚úñÔ∏è‰∏ÄÂàó</li>
<li><strong>Parallelization approach</strong>: assign one thread to each element in the output matrix (C)</li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-16-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-16-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-16-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-16-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-16-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-16-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-16-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-16-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-16-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-16-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">mm_kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2"></a><span class="p">{</span>
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-16-6"><a id="__codelineno-16-6" name="__codelineno-16-6"></a><span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-16-7"><a id="__codelineno-16-7" name="__codelineno-16-7"></a><span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-16-8"><a id="__codelineno-16-8" name="__codelineno-16-8"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-16-9"><a id="__codelineno-16-9" name="__codelineno-16-9"></a><span class="w">  </span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span><span id="__span-16-10"><a id="__codelineno-16-10" name="__codelineno-16-10"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h2 id="4-compute-architecture-and-scheduling">4 Compute Architecture and Scheduling<a class="headerlink" href="#4-compute-architecture-and-scheduling" title="Permanent link">&para;</a></h2>
<h3 id="executing-thread-blocks">Executing Thread Blocks<a class="headerlink" href="#executing-thread-blocks" title="Permanent link">&para;</a></h3>
<p>Threads are assigned to <strong>Streaming Multiprocessors</strong> in block granularity ÂùóÁ≤íÂ∫¶ÁöÑÊµÅÂ§öÂ§ÑÁêÜÂô®</p>
<ul>
<li>Up to <strong>32</strong> blocks to each SM</li>
<li>SMs can take up to <strong>2048</strong> threads</li>
</ul>
<p>Threads run concurrently Âπ∂Ë°å</p>
<ul>
<li>SM maintains thread/block id #s</li>
<li>SM manages/schedules thread execution</li>
</ul>
<h4 id="gpu-architecture">GPU Architecture<a class="headerlink" href="#gpu-architecture" title="Permanent link">&para;</a></h4>
<p>A GPU consists of <strong>multiple Streaming Multiprocessor (SMs)</strong>, each consisting of multiple cores with <em>shared control and memory</em></p>
<p><img src="./assets/image-20250904094714370.png" alt="image-20250904094714370" style="zoom:25%;" /></p>
<h4 id="assigning-blocks-to-sms">Assigning Blocks to SMs<a class="headerlink" href="#assigning-blocks-to-sms" title="Permanent link">&para;</a></h4>
<p>Threads are assigned to SMs at block granularity</p>
<ul>
<li>One/more thread to one SM</li>
<li>The remaining block wait for others to finish</li>
<li><strong>All threads in a block</strong> are assigned to the <strong>same</strong> SM</li>
</ul>
<p><img src="./assets/image-20250904100000607.png" alt="image-20250904100000607" style="zoom:25%;" /></p>
<ul>
<li><strong>All threads in a block</strong> are assigned to an SM <strong>simultaneously</strong> ÂêåÊó∂ÂàÜÈÖç<ul>
<li>A block cannot be assigned to an SM until it secures enough resources for all its threads to execute ==&gt; <em>ZERO-OVERHEAD</em></li>
<li>Otherwise, if some threads reach a barrier and others cannot execute, the system could deadlock</li>
</ul>
</li>
</ul>
<p>Threads in the <strong>same block</strong> can <strong>collaborate</strong> in ways that threads in different blocks cannot:</p>
<ul>
<li>
<p>Lightweight barrier synchronization: <code>__syncthreads()</code></p>
<ul>
<li>Wait for all threads in the block to reach the barrier before any thread can proceed</li>
</ul>
</li>
<li>
<p>Shared memory (discussed later)</p>
<ul>
<li>Access a fast memory that <strong>only threads in the same block can access</strong></li>
</ul>
</li>
<li>
<p>Others (discussed later)</p>
</li>
</ul>
<h4 id="synchronization-across-thread-blocks">Synchronization across Thread Blocks<a class="headerlink" href="#synchronization-across-thread-blocks" title="Permanent link">&para;</a></h4>
<p>If threads in different blocks <strong>do not synchronize</strong> with each other</p>
<ul>
<li>Blocks can execute in any order</li>
<li>Blocks can execute both in parallel with each other or sequentially with respect to each other</li>
<li>Enables <strong>transparent scalability</strong> ÈÄèÊòéÁöÑÂèØÊãìÂ±ïÊÄß<ul>
<li>Same code can run on different devices with different amounts of hardware parallelism</li>
<li>Execute blocks sequentially if device has few SMs</li>
<li>Execute blocks in parallel if device has many SMs</li>
</ul>
</li>
</ul>
<p>If threads in different blocks to <strong>synchronize</strong> with each other</p>
<ul>
<li>Deadlock may occur if the synchronizing blocks are not scheduled simultaneously</li>
<li>
<p><strong>Cooperative groups</strong> Âêà‰ΩúÁªÑ (covered later) allows <em>barrier synchronization</em> across clusters of thread blocks, or across the entire grid by limiting the number of blocks to guarantee that all blocks are executing simultaneously</p>
</li>
<li>
<p>Other techniques (covered later) allow <strong>unidirectional synchronization</strong> Èó¥Êé•ÂêåÊ≠• by ensuring that the producer block is scheduled before the consumer block</p>
</li>
</ul>
<h3 id="sm-scheduling">SM Scheduling<a class="headerlink" href="#sm-scheduling" title="Permanent link">&para;</a></h3>
<p>Blocks assigned to an SM are further divided into <strong>warps</strong> which are <em>the unit of scheduling</em></p>
<ul>
<li>The SM cores are organized into <strong>processing blocks</strong> Â§ÑÁêÜÂø´, with each processing block having its own warp scheduler to execute multiple warps concurrently</li>
</ul>
<h4 id="warps">Warps<a class="headerlink" href="#warps" title="Permanent link">&para;</a></h4>
<p>The size of warps is device-specific, but has always been 32 threads to date</p>
<p>Threads in a warp are scheduled together on a processing block and executed following the <strong>SIMD model</strong> ÂçïÊåá‰ª§Â§öÊï∞ÊçÆÊ®°Âûã</p>
<ul>
<li><u>S</u>ingle <u>I</u>nstruction, <u>M</u>ultiple <u>D</u>ata</li>
<li>One instruction is fetched and executed by all the threads in the warp, each processing different data</li>
<li>All threads ina warp execute the same instruction</li>
</ul>
<h4 id="thread-scheduling">Thread Scheduling<a class="headerlink" href="#thread-scheduling" title="Permanent link">&para;</a></h4>
<p>Each block is executed as <strong>32-thread warps</strong></p>
<p><img src="./assets/image-20250904101235227.png" alt="image-20250904101235227" style="zoom:33%;" /></p>
<p>SM ÂÆûÁé∞Èõ∂ÂºÄÈîÄ Warp Ë∞ÉÂ∫¶</p>
<p><img src="./assets/image-20250904101541283.png" alt="image-20250904101541283" style="zoom:33%;" /></p>
<p>Pitfalls: not divisible by 32, other threads idle</p>
<p><strong>Why SIMD?</strong></p>
<blockquote>
<p><strong>Advantage</strong></p>
<ul>
<li>Share the same instruction fetch/dispatch unit across multiple execution units (cores)</li>
</ul>
<p><strong>Disadvantage</strong></p>
<ul>
<li>
<p>Different threads taking different execution paths result in <strong>control divergence</strong></p>
<ul>
<li>Warp does a pass over each unique execution path</li>
<li>In each pass, threads taking the path execute while others are disabled</li>
</ul>
</li>
<li>
<p>The percentage of threads/cores enabled during SIMD execution is called the <strong>SIMD efficiency</strong></p>
</li>
</ul>
</blockquote>
<h4 id="control-divergence">Control Divergence<a class="headerlink" href="#control-divergence" title="Permanent link">&para;</a></h4>
<p>Control Divergence Example</p>
<p><img src="./assets/image-20250904102710933.png" alt="image-20250904102710933" style="zoom: 33%;" /></p>
<p><img src="./assets/image-20250912173030953.png" alt="image-20250912173030953" style="zoom:33%;" /></p>
<blockquote>
<p>[!NOTE]</p>
<p><strong>What is Control Divergence?</strong></p>
<p>On a GPU, a <strong>warp</strong> (a group of 32 threads) is a fundamental execution unit. All 32 threads in a warp execute the same instruction at the same time.</p>
<p><strong>Control divergence</strong> occurs when threads within a single warp encounter a conditional statement (like an <code>if-else</code> block) and disagree on which path to take. IfÊù°‰ª∂‰∏≠Êúâ<code>threadIdx</code>Áõ∏ÂÖ≥ÂèòÈáèÂ∞±ÂèØËÉΩ‰ºö‰∫ßÁîüÊéßÂà∂ÂèëÊï£</p>
<ul>
<li>Some threads evaluate the condition to <code>true</code>.</li>
<li>Others evaluate it to <code>false</code>.</li>
</ul>
<p>The hardware handles this by running both paths sequentially: first, the <code>true</code> path is executed by the corresponding threads while the others are idle, and then the <code>false</code> path is executed by its threads while the first group is idle. This serialization is a performance penalty. ü§∑‚Äç‚ôÄÔ∏è</p>
</blockquote>
<h4 id="avoiding-branch-divergence">Avoiding Branch Divergence<a class="headerlink" href="#avoiding-branch-divergence" title="Permanent link">&para;</a></h4>
<p>Try to <strong>make branch granularity a multiple of warp size</strong> (remember, it <em>may not always be 32</em>!)</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-17-1">1</a></span>
<span class="normal"><a href="#__codelineno-17-2">2</a></span>
<span class="normal"><a href="#__codelineno-17-3">3</a></span>
<span class="normal"><a href="#__codelineno-17-4">4</a></span>
<span class="normal"><a href="#__codelineno-17-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2"></a><span class="c1">// THEN path (lots of lines)</span>
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3"></a><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4"></a><span class="c1">// ELSE path (lots of lines)</span>
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>Still has two control paths</li>
<li>But all threads in any warp follow only one path</li>
</ul>
<h4 id="lantency-hiding">Lantency hiding Âª∂ËøüÈöêËóè<a class="headerlink" href="#lantency-hiding" title="Permanent link">&para;</a></h4>
<p>When a warp needs to wait for a high latency operation, another warp that is ready is selected and scheduled for execution</p>
<p><img src="./assets/image-20250909092742286.png" alt="image-20250909092742286" style="zoom:25%;" /></p>
<p>Many warps are needed so that there is sufficient work available to hide long latency operations, i.e., there is high chance of finding a warp that is ready</p>
<p>For this reason, <em>an SM typically supports many more threads than the number of cores</em> it has -- Max threads per SM is much higher than cores per SM</p>
<h4 id="occupancy">Occupancy<a class="headerlink" href="#occupancy" title="Permanent link">&para;</a></h4>
<p>The <strong>occupancy</strong> Âç†Áî®Áéá of an SM refers to the ratio of the warps or threads active on the SM to the maximum allowed</p>
<p>In general, maximizing occupancy is desirable because it improves latency hiding</p>
<ul>
<li>Common case, but possible to have cases where lower occupancy is desirable</li>
</ul>
<p>Occupancy Example</p>
<p><img src="./assets/image-20250909091357699.png" alt="image-20250909091357699" style="zoom: 50%;" /></p>
<h4 id="block-granularity-considerations">Block Granularity Considerations<a class="headerlink" href="#block-granularity-considerations" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250912182406187.png" alt="image-20250912182406187" style="zoom: 50%;" /></p>
<h3 id="problem-solving">Problem solving<a class="headerlink" href="#problem-solving" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250912182705088.png" alt="image-20250912182705088" style="zoom: 40%;" /></p>
<p><img src="./assets/image-20250912182557010.png" alt="image-20250912182557010" style="zoom:40%;" /></p>
<p><img src="./assets/image-20250912182621756.png" alt="image-20250912182621756" style="zoom:40%;" /></p>
<h2 id="5-cuda-memory-model">5 CUDA Memory Model<a class="headerlink" href="#5-cuda-memory-model" title="Permanent link">&para;</a></h2>
<h3 id="the-von-neumann-model">The Von-Neumann Model ÂÜØËØ∫‰æùÊõº<a class="headerlink" href="#the-von-neumann-model" title="Permanent link">&para;</a></h3>
<p>Processing Unit (PU)</p>
<ul>
<li>Performs all arithmetic and logical operations</li>
<li>Includes the <strong>Register File</strong>, where data is temporarily stored for processing</li>
</ul>
<p>Memory</p>
<ul>
<li>Stores both program instructions and data</li>
</ul>
<p>Input/Output (I/O) Subsystem</p>
<ul>
<li>Handles communication between the computer and the external environment</li>
</ul>
<p>Control Unit (CU)</p>
<ul>
<li>Directs the execution of instructions by coordinating all components</li>
</ul>
<p>All operations are performed on data stored in <strong>registers</strong> within the Processing Unit. Before any calculation:</p>
<ul>
<li>Data must be fetched from Memory into registers, and Instructions must be loaded from Memory into the Instruction Register (IR)</li>
</ul>
<p><img src="./assets/image-20250909094006962.png" alt="image-20250909094006962" style="zoom:25%;" /></p>
<p>Instruction processing breaks into steps: <strong>Fetch | Decode | Execute | Memory</strong></p>
<p>Instructions come in three flavors: Operate, Data Transfer, and Control Flow</p>
<p>ADD instruction</p>
<p>LOAD instruction</p>
<h3 id="programmers-view-of-cuda-memories">Programmer‚Äôs View of CUDA Memories<a class="headerlink" href="#programmers-view-of-cuda-memories" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251005202750869.png" alt="image-20251005202750869" style="zoom:50%;" /></p>
<h3 id="registers-vs-memory">Registers vs Memory<a class="headerlink" href="#registers-vs-memory" title="Permanent link">&para;</a></h3>
<p>Registers</p>
<ul>
<li>Fast: 1 cycle; no memory access required</li>
<li>Few: hundreds for CPU, O(10k) for GPU SM</li>
</ul>
<p>Memory</p>
<ul>
<li>Slow: hundreds of cycles</li>
<li>Huge: GB or more</li>
</ul>
<p><img alt="image-20250909095244547" src="assets/image-20250909095244547.png" /></p>
<p>Matrix Multiplication Áü©Èòµ‰πòÊ≥ïÔºöA Simple Host Version in C</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-18-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-18-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-18-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-18-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-18-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-18-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-18-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-18-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-18-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-18-10">10</a></span>
<span class="normal"><a href="#__codelineno-18-11">11</a></span>
<span class="normal"><a href="#__codelineno-18-12">12</a></span>
<span class="normal"><a href="#__codelineno-18-13">13</a></span>
<span class="normal"><a href="#__codelineno-18-14">14</a></span>
<span class="normal"><a href="#__codelineno-18-15">15</a></span>
<span class="normal"><a href="#__codelineno-18-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1"></a><span class="c1">// Matrix multiplication on the (CPU) host</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2"></a><span class="kt">void</span><span class="w"> </span><span class="nf">MatrixMul</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span>
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3"></a><span class="p">{</span><span class="w"> </span>
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">j</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6"></a><span class="w">    </span><span class="p">{</span>
</span><span id="__span-18-7"><a id="__codelineno-18-7" name="__codelineno-18-7"></a><span class="w">      </span><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-18-8"><a id="__codelineno-18-8" name="__codelineno-18-8"></a><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">k</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-18-9"><a id="__codelineno-18-9" name="__codelineno-18-9"></a><span class="w">      </span><span class="p">{</span>
</span><span id="__span-18-10"><a id="__codelineno-18-10" name="__codelineno-18-10"></a><span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">];</span>
</span><span id="__span-18-11"><a id="__codelineno-18-11" name="__codelineno-18-11"></a><span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">k</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">];</span>
</span><span id="__span-18-12"><a id="__codelineno-18-12" name="__codelineno-18-12"></a><span class="w">        </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">;</span>
</span><span id="__span-18-13"><a id="__codelineno-18-13" name="__codelineno-18-13"></a><span class="w">      </span><span class="p">}</span>
</span><span id="__span-18-14"><a id="__codelineno-18-14" name="__codelineno-18-14"></a><span class="w">      </span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span><span id="__span-18-15"><a id="__codelineno-18-15" name="__codelineno-18-15"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-18-16"><a id="__codelineno-18-16" name="__codelineno-18-16"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="parallelize-elements-of-p">Parallelize Elements of P<a class="headerlink" href="#parallelize-elements-of-p" title="Permanent link">&para;</a></h3>
<p>What can we parallelize?</p>
<ul>
<li>start with the <strong>two outer loops</strong></li>
<li>parallelize the <strong>computation of elements of P</strong></li>
</ul>
<h4 id="compute-using-2d-blocks-in-a-2d-grid">Compute Using 2D Blocks in a 2D Grid<a class="headerlink" href="#compute-using-2d-blocks-in-a-2d-grid" title="Permanent link">&para;</a></h4>
<p><strong>P</strong> is 2D, so organize threads in 2D as well:</p>
<p>Split the output <strong>P</strong> into square tiles of size <code>TILE_WIDTH √ó TILE_WIDTH</code>(a preprocessor constant)</p>
<p><strong>Each thread block produces one tile</strong> of TILE_WIDTH^2 elements</p>
<p>Create <strong>[ceil (Width / TILE_WIDTH)]^2</strong> thread <strong>blocks</strong> to cover the output matrix</p>
<h3 id="kernel-invocation-host-side-code">Kernel Invocation (Host-side Code)<a class="headerlink" href="#kernel-invocation-host-side-code" title="Permanent link">&para;</a></h3>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-19-1">1</a></span>
<span class="normal"><a href="#__codelineno-19-2">2</a></span>
<span class="normal"><a href="#__codelineno-19-3">3</a></span>
<span class="normal"><a href="#__codelineno-19-4">4</a></span>
<span class="normal"><a href="#__codelineno-19-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1"></a><span class="c1">// TILE_WIDTH is a #define constant</span>
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2"></a><span class="n">dim3</span><span class="w"> </span><span class="n">dimGrid</span><span class="p">(</span><span class="n">ceil</span><span class="p">((</span><span class="mf">1.0</span><span class="o">*</span><span class="n">Width</span><span class="p">)</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">),</span><span class="w"> </span><span class="n">ceil</span><span class="p">((</span><span class="mf">1.0</span><span class="o">*</span><span class="n">Width</span><span class="p">)</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3"></a><span class="n">dim3</span><span class="w"> </span><span class="nf">dimBlock</span><span class="p">(</span><span class="n">TILE_WIDTH</span><span class="p">,</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4"></a><span class="c1">// Launch the device computation threads!</span>
</span><span id="__span-19-5"><a id="__codelineno-19-5" name="__codelineno-19-5"></a><span class="n">MatrixMulKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="w"> </span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">Md</span><span class="p">,</span><span class="w"> </span><span class="n">Nd</span><span class="p">,</span><span class="w"> </span><span class="n">Pd</span><span class="p">,</span><span class="w"> </span><span class="n">Width</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="kernel-function">Kernel Function<a class="headerlink" href="#kernel-function" title="Permanent link">&para;</a></h3>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-20-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-20-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-20-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-20-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-20-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-20-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-20-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-20-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-20-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-20-10">10</a></span>
<span class="normal"><a href="#__codelineno-20-11">11</a></span>
<span class="normal"><a href="#__codelineno-20-12">12</a></span>
<span class="normal"><a href="#__codelineno-20-13">13</a></span>
<span class="normal"><a href="#__codelineno-20-14">14</a></span>
<span class="normal"><a href="#__codelineno-20-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1"></a><span class="c1">// Matrix multiplication kernel ‚Äì per thread code</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2"></a><span class="n">__global__</span><span class="w"> </span>
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3"></a><span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">MatrixMulKernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_M</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_P</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span>
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4"></a><span class="p">{</span>
</span><span id="__span-20-5"><a id="__codelineno-20-5" name="__codelineno-20-5"></a><span class="w">  </span><span class="c1">// Calculate the row index of the d_P element and d_M</span>
</span><span id="__span-20-6"><a id="__codelineno-20-6" name="__codelineno-20-6"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-20-7"><a id="__codelineno-20-7" name="__codelineno-20-7"></a><span class="w">  </span><span class="c1">// Calculate the column idenx of d_P and d_N</span>
</span><span id="__span-20-8"><a id="__codelineno-20-8" name="__codelineno-20-8"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-20-9"><a id="__codelineno-20-9" name="__codelineno-20-9"></a><span class="w">  </span><span class="c1">// Pvalue is used to store the element of the matrix</span>
</span><span id="__span-20-10"><a id="__codelineno-20-10" name="__codelineno-20-10"></a><span class="w">  </span><span class="c1">// that is computed by the thread</span>
</span><span id="__span-20-11"><a id="__codelineno-20-11" name="__codelineno-20-11"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-20-12"><a id="__codelineno-20-12" name="__codelineno-20-12"></a><span class="w">        </span><span class="p">...</span>
</span><span id="__span-20-13"><a id="__codelineno-20-13" name="__codelineno-20-13"></a><span class="w">    </span><span class="p">...</span>
</span><span id="__span-20-14"><a id="__codelineno-20-14" name="__codelineno-20-14"></a><span class="w">    </span><span class="n">d_P</span><span class="p">[</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-20-15"><a id="__codelineno-20-15" name="__codelineno-20-15"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p><img src="./assets/image-20251005210446452.png" alt="image-20251005210446452" style="zoom:50%;" /></p>
<h4 id="matrix-multiplication-kernel">Matrix Multiplication Kernel<a class="headerlink" href="#matrix-multiplication-kernel" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-21-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-21-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-21-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-21-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-21-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-21-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-21-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-21-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-21-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-21-10">10</a></span>
<span class="normal"><a href="#__codelineno-21-11">11</a></span>
<span class="normal"><a href="#__codelineno-21-12">12</a></span>
<span class="normal"><a href="#__codelineno-21-13">13</a></span>
<span class="normal"><a href="#__codelineno-21-14">14</a></span>
<span class="normal"><a href="#__codelineno-21-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1"></a><span class="n">__global__</span><span class="w"> </span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2"></a><span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">MatrixMulKernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_M</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_P</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3"></a><span class="p">{</span>
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4"></a><span class="w">  </span><span class="c1">// Calculate the row index of the d_P element and d_M</span>
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="o">+</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-21-6"><a id="__codelineno-21-6" name="__codelineno-21-6"></a><span class="w">  </span><span class="c1">// Calculate the column idenx of d_P and d_N</span>
</span><span id="__span-21-7"><a id="__codelineno-21-7" name="__codelineno-21-7"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">Col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-21-8"><a id="__codelineno-21-8" name="__codelineno-21-8"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="n">Row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">Col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-21-9"><a id="__codelineno-21-9" name="__codelineno-21-9"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-21-10"><a id="__codelineno-21-10" name="__codelineno-21-10"></a><span class="w">    </span><span class="c1">// each thread computes one element of the block sub-matrix</span>
</span><span id="__span-21-11"><a id="__codelineno-21-11" name="__codelineno-21-11"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">k</span><span class="p">)</span>
</span><span id="__span-21-12"><a id="__codelineno-21-12" name="__codelineno-21-12"></a><span class="w">      </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">d_M</span><span class="p">[</span><span class="n">Row</span><span class="o">*</span><span class="n">Width</span><span class="o">+</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">d_N</span><span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="n">Width</span><span class="o">+</span><span class="n">Col</span><span class="p">];</span>
</span><span id="__span-21-13"><a id="__codelineno-21-13" name="__codelineno-21-13"></a><span class="w">    </span><span class="n">d_P</span><span class="p">[</span><span class="n">Row</span><span class="o">*</span><span class="n">Width</span><span class="o">+</span><span class="n">Col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-21-14"><a id="__codelineno-21-14" name="__codelineno-21-14"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-21-15"><a id="__codelineno-21-15" name="__codelineno-21-15"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>Memory Bandwidth is Overloaded!</p>
<p>That‚Äôs a <strong>simple implementation</strong>:</p>
<ul>
<li>
<p>GPU kernel is the <strong>CPU code</strong> with the <strong>outer loops replaced with</strong> per-thread <strong>index calculations</strong>!</p>
</li>
<li>
<p>Unfortunately, performance is quite bad.</p>
</li>
</ul>
<p>Why?</p>
<ul>
<li>With the given approach, global <strong>memory bandwidth</strong> can‚Äôt supply enough data to <strong>keep the SMs busy</strong>!</li>
</ul>
<p><img src="./assets/image-20251005212333216.png" alt="image-20251005212333216" style="zoom: 50%;" /></p>
<p><img src="./assets/image-20251007183850576.png" alt="image-20251007183850576" style="zoom: 33%;" /></p>
<p>We should Reuse Memory Accesses</p>
<p>In an <strong>actual execution</strong>, memory is not busy all the time, and the code <strong>runs at</strong> about <strong>25 GFLOPs</strong></p>
<p>To get closer to 1,000 GFLOPs,we <strong>need to</strong> drastically <strong>cut down accesses to global memory</strong> (next lecture)</p>
<h3 id="problem-solving_1">Problem Solving<a class="headerlink" href="#problem-solving_1" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250909102403773.png" alt="image-20250909102403773" style="zoom:25%;" /></p>
<hr />
<p><img src="./assets/image-20250909102713902.png" alt="image-20250909102713902" style="zoom:25%;" /></p>
<blockquote>
<p>The answer is <strong>Either 0 or 1</strong> because of a <strong>race condition</strong>. üèÅ</p>
<p>A race condition occurs when multiple threads try to access and modify the same memory location at the same time, and the final result depends on the unpredictable order in which they execute.</p>
<ol>
<li>
<p><strong>Kernel Launch:</strong> The line <code>kernel&lt;&lt;&lt;2,1&gt;&gt;&gt;(dst);</code> launches the kernel with a grid of <strong>2 blocks</strong>, and each block contains <strong>1 thread</strong>.</p>
<ul>
<li>This creates two blocks in total: Block 0 and Block 1.</li>
<li>For Block 0, the built-in variable <code>blockIdx.x</code> is <strong>0</strong>.</li>
<li>For Block 1, the built-in variable <code>blockIdx.x</code> is <strong>1</strong>.</li>
</ul>
</li>
<li>
<p>Conflicting Writes:</p>
<p>Both threads execute the same instruction, dst[0] = blockIdx.x;, but with different values for blockIdx.x:</p>
<ul>
<li>The thread from Block 0 executes <code>dst[0] = 0;</code>.</li>
<li>The thread from Block 1 executes <code>dst[0] = 1;</code>.</li>
</ul>
</li>
<li>
<p>Unpredictable Order:</p>
<p>The CUDA programming model does not guarantee the execution order of different blocks. The GPU's scheduler might run Block 0 first, then Block 1, or vice-versa.</p>
<ul>
<li><strong>Scenario 1:</strong> Block 1's write is the last one to complete. The initial value at <code>dst[0]</code> is overwritten by <code>0</code> (from Block 0), and then finally overwritten by <strong><code>1</code></strong>.</li>
<li><strong>Scenario 2:</strong> Block 0's write is the last one to complete. The initial value is overwritten by <code>1</code> (from Block 1), and then finally overwritten by <strong><code>0</code></strong>.</li>
</ul>
</li>
</ol>
<p>Since there's no way to know which block will "win" the race to write to <code>dst[0]</code> last, the final value stored in that location after the kernel finishes could be either 0 or 1.</p>
</blockquote>
<h2 id="6-data-locality-and-tiled-matrix-multiply">6 Data Locality and Tiled Matrix Multiply<a class="headerlink" href="#6-data-locality-and-tiled-matrix-multiply" title="Permanent link">&para;</a></h2>
<h3 id="performance-metrics">Performance Metrics<a class="headerlink" href="#performance-metrics" title="Permanent link">&para;</a></h3>
<p><strong>FLOPS Rate</strong>: floating point operations per second</p>
<ul>
<li>How much computation a processor‚Äôs cores can do per unit time</li>
</ul>
<p><strong>Memory Bandwidth</strong>: bytes per second</p>
<ul>
<li>How much data the memory can supply to the cores per unit time</li>
</ul>
<p><img src="./assets/image-20250911093925332.png" alt="image-20250911093925332" style="zoom:25%;" /></p>
<ul>
<li>FLOPs rate(GLOPS/s)</li>
<li>Memory bandwidth(GB/s)</li>
</ul>
<h4 id="performance-bound-and-the-roofline-model">Performance Bound and the Roofline Model<a class="headerlink" href="#performance-bound-and-the-roofline-model" title="Permanent link">&para;</a></h4>
<p>A kernel can be:</p>
<ul>
<li><strong>Compute-bound</strong> ËÆ°ÁÆóÂèóÈôê: performance limited by the FLOPS rate<ul>
<li>The processor‚Äôs cores are fully utilized (always have work to do)</li>
</ul>
</li>
<li><strong>Memory-bound</strong> ÂÜÖÂ≠òÂèóÈôê: performance limited by the memory bandwidth<ul>
<li>The processor‚Äôs cores are frequently idle because memory cannot supply data fast enough</li>
</ul>
</li>
</ul>
<p>The <strong>roofline model</strong> helps visualize a kernel‚Äôs performance bound based on the ratio of operations it 
performs and bytes it accesses from memory</p>
<p><img src="./assets/image-20250911094055993.png" alt="image-20250911094055993" style="zoom:25%;" /></p>
<ul>
<li>ÂÖàÂèóÂÜÖÂ≠òÈôêÂà∂ÂêéÂèóCPUÈôêÂà∂</li>
<li><strong>OP/B ratio</strong>: allows us to determine if a kernel is memory-bound or compute-bound on a specific hardware Ê†πÊçÆÊØî‰æãÂà§Êñ≠Á±ªÂûã </li>
<li><em>OP/B = operations / data</em></li>
</ul>
<p>Knowing the kernel‚Äôs bound allows us to determine the best possible performance achievable by the kernel (sometimes called the <strong>speed of light</strong>)</p>
<h4 id="example">Example<a class="headerlink" href="#example" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250913220651366.png" alt="image-20250913220651366" style="zoom: 40%;" /></p>
<p><img src="./assets/image-20250913221250249.png" alt="image-20250913221250249" style="zoom:50%;" /></p>
<h3 id="a-common-programming-strategy">A Common Programming Strategy<a class="headerlink" href="#a-common-programming-strategy" title="Permanent link">&para;</a></h3>
<p><strong>Global memory</strong> is implemented with <strong>DRAM</strong>(Dynamic random-access memory) ‚Äì slow</p>
<p>Sometimes, we are lucky:</p>
<ul>
<li>The thread finds the data in the L1 cache because it was recently loaded by another thread</li>
</ul>
<p>Sometimes, we are not lucky:</p>
<ul>
<li>The data gets evicted from the L1 cache before another thread tries to load it</li>
</ul>
<p>To avoid a Global Memory bottleneck, <strong><mark>tile the input data</mark></strong> to take advantage of Shared Memory Â∞ÜËæìÂÖ•Êï∞ÊçÆÂπ≥Èì∫‰ª•Âà©Áî®ÂÖ±‰∫´ÂÜÖÂ≠òÔºö</p>
<ul>
<li><strong>Partition data into subsets</strong> (<em>tiles</em>) that fit into the (smaller but faster) shared memory</li>
<li><strong>Handle each data subset with one thread block</strong> by:<ul>
<li>Loading the subset from global memory to shared memory, <em>using multiple threads to exploit memory-level parallelism</em> Âà©Áî®ÂÜÖÂ≠òÁ∫ßÂπ∂Ë°åÊÄß</li>
<li>Performing the computation on the subset from shared memory, each thread can efficiently access any data element</li>
<li>Copying results from shared memory to global memory</li>
</ul>
</li>
<li>Tiles are also called blocks in the literature</li>
</ul>
<p><img src="./assets/image-20250911095949762.png" alt="image-20250911095949762" style="zoom:33%;" /></p>
<h4 id="tiled-multiply">Tiled Multiply<a class="headerlink" href="#tiled-multiply" title="Permanent link">&para;</a></h4>
<p>Âπ≥Èì∫Á≠ñÁï•ÔºöBreak up the execution of the kernel into phases so that the data accesses in each phase are focused on one tile of A and B</p>
<p><img src="./assets/image-20250911100629113.png" alt="image-20250911100629113" style="zoom:33%;" /></p>
<p>For each tile:</p>
<ul>
<li>
<p>Phase 1: Load tiles of A &amp; B into share memory</p>
<ul>
<li>
<p>Each thread loads one A element and one B element in basic tiling code</p>
</li>
<li>
<p>```c
    A[Row][1<em>TILE_WIDTH+tx]
    B[1</em>TILE_WIDTH+ty][Col]</p>
<p>A[Row][q<em>TILE_WIDTH+tx]
A[Row</em>Width + q*TILE_WIDTH + tx]</p>
<p>B[q<em>TILE_WIDTH+ty][Col]
B[(q</em>TILE_WIDTH+ty) * Width + Col]</p>
<p>//A and B are dynamically allocated and can only use 1D indexing
```</p>
</li>
</ul>
</li>
<li>
<p>Phase 2: Calculate partial dot product for tile of C</p>
<ul>
<li><code>c
    //To perform the kth step of the product within the tile
    subTileA[ty][k];
    subTileB[k][tx];</code></li>
</ul>
</li>
</ul>
<h4 id="tiled-matrix-matrix-multiplication">Tiled Matrix-Matrix Multiplication<a class="headerlink" href="#tiled-matrix-matrix-multiplication" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-22-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-22-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-22-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-22-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-22-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-22-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-22-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-22-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-22-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-22-10">10</a></span>
<span class="normal"><a href="#__codelineno-22-11">11</a></span>
<span class="normal"><a href="#__codelineno-22-12">12</a></span>
<span class="normal"><a href="#__codelineno-22-13">13</a></span>
<span class="normal"><a href="#__codelineno-22-14">14</a></span>
<span class="normal"><a href="#__codelineno-22-15">15</a></span>
<span class="normal"><a href="#__codelineno-22-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1"></a><span class="c1">// declare arrays in shared memory</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">TILE_DIM</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="p">];</span>
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">B_s</span><span class="p">[</span><span class="n">TILE_DIM</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="p">];</span>
</span><span id="__span-22-4"><a id="__codelineno-22-4" name="__codelineno-22-4"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-22-5"><a id="__codelineno-22-5" name="__codelineno-22-5"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-22-6"><a id="__codelineno-22-6" name="__codelineno-22-6"></a><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-22-7"><a id="__codelineno-22-7" name="__codelineno-22-7"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">tile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-22-8"><a id="__codelineno-22-8" name="__codelineno-22-8"></a><span class="w">  </span><span class="c1">// Load tile to shared memory</span>
</span><span id="__span-22-9"><a id="__codelineno-22-9" name="__codelineno-22-9"></a><span class="w">  </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-22-10"><a id="__codelineno-22-10" name="__codelineno-22-10"></a><span class="w">  </span><span class="n">B_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">[(</span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-22-11"><a id="__codelineno-22-11" name="__codelineno-22-11"></a><span class="w">  </span><span class="c1">// Compute with tile</span>
</span><span id="__span-22-12"><a id="__codelineno-22-12" name="__codelineno-22-12"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-22-13"><a id="__codelineno-22-13" name="__codelineno-22-13"></a><span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">B_s</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-22-14"><a id="__codelineno-22-14" name="__codelineno-22-14"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-22-15"><a id="__codelineno-22-15" name="__codelineno-22-15"></a><span class="p">}</span>
</span><span id="__span-22-16"><a id="__codelineno-22-16" name="__codelineno-22-16"></a><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span></code></pre></div></td></tr></table></div>
<p>code inside the tunnel</p>
<blockquote>
<p>[!IMPORTANT]</p>
<p>We need to <strong>synchronize</strong>! ÂêåÊ≠•</p>
</blockquote>
<h4 id="bulk-synchronous-steps-based-on-barriers">Bulk Synchronous Steps Based on Barriers<a class="headerlink" href="#bulk-synchronous-steps-based-on-barriers" title="Permanent link">&para;</a></h4>
<p><strong>Bulk synchronous execution</strong>: threads execute roughly in unison</p>
<ol>
<li>Do some work</li>
<li>Wait for others to catch up</li>
<li>Repeat</li>
</ol>
<p>Much easier programming model</p>
<ul>
<li>Threads only parallel within a section</li>
<li>Debug lots of little programs</li>
<li>Instead of one large one</li>
</ul>
<p>Dominates high-performance applications</p>
<p>How does it work?</p>
<ul>
<li>Use a <strong>barrier</strong> to wait for the thread to 'catch up.'</li>
</ul>
<p>A barrier is a synchronization point:</p>
<ul>
<li>each thread <em>calls a function</em> to enter the barrier;</li>
<li>threads <em>block</em> (sleep) in barrier function until all threads have called;</li>
<li><em>After the last thread</em> calls the function, all threads <em>continue</em> past the barrier.</li>
</ul>
<p><img src="./assets/image-20250911102053535.png" alt="image-20250911102053535" style="zoom:25%;" /></p>
<p><strong>API function</strong>: <code>__syncthreads()</code></p>
<p>All threads <strong>in the same block</strong> must reach the <code>__syncthreads()</code> before any can move on</p>
<ul>
<li>To ensure that all elements of a tile are loaded</li>
<li>To ensure that certain computation on elements is complete</li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-23-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-23-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-23-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-23-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-23-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-23-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-23-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-23-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-23-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-23-10">10</a></span>
<span class="normal"><a href="#__codelineno-23-11">11</a></span>
<span class="normal"><a href="#__codelineno-23-12">12</a></span>
<span class="normal"><a href="#__codelineno-23-13">13</a></span>
<span class="normal"><a href="#__codelineno-23-14">14</a></span>
<span class="normal"><a href="#__codelineno-23-15">15</a></span>
<span class="normal"><a href="#__codelineno-23-16">16</a></span>
<span class="normal"><a href="#__codelineno-23-17">17</a></span>
<span class="normal"><a href="#__codelineno-23-18">18</a></span>
<span class="normal"><a href="#__codelineno-23-19">19</a></span>
<span class="normal"><a href="#__codelineno-23-20">20</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1"></a><span class="c1">// declare arrays in shared memory</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">TILE_DIM</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="p">];</span>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">B_s</span><span class="p">[</span><span class="n">TILE_DIM</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="p">];</span>
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6"></a><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-23-7"><a id="__codelineno-23-7" name="__codelineno-23-7"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">tile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-23-8"><a id="__codelineno-23-8" name="__codelineno-23-8"></a><span class="w">  </span><span class="c1">// Load tile to shared memory</span>
</span><span id="__span-23-9"><a id="__codelineno-23-9" name="__codelineno-23-9"></a><span class="w">  </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-23-10"><a id="__codelineno-23-10" name="__codelineno-23-10"></a><span class="w">  </span><span class="n">B_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">[(</span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-23-11"><a id="__codelineno-23-11" name="__codelineno-23-11"></a>
</span><span id="__span-23-12"><a id="__codelineno-23-12" name="__codelineno-23-12"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span><span class="w"> </span><span class="c1">// Threads wait for each other to finish loading before computing</span>
</span><span id="__span-23-13"><a id="__codelineno-23-13" name="__codelineno-23-13"></a>
</span><span id="__span-23-14"><a id="__codelineno-23-14" name="__codelineno-23-14"></a><span class="w">  </span><span class="c1">// Compute with tile</span>
</span><span id="__span-23-15"><a id="__codelineno-23-15" name="__codelineno-23-15"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-23-16"><a id="__codelineno-23-16" name="__codelineno-23-16"></a><span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">B_s</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-23-17"><a id="__codelineno-23-17" name="__codelineno-23-17"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-23-18"><a id="__codelineno-23-18" name="__codelineno-23-18"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span><span class="w"> </span><span class="c1">// Threads wait for each other to finish loading before computing</span>
</span><span id="__span-23-19"><a id="__codelineno-23-19" name="__codelineno-23-19"></a><span class="p">}</span>
</span><span id="__span-23-20"><a id="__codelineno-23-20" name="__codelineno-23-20"></a><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="boundary-conditions">Boundary Conditions<a class="headerlink" href="#boundary-conditions" title="Permanent link">&para;</a></h4>
<p>Different Matrix Dimensions</p>
<ul>
<li>Solution: Write 0 for Missing Elements<ul>
<li>Is the target within input matrix?<ul>
<li>If yes, proceed to load. Otherwise, just write 0 to the shared memory</li>
</ul>
</li>
<li>Benefit<ul>
<li>No specialization during tile use!</li>
<li>Multiplying by 0 guarantees that unwanted terms do not contribute to the inner product.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="./assets/image-20250913233126141.png" alt="image-20250913233126141" style="zoom: 50%;" /></p>
<p><strong>Modifying the Tile Count</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-24-1">1</a></span>
<span class="normal"><a href="#__codelineno-24-2">2</a></span>
<span class="normal"><a href="#__codelineno-24-3">3</a></span>
<span class="normal"><a href="#__codelineno-24-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">tile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2"></a>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3"></a><span class="c1">//The bound for m implicitly assumes that Width is a multiple of TILE_WIDTH. We need to round up.</span>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">tile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>For non-multiples ÈùûÊï¥Êï∞ÂÄç of <code>TILE_DIM</code>:<ul>
<li>quotient is unchanged;</li>
<li>add one to round up</li>
</ul>
</li>
<li>For multiples Êï¥Êï∞ÂÄç of <code>TILE_DIM</code>:<ul>
<li>quotient is now one smaller, but we add 1.</li>
</ul>
</li>
</ul>
<p><strong>Modifying the Tile Loading Code</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-25-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-25-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-25-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-25-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-25-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-25-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-25-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-25-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-25-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-25-10">10</a></span>
<span class="normal"><a href="#__codelineno-25-11">11</a></span>
<span class="normal"><a href="#__codelineno-25-12">12</a></span>
<span class="normal"><a href="#__codelineno-25-13">13</a></span>
<span class="normal"><a href="#__codelineno-25-14">14</a></span>
<span class="normal"><a href="#__codelineno-25-15">15</a></span>
<span class="normal"><a href="#__codelineno-25-16">16</a></span>
<span class="normal"><a href="#__codelineno-25-17">17</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1"></a><span class="c1">// We had: Load tile to shared memory</span>
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2"></a><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3"></a><span class="n">B_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">[(</span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-25-4"><a id="__codelineno-25-4" name="__codelineno-25-4"></a>
</span><span id="__span-25-5"><a id="__codelineno-25-5" name="__codelineno-25-5"></a><span class="c1">//Note: the tests for A and B tiles are NOT the same.</span>
</span><span id="__span-25-6"><a id="__codelineno-25-6" name="__codelineno-25-6"></a>
</span><span id="__span-25-7"><a id="__codelineno-25-7" name="__codelineno-25-7"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="o">+</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-25-8"><a id="__codelineno-25-8" name="__codelineno-25-8"></a><span class="w">  </span><span class="c1">// as before</span>
</span><span id="__span-25-9"><a id="__codelineno-25-9" name="__codelineno-25-9"></a><span class="w">  </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-25-10"><a id="__codelineno-25-10" name="__codelineno-25-10"></a><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-25-11"><a id="__codelineno-25-11" name="__codelineno-25-11"></a><span class="w">  </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-25-12"><a id="__codelineno-25-12" name="__codelineno-25-12"></a><span class="p">}</span>
</span><span id="__span-25-13"><a id="__codelineno-25-13" name="__codelineno-25-13"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="o">+</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-25-14"><a id="__codelineno-25-14" name="__codelineno-25-14"></a><span class="w">  </span><span class="n">B_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">[(</span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-25-15"><a id="__codelineno-25-15" name="__codelineno-25-15"></a><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-25-16"><a id="__codelineno-25-16" name="__codelineno-25-16"></a><span class="w">  </span><span class="n">B_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-25-17"><a id="__codelineno-25-17" name="__codelineno-25-17"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p><strong>Modifying the Tile Use Code</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-26-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-26-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-26-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-26-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-26-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-26-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-26-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-26-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-26-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-26-10">10</a></span>
<span class="normal"><a href="#__codelineno-26-11">11</a></span>
<span class="normal"><a href="#__codelineno-26-12">12</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1"></a><span class="c1">// We had: Compute with tile</span>
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3"></a><span class="w">  </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B_s</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-26-4"><a id="__codelineno-26-4" name="__codelineno-26-4"></a><span class="p">}</span>
</span><span id="__span-26-5"><a id="__codelineno-26-5" name="__codelineno-26-5"></a>
</span><span id="__span-26-6"><a id="__codelineno-26-6" name="__codelineno-26-6"></a><span class="c1">//Note: no changes are needed, but we might save a little energy (fewer floating-point ops)?</span>
</span><span id="__span-26-7"><a id="__codelineno-26-7" name="__codelineno-26-7"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-26-8"><a id="__codelineno-26-8" name="__codelineno-26-8"></a><span class="w">  </span><span class="c1">// as before</span>
</span><span id="__span-26-9"><a id="__codelineno-26-9" name="__codelineno-26-9"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-26-10"><a id="__codelineno-26-10" name="__codelineno-26-10"></a><span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B_s</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-26-11"><a id="__codelineno-26-11" name="__codelineno-26-11"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-26-12"><a id="__codelineno-26-12" name="__codelineno-26-12"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p><strong>Modifying the Write to C</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-27-1">1</a></span>
<span class="normal"><a href="#__codelineno-27-2">2</a></span>
<span class="normal"><a href="#__codelineno-27-3">3</a></span>
<span class="normal"><a href="#__codelineno-27-4">4</a></span>
<span class="normal"><a href="#__codelineno-27-5">5</a></span>
<span class="normal"><a href="#__codelineno-27-6">6</a></span>
<span class="normal"><a href="#__codelineno-27-7">7</a></span>
<span class="normal"><a href="#__codelineno-27-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1"></a><span class="c1">// We had:</span>
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2"></a><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3"></a>
</span><span id="__span-27-4"><a id="__codelineno-27-4" name="__codelineno-27-4"></a><span class="c1">//We must test for threads outside of C:</span>
</span><span id="__span-27-5"><a id="__codelineno-27-5" name="__codelineno-27-5"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-27-6"><a id="__codelineno-27-6" name="__codelineno-27-6"></a><span class="w">  </span><span class="c1">// as before</span>
</span><span id="__span-27-7"><a id="__codelineno-27-7" name="__codelineno-27-7"></a><span class="w">  </span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span><span id="__span-27-8"><a id="__codelineno-27-8" name="__codelineno-27-8"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<blockquote>
<p>[!IMPORTANT]</p>
<p>For each thread, conditions are different for </p>
<ul>
<li>Loading A element</li>
<li>Loading B element</li>
<li>Calculation/storing output elements</li>
</ul>
<p>Branch divergence </p>
<ul>
<li>affects only blocks on boundaries, and should be small for large matrices</li>
</ul>
</blockquote>
<h3 id="bottleneck">Bottleneck Áì∂È¢à<a class="headerlink" href="#bottleneck" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250914145510157.png" alt="image-20250914145510157" style="zoom:33%;" /></p>
<ul>
<li>Á≥ªÁªüÂ∑≤Áªè‰ªé<strong>ÂÜÖÂ≠òÂèóÈôê</strong>ËΩ¨Âèò‰∏∫<strong>ËÆ°ÁÆóÂèóÈôê</strong> memory-bound to compute-bound</li>
</ul>
<p><img src="./assets/image-20250914165622133.png" alt="image-20250914165622133" style="zoom:33%;" /></p>
<ul>
<li>Memory per Block = ‰∏§‰∏™Áü©Èòµ, 16^2‰∏™Á∫øÁ®ã,4‰∏™Â≠óËäÇ</li>
<li>Max Blocks (Memory) =  (Total SM Shared Memory) / (Memory per Block) = 64 kB / 2 kB = 32 blocks</li>
<li>Max Blocks (Threads) = (Max Threads on SM) / (Threads per Block) = 2048 / 256 = 8 blocks</li>
<li>Pending loads = maximum number of active blocks ‚úñÔ∏èthe number of loads per block</li>
</ul>
<p><img src="./assets/image-20250914171006989.png" alt="image-20250914171006989" style="zoom:33%;" /></p>
<h4 id="memory-and-occupancy">Memory and Occupancy<a class="headerlink" href="#memory-and-occupancy" title="Permanent link">&para;</a></h4>
<p>Register usage per thread, and shared memory usage per thread block constrain occupancy</p>
<h4 id="dynamic-shared-memory">Dynamic Shared Memory<a class="headerlink" href="#dynamic-shared-memory" title="Permanent link">&para;</a></h4>
<p>Âä®ÊÄÅÂàÜÈÖçÂÖ±‰∫´ÂÜÖÂ≠ò</p>
<p>Declaration: <code>extern __shared__ A_s[];</code></p>
<p>Configuration: <code>kernel &lt;&lt;&lt; numBlocks, numThreadsPerBlock, smemPerBlock &gt;&gt;&gt; (...)</code></p>
<h3 id="tiling-on-cpu">Tiling on CPU<a class="headerlink" href="#tiling-on-cpu" title="Permanent link">&para;</a></h3>
<p>Tiling also works for CPU</p>
<ul>
<li>No scratchpad memory, but relies on caches Êó†ÈúÄÊöÇÂ≠òÂô®Ôºå‰ΩÜ‰æùËµñÁºìÂ≠ò</li>
<li>Cache is sufficiently reliable because there are fewer threads running on the core and the cache is larger ÁºìÂ≠òË∂≥Â§üÂèØÈù†ÔºåÂõ†‰∏∫Ê†∏ÂøÉ‰∏äËøêË°åÁöÑÁ∫øÁ®ãËæÉÂ∞ëÔºåËÄå‰∏îÁºìÂ≠òËæÉÂ§ß</li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-28-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-28-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-28-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-28-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-28-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-28-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-28-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-28-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-28-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-28-10">10</a></span>
<span class="normal"><a href="#__codelineno-28-11">11</a></span>
<span class="normal"><a href="#__codelineno-28-12">12</a></span>
<span class="normal"><a href="#__codelineno-28-13">13</a></span>
<span class="normal"><a href="#__codelineno-28-14">14</a></span>
<span class="normal"><a href="#__codelineno-28-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">rowTile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">rowTile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">rowTile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">colTile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">colTile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">colTile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-28-3"><a id="__codelineno-28-3" name="__codelineno-28-3"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">iTile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">iTile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">iTile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-28-4"><a id="__codelineno-28-4" name="__codelineno-28-4"></a><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rowTile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">rowTile</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">row</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-28-5"><a id="__codelineno-28-5" name="__codelineno-28-5"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colTile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">colTile</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">col</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-28-6"><a id="__codelineno-28-6" name="__codelineno-28-6"></a><span class="w">          </span><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-28-7"><a id="__codelineno-28-7" name="__codelineno-28-7"></a><span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iTile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">iTile</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-28-8"><a id="__codelineno-28-8" name="__codelineno-28-8"></a><span class="w">            </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-28-9"><a id="__codelineno-28-9" name="__codelineno-28-9"></a><span class="w">          </span><span class="p">}</span>
</span><span id="__span-28-10"><a id="__codelineno-28-10" name="__codelineno-28-10"></a><span class="w">          </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">iTile</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span><span id="__span-28-11"><a id="__codelineno-28-11" name="__codelineno-28-11"></a><span class="w">          </span><span class="k">else</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
</span><span id="__span-28-12"><a id="__codelineno-28-12" name="__codelineno-28-12"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-28-13"><a id="__codelineno-28-13" name="__codelineno-28-13"></a><span class="w">      </span><span class="p">}</span>
</span><span id="__span-28-14"><a id="__codelineno-28-14" name="__codelineno-28-14"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-28-15"><a id="__codelineno-28-15" name="__codelineno-28-15"></a><span class="w">  </span><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h2 id="7-dram-bandwidth-and-other-performance-considerations">7 DRAM Bandwidth and other Performance Considerations<a class="headerlink" href="#7-dram-bandwidth-and-other-performance-considerations" title="Permanent link">&para;</a></h2>
<blockquote>
<p>[!NOTE]</p>
<p>Performance optimizations covered so far
  - Tuning resource usage to maximize occupancy to hide latency in cores
  - Threads per block, shared memory per block, registers per thread
  - Reducing control divergence to increase SIMD efficiency
  - Shared memory and register tiling to reduce memory traffic</p>
<p>More optimizations to be covered today
  - Memory coalescing
  - Maximizing occupancy (again) to hide memory latency
  - Thread coarsening
  - Loop unrolling
  - Double-buffering</p>
</blockquote>
<h3 id="dram">DRAM<a class="headerlink" href="#dram" title="Permanent link">&para;</a></h3>
<p><strong>Random Access Memory (RAM)</strong>: same time needed to read/write any address</p>
<p><strong>DRAM(Dynamic RAM)</strong> </p>
<ul>
<li>
<p>is Slow But Dense</p>
</li>
<li>
<p>Capacitance‚Ä¶</p>
<ul>
<li>tiny for the BIT, but</li>
<li>huge for the <em>BIT LINE</em></li>
<li>Use an amplifier for higher speed!</li>
<li>Still slow‚Ä¶</li>
<li>But only need <em>1 transistor per bit</em> ‰∏Ä‰ΩçÂè™Ë¶Å‰∏Ä‰∏™Êô∂‰ΩìÁÆ°</li>
</ul>
</li>
</ul>
<p><strong>A DRAM bank</strong> consists of a 2D array of DRAM cells activated one row at a time, and read at the column</p>
<ul>
<li><em>SELECT</em> lines connect to about 1,000 bit lines</li>
<li>Core DRAM array has about O(1M) bits</li>
<li>Use more address bits to choose bit line(s)</li>
</ul>
<p><img src="./assets/image-20250916095042325.png" alt="image-20250916095042325" style="zoom:30%;" /></p>
<ul>
<li>Accessing data in the same burst is faster than accessing data in different bursts</li>
</ul>
<h3 id="memory-coalescing">Memory Coalescing ÂÜÖÂ≠òÂêàÂπ∂<a class="headerlink" href="#memory-coalescing" title="Permanent link">&para;</a></h3>
<p>When threads in the same warp access <strong>consecutive memory locations</strong> in the <strong>same burst ÁàÜÂèë</strong>, the accesses can be combined and served by one burst</p>
<ul>
<li>One DRAM transaction is needed</li>
<li>Known as memory coalescing</li>
</ul>
<p>If threads in the same warp access locations not in the same burst, accesses cannot be combined</p>
<ul>
<li>
<p>Multiple transactions are needed</p>
</li>
<li>
<p>Takes longer to service data to the warp</p>
</li>
<li>Sometimes called memory divergence</li>
</ul>
<p><img src="./assets/image-20250916100200094.png" alt="image-20250916100200094" style="zoom:33%;" /></p>
<p><img src="./assets/image-20250916100629483.png" alt="image-20250916100629483" style="zoom:33%;" /></p>
<h4 id="matrix-matrix-multiplication_1">Matrix-matrix multiplication<a class="headerlink" href="#matrix-matrix-multiplication_1" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-29-1">1</a></span>
<span class="normal"><a href="#__codelineno-29-2">2</a></span>
<span class="normal"><a href="#__codelineno-29-3">3</a></span>
<span class="normal"><a href="#__codelineno-29-4">4</a></span>
<span class="normal"><a href="#__codelineno-29-5">5</a></span>
<span class="normal"><a href="#__codelineno-29-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2"></a><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3"></a><span class="c1">// Note: a warp contains consecutive threads in the x dimension followed by the y dimension</span>
</span><span id="__span-29-4"><a id="__codelineno-29-4" name="__codelineno-29-4"></a><span class="n">For</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-29-5"><a id="__codelineno-29-5" name="__codelineno-29-5"></a><span class="w">  </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">M</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-29-6"><a id="__codelineno-29-6" name="__codelineno-29-6"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>Accesses to M and N are coalesced ÂêàÂπ∂</p>
<ul>
<li>e.g., threads 0 to 31 access element 0 of M on the first iteration, resulting in one memory transaction to service warp 0</li>
<li>e.g., threads 0 to 31 access elements 0 to 31 of N on the first iteration, resulting in one memory transaction to service warp 0</li>
</ul>
<h4 id="use-of-shared-memory-enables-coalescing">Use of Shared Memory Enables Coalescing<a class="headerlink" href="#use-of-shared-memory-enables-coalescing" title="Permanent link">&para;</a></h4>
<p>Tiled matrix-matrix multiplication</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-30-1">1</a></span>
<span class="normal"><a href="#__codelineno-30-2">2</a></span>
<span class="normal"><a href="#__codelineno-30-3">3</a></span>
<span class="normal"><a href="#__codelineno-30-4">4</a></span>
<span class="normal"><a href="#__codelineno-30-5">5</a></span>
<span class="normal"><a href="#__codelineno-30-6">6</a></span>
<span class="normal"><a href="#__codelineno-30-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3"></a><span class="n">For</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">tile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4"></a><span class="w">  </span><span class="n">M_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">M</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5"></a><span class="w">  </span><span class="n">N_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[(</span><span class="n">tile</span><span class="o">*</span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6"></a><span class="w">  </span><span class="p">...</span>
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="latency-hiding-with-multiple-banks">Latency Hiding with Multiple Banks<a class="headerlink" href="#latency-hiding-with-multiple-banks" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250916101427036.png" alt="image-20250916101427036" style="zoom:33%;" /></p>
<ul>
<li>Need many threads to simultaneously access memory to keep all banks busy</li>
<li>Achieved with having high occupancy in SMs</li>
<li>Similar idea to hiding pipeline latency in the core</li>
</ul>
<h3 id="fine-grain-thread-granularity">Fine-Grain Thread Granularity<a class="headerlink" href="#fine-grain-thread-granularity" title="Permanent link">&para;</a></h3>
<p>So far, parallelization approaches made threads as <em>fine-grain</em> Á∫øÁ®ãÁ≤íÂ∫¶ÁªÜÂåñ as possible</p>
<ul>
<li>Assign smallest possible unit of parallelizable work per thread<ul>
<li>e.g., one vector element per thread in vector addition</li>
<li>e.g., one output pixel per thread in RGB to gray and in blur</li>
<li>e.g., one output matrix element per thread in matrix-matrix multiplication</li>
</ul>
</li>
</ul>
<p><img src="./assets/image-20251002223538183.png" alt="image-20251002223538183" style="zoom: 67%;" /></p>
<p><strong>Advantage</strong>: provide hardware with as many threads as possible to fully utilize resources</p>
<ul>
<li>If more threads are provided than the GPU can support, the hardware can serialize the work with low overhead</li>
<li>If future GPUs come out with more resources, more parallelism can be extracted without code being rewritten<ul>
<li>Recall: <em>transparent scalability</em></li>
</ul>
</li>
</ul>
<p><strong>Disadvantage</strong>: if there is an overhead for parallelizing work across more threads, that overhead is maximized</p>
<ul>
<li>Okay if threads actually run in parallel</li>
<li>Suboptimal if threads are getting serialized by the hardware</li>
</ul>
<h4 id="thread-coarsening">Thread Coarsening Á≤óÂåñ<a class="headerlink" href="#thread-coarsening" title="Permanent link">&para;</a></h4>
<p><strong>Thread coarsening</strong> is an optimization were a thread is assigned multiple units of parallelizable work</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-31-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-31-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-31-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-31-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-31-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-31-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-31-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-31-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-31-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-31-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-31-2"><a id="__codelineno-31-2" name="__codelineno-31-2"></a><span class="n">foo</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span><span id="__span-31-3"><a id="__codelineno-31-3" name="__codelineno-31-3"></a>
</span><span id="__span-31-4"><a id="__codelineno-31-4" name="__codelineno-31-4"></a><span class="c1">// =&gt; Thread coarsening</span>
</span><span id="__span-31-5"><a id="__codelineno-31-5" name="__codelineno-31-5"></a>
</span><span id="__span-31-6"><a id="__codelineno-31-6" name="__codelineno-31-6"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">iStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="o">*</span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
</span><span id="__span-31-7"><a id="__codelineno-31-7" name="__codelineno-31-7"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">c</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-31-8"><a id="__codelineno-31-8" name="__codelineno-31-8"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iStart</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="p">;</span>
</span><span id="__span-31-9"><a id="__codelineno-31-9" name="__codelineno-31-9"></a><span class="w">  </span><span class="n">foo</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span><span id="__span-31-10"><a id="__codelineno-31-10" name="__codelineno-31-10"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p><strong>Advantages</strong></p>
<ul>
<li>Reduces the overhead incurred for parallelization</li>
<li>Could be redundant ÂÜó‰Ωô memory accesses</li>
<li>Could be redundant computations</li>
<li>Could be synchronization overhead or control divergence</li>
<li>We will see many examples throughout the course</li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul>
<li>More resources(variables allocation memory) per thread which may affect occupancy</li>
<li>Underutilizes resources if coarsening factor is too high</li>
<li>Need to retune Ë∞ÉÊï¥ coarsening factor for each device</li>
</ul>
<h4 id="loop-unrolling">Loop unrolling Âæ™ÁéØÂ±ïÂºÄ<a class="headerlink" href="#loop-unrolling" title="Permanent link">&para;</a></h4>
<p>Loop unrolling transforms a loop by replicating the body of the loop by some factor and reducing the number of loop iterations by the same factor ÈÄöËøáÂ∞ÜÂæ™ÁéØ‰∏ª‰ΩìÂ§çÂà∂Êüê‰∏™Âõ†Â≠êÂπ∂Â∞ÜÂæ™ÁéØËø≠‰ª£Ê¨°Êï∞ÂáèÂ∞ëÁõ∏ÂêåÁöÑÂõ†Â≠êÊù•ËΩ¨Êç¢Âæ™ÁéØ</p>
<ul>
<li>Loop unrolling reduces stalls in two ways:<ul>
<li>Fewer loop iterations implies fewer branches</li>
<li>Branches have long-latency in the absence of branch prediction</li>
</ul>
</li>
<li>Exposes more independent instructions for instruction scheduling</li>
</ul>
<p><img src="./assets/image-20251004232213163.png" alt="image-20251004232213163" style="zoom:50%;" /></p>
<h4 id="instruction-scheduling">Instruction Scheduling Êåá‰ª§Ë∞ÉÂ∫¶<a class="headerlink" href="#instruction-scheduling" title="Permanent link">&para;</a></h4>
<p><strong>Instruction scheduling</strong> reorders instructions to reduce stalling by placing instructions that depend on </p>
<p>each other farther away from each other</p>
<p>ÈÄöËøáÈáçÊñ∞ÊéíÂ∫èÊåá‰ª§ÔºåÂ∞ÜÁõ∏‰∫í‰æùËµñÁöÑÊåá‰ª§ÊîæÁΩÆÂæóÊõ¥ËøúÔºå‰ªéËÄåÂáèÂ∞ëÂÅúÈ°ø</p>
<h4 id="double-buffering">Double Buffering ÂèåÁºìÂÜ≤<a class="headerlink" href="#double-buffering" title="Permanent link">&para;</a></h4>
<p>Double buffering eliminates false dependences by using a different memory buffer for writing data than the memory buffer containing the data being read ÂèåÁºìÂÜ≤ÈÄöËøá‰ΩøÁî®‰∏çÂêåÁöÑÂÜÖÂ≠òÁºìÂÜ≤Âå∫Êù•ÂÜôÂÖ•Êï∞ÊçÆÔºåËÄå‰∏çÊòØÂåÖÂê´Ê≠£Âú®ËØªÂèñÁöÑÊï∞ÊçÆÁöÑÂÜÖÂ≠òÁºìÂÜ≤Âå∫Ôºå‰ªéËÄåÊ∂àÈô§‰∫ÜÈîôËØØÁöÑ‰æùËµñÂÖ≥Á≥ª</p>
<p><img src="./assets/image-20250916103340842.png" alt="image-20250916103340842" style="zoom:33%;" /></p>
<h3 id="checklist-of-common-optimizations">Checklist of Common Optimizations<a class="headerlink" href="#checklist-of-common-optimizations" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Optimization</th>
<th>Benefit to Compute Cores</th>
<th>Benefit to Memory</th>
<th>Strategies</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Compute utilization</strong></td>
<td>Occupancy tuning</td>
<td>More work to hide pipeline latency</td>
<td>More parallel memory accesses to hide DRAM latency</td>
<td>Tune the usage of SM resources such as threads per block, shared memory per block, and registers per thread</td>
</tr>
<tr>
<td><strong>Compute utilization</strong></td>
<td>Loop unrolling</td>
<td>Fewer branch instructions and more independent instruction sequences with fewer stalls</td>
<td>May enable promoting local arrays to registers to reduce global memory traffic</td>
<td>Performed automatically by the compiler<br><br>Use loops with constant bounds where possible to facilitate the compiler's job</td>
</tr>
<tr>
<td><strong>Compute utilization</strong></td>
<td>Reducing control divergence</td>
<td>High SIMD efficiency (fewer idle cores during SIMD execution)</td>
<td>/</td>
<td>Rearrange the assignment of threads to work and/or data</td>
</tr>
<tr>
<td><strong>Memory utilization</strong></td>
<td>Using coalescable global memory accesses</td>
<td>Fewer pipeline stalls waiting for global memory accesses</td>
<td>Less global memory traffic and better utilization of bursts/cache-lines</td>
<td>Rearranging the layout of the data<br>Rearranging the mapping of threads to data</td>
</tr>
<tr>
<td><strong>Memory utilization</strong></td>
<td>Shared memory tiling</td>
<td>Fewer pipeline stalls waiting for global memory accesses</td>
<td>Less global memory traffic</td>
<td>Transfer data between global memory and shared memory in a coalescable manner and perform irregular accesses in shared memory (e.g., corner turning)<br>Place data that is reused within a block in shared memory so that it is transferred between global memory and the SM only once</td>
</tr>
<tr>
<td><strong>Memory utilization</strong></td>
<td>Register tiling</td>
<td>Fewer pipeline stalls waiting for shared memory accesses</td>
<td>Less shared memory traffic</td>
<td>Place data that is reused within a warp or thread in registers so that it is transferred between shared memory and registers only once</td>
</tr>
<tr>
<td><strong>Synchronization latency</strong></td>
<td>Privatization</td>
<td>Fewer pipeline stalls waiting for atomic updates</td>
<td>Less contention and serialization of atomic updates</td>
<td>Apply partial updates to a private copy of the data then update the public copy when done</td>
</tr>
<tr>
<td><strong>Synchronization latency</strong></td>
<td>Warp-level primitives</td>
<td>Reduce block-wide barrier synchronizations</td>
<td>Less shared memory traffic</td>
<td>Perform operations requiring barrier synchronization at the warp-level, then consolidate warp-level results at the block-level</td>
</tr>
<tr>
<td><strong>Synchronization latency</strong></td>
<td>Double buffering</td>
<td>Eliminates barriers that enforce false dependencies</td>
<td>/</td>
<td>Eliminate false (write-after-read) dependencies by using different buffers for the writes and the preceding reads</td>
</tr>
<tr>
<td><strong>General</strong></td>
<td>Thread coarsening</td>
<td>Depends on the overhead of parallelization</td>
<td>Depends on the overhead of parallelization</td>
<td>Assign multiple units of parallelism to each thread in order to reduce the</td>
</tr>
</tbody>
</table>
<h4 id="trade-off-between-optimizations">Trade-off Between Optimizations<a class="headerlink" href="#trade-off-between-optimizations" title="Permanent link">&para;</a></h4>
<p>Maximizing occupancy ÊúÄÂ§ßÂåñÂç†ÊúâÁéá</p>
<ul>
<li>Maximizing occupancy hides pipeline latency, but threads may compete for resources (e.g., registers, shared memory, cache) ÊúÄÂ§ßÂåñÂç†Áî®ÁéáÂèØ‰ª•Èôç‰ΩéÊµÅÊ∞¥Á∫øÂª∂ËøüÔºå‰ΩÜÁ∫øÁ®ãÂèØËÉΩ‰ºöÁ´û‰∫âËµÑÊ∫êÔºà‰æãÂ¶ÇÂØÑÂ≠òÂô®„ÄÅÂÖ±‰∫´ÂÜÖÂ≠ò„ÄÅÁºìÂ≠òÔºâ</li>
</ul>
<p>Shared memory tiling</p>
<ul>
<li>Using more shared memory enables more data reuse, but may limit occupancy ‰ΩøÁî®Êõ¥Â§öÂÖ±‰∫´ÂÜÖÂ≠òÂèØ‰ª•ÂÆûÁé∞Êõ¥Â§öÊï∞ÊçÆÈáçÁî®Ôºå‰ΩÜÂèØËÉΩ‰ºöÈôêÂà∂Âç†Áî®Áéá</li>
</ul>
<p>Thread coarsening</p>
<ul>
<li>Coarsening reduces parallelization overhead, but requires more resources per thread which may limit occupancy Á≤óÂåñÂèØ‰ª•Èôç‰ΩéÂπ∂Ë°åÂåñÂºÄÈîÄÔºå‰ΩÜÊØè‰∏™Á∫øÁ®ãÈúÄË¶ÅÊõ¥Â§öËµÑÊ∫êÔºåËøôÂèØËÉΩ‰ºöÈôêÂà∂Âç†Áî®Áéá</li>
</ul>
<h3 id="problem-solving_2">Problem Solving<a class="headerlink" href="#problem-solving_2" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251004233101679.png" alt="image-20251004233101679" style="zoom:50%;" /></p>
<blockquote>
<p>Performance hinges on a GPU's ability to perform <strong>coalesced memory access</strong>, and we can't know if access is coalesced without the kernel launch configuration(specifically, the <code>blockDim</code> values)</p>
<p>The performance is not an inherent property of the code line itself but of the interaction between the code and the thread hierarchy.</p>
</blockquote>
<p><img src="./assets/image-20251004233624425.png" alt="image-20251004233624425" style="zoom:50%;" /></p>
<blockquote>
<p>The <strong>DRAM burst size</strong> is the minimum amount of data the memory system will fetch in a single transaction, regardless of how little you ask for. ÂÜÖÂ≠òÁ≥ªÁªüÂú®ÂçïÊ¨°‰∫ãÂä°‰∏≠Ëé∑ÂèñÁöÑÊúÄÂ∞èÊï∞ÊçÆÈáè„ÄÇÂç≥‰Ωø‰∏Ä‰∏™Á∫øÁ®ãÂè™ÈúÄË¶Å 8 ‰∏™Â≠óËäÇÔºåÂÜÖÂ≠òÊéßÂà∂Âô®‰πü‰ºöËé∑ÂèñÂåÖÂê´Ëøô 8 ‰∏™Â≠óËäÇÁöÑÊï¥‰∏™ 512 Â≠óËäÇÂùó„ÄÇ</p>
<p><strong>Data Needed:</strong> The 32 threads in the warp each need 8 bytes. The total <em>useful</em> data for the warp is <code>32 threads * 8 bytes/thread =</code> <strong>256 bytes</strong>.</p>
<p><strong>Data Fetched:</strong> All the data needed by the warp (from <code>A[0]</code> up to <code>A[4*31 + 1] = A[125]</code>) fits within a single 512-byte memory block. Because of the DRAM burst rule, the system <em>must</em> fetch the entire <strong>512-byte</strong> chunk to satisfy these requests.</p>
<p>Efficiency=Total Fetched Data/Useful Data=256 bytes/512 bytes=0.5</p>
<p>Achieved Throughput=Peak Bandwidth√óEfficiency=240GB/s √ó 0.5=120 GB/s</p>
</blockquote>
<h2 id="8-convolution-concept-constant-cache">8 Convolution Concept; Constant Cache<a class="headerlink" href="#8-convolution-concept-constant-cache" title="Permanent link">&para;</a></h2>
<h3 id="convolution-applications">Convolution Applications<a class="headerlink" href="#convolution-applications" title="Permanent link">&para;</a></h3>
<p><strong>Convolution compuation</strong>: An array operation where each output data element is a weighted sum of a collection of neighboring input elements</p>
<p>The weights used in the weighted sum calculation are defined by an input mask array, commonly referred to as the <em>convolution kernel(convolution filter, or convolution masks)</em>.</p>
<h4 id="1d-kernel-convolution">1D kernel convolution<a class="headerlink" href="#1d-kernel-convolution" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250918095150442.png" alt="image-20250918095150442" style="zoom:33%;" /></p>
<p>Boundary Handling ËæπÁïåÂ§ÑÁêÜ</p>
<ul>
<li>This kernel forces all elements outside the valid range to <strong>0</strong></li>
</ul>
<p><img src="./assets/image-20250919113811744.png" alt="image-20250919113811744" style="zoom:33%;" /></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-32-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-32-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-32-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-32-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-32-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-32-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-32-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-32-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-32-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-32-10">10</a></span>
<span class="normal"><a href="#__codelineno-32-11">11</a></span>
<span class="normal"><a href="#__codelineno-32-12">12</a></span>
<span class="normal"><a href="#__codelineno-32-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span>
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2"></a><span class="n">convolution_1D_basic_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">Mask_Width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span>
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3"></a><span class="p">{</span>
</span><span id="__span-32-4"><a id="__codelineno-32-4" name="__codelineno-32-4"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-32-5"><a id="__codelineno-32-5" name="__codelineno-32-5"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-32-6"><a id="__codelineno-32-6" name="__codelineno-32-6"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">N_start_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="n">Mask_Width</span><span class="o">/</span><span class="mi">2</span><span class="p">);</span>
</span><span id="__span-32-7"><a id="__codelineno-32-7" name="__codelineno-32-7"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Mask_Width</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-32-8"><a id="__codelineno-32-8" name="__codelineno-32-8"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(((</span><span class="n">N_start_point</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">((</span><span class="n">N_start_point</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-32-9"><a id="__codelineno-32-9" name="__codelineno-32-9"></a><span class="w">      </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">N_start_point</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">M</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
</span><span id="__span-32-10"><a id="__codelineno-32-10" name="__codelineno-32-10"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-32-11"><a id="__codelineno-32-11" name="__codelineno-32-11"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-32-12"><a id="__codelineno-32-12" name="__codelineno-32-12"></a><span class="w">  </span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-32-13"><a id="__codelineno-32-13" name="__codelineno-32-13"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="2d-convolution-with-boundary-condition-handling">2D Convolution with boundary condition handling<a class="headerlink" href="#2d-convolution-with-boundary-condition-handling" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250919114321290.png" alt="image-20250919114321290" style="zoom:33%;" /></p>
<ul>
<li>Boundry conditions also affect the efficiency of tiling</li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-33-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-33-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-33-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-33-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-33-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-33-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-33-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-33-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-33-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-33-10">10</a></span>
<span class="normal"><a href="#__codelineno-33-11">11</a></span>
<span class="normal"><a href="#__codelineno-33-12">12</a></span>
<span class="normal"><a href="#__codelineno-33-13">13</a></span>
<span class="normal"><a href="#__codelineno-33-14">14</a></span>
<span class="normal"><a href="#__codelineno-33-15">15</a></span>
<span class="normal"><a href="#__codelineno-33-16">16</a></span>
<span class="normal"><a href="#__codelineno-33-17">17</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">convolution_2D_basic_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="err">Ôºå</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">F</span><span class="err">Ôºå</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span>
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span>
</span><span id="__span-33-3"><a id="__codelineno-33-3" name="__codelineno-33-3"></a><span class="p">{</span>
</span><span id="__span-33-4"><a id="__codelineno-33-4" name="__codelineno-33-4"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">outCol</span><span class="o">=</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-33-5"><a id="__codelineno-33-5" name="__codelineno-33-5"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">outRow</span><span class="o">=</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-33-6"><a id="__codelineno-33-6" name="__codelineno-33-6"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="o">=</span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-33-7"><a id="__codelineno-33-7" name="__codelineno-33-7"></a><span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fRow</span><span class="o">=</span><span class="mi">0</span><span class="o">:</span><span class="n">fRow</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">*</span><span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span><span class="n">fRow</span><span class="o">++</span><span class="p">){</span>
</span><span id="__span-33-8"><a id="__codelineno-33-8" name="__codelineno-33-8"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fCol</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">fCol</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">*</span><span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span><span class="n">fCol</span><span class="o">++</span><span class="p">){</span>
</span><span id="__span-33-9"><a id="__codelineno-33-9" name="__codelineno-33-9"></a><span class="w">      </span><span class="n">inRow</span><span class="w"> </span><span class="o">=</span><span class="n">outRow</span><span class="o">+</span><span class="n">fRow</span><span class="p">;</span>
</span><span id="__span-33-10"><a id="__codelineno-33-10" name="__codelineno-33-10"></a><span class="w">      </span><span class="n">inCol</span><span class="o">=</span><span class="n">outCol</span><span class="o">-</span><span class="n">r</span><span class="o">+</span><span class="n">fCol</span><span class="p">;</span>
</span><span id="__span-33-11"><a id="__codelineno-33-11" name="__codelineno-33-11"></a><span class="w">      </span><span class="k">if</span><span class="p">(</span><span class="n">inRow</span><span class="o">&gt;=</span><span class="mi">0</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inRow</span><span class="o">&lt;</span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">&gt;=</span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">){</span>
</span><span id="__span-33-12"><a id="__codelineno-33-12" name="__codelineno-33-12"></a><span class="w">        </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">F</span><span class="p">[</span><span class="n">fRow</span><span class="p">][</span><span class="n">fCol</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">[</span><span class="n">inRow</span><span class="o">*</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">inCol</span><span class="p">];</span>
</span><span id="__span-33-13"><a id="__codelineno-33-13" name="__codelineno-33-13"></a><span class="w">      </span><span class="p">}</span>
</span><span id="__span-33-14"><a id="__codelineno-33-14" name="__codelineno-33-14"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-33-15"><a id="__codelineno-33-15" name="__codelineno-33-15"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-33-16"><a id="__codelineno-33-16" name="__codelineno-33-16"></a><span class="w">    </span><span class="n">P</span><span class="p">[</span><span class="n">outRow</span><span class="p">][</span><span class="n">outCol</span><span class="p">]</span><span class="o">=</span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-33-17"><a id="__codelineno-33-17" name="__codelineno-33-17"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>For global memory, you just <code>cudaMalloc()</code> and <code>cudaMemcpy()</code> like other arrays: </p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-34-1">1</a></span>
<span class="normal"><a href="#__codelineno-34-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1"></a><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_F</span><span class="p">,</span><span class="w"> </span><span class="n">filterSize</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</span><span id="__span-34-2"><a id="__codelineno-34-2" name="__codelineno-34-2"></a><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_F</span><span class="p">,</span><span class="w"> </span><span class="n">h_F</span><span class="p">,</span><span class="w"> </span><span class="n">filterSize</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<p>What does this kernel accomplish?</p>
<p><img src="./assets/image-20250919114747548.png" alt="image-20250919114747548" style="zoom:25%;" /></p>
<ul>
<li>Elements of M are called <strong>mask</strong> (kernel, filter) <strong>coefficients</strong>(weights)</li>
<li>Calculation of all output P elements needs M</li>
<li>M is not changed during grid execution </li>
<li>Bonus - M elements are accessed in the same order when calculating all P elements</li>
<li>M is a good candidate for <strong>Constant Memory</strong></li>
</ul>
<h3 id="programmer-view-of-cuda-memories">Programmer View of CUDA Memories<a class="headerlink" href="#programmer-view-of-cuda-memories" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250919115739416.png" alt="image-20250919115739416" style="zoom:33%;" /></p>
<h3 id="memory-hierarchies">Memory Hierarchies<a class="headerlink" href="#memory-hierarchies" title="Permanent link">&para;</a></h3>
<blockquote>
<p><strong>Review</strong>: If we had to go to global memory to access data all the time, the execution speed of GPUs would be limited by the global memory bandwidth</p>
<ul>
<li>We saw the use of shared memory in tiled matrix multiplication to reduce this limitation</li>
<li>Another important solution: Caches</li>
</ul>
</blockquote>
<h4 id="a-2d-convolution-kernel-using-constant-memory-for-f">A 2D convolution kernel using constant memory for F<a class="headerlink" href="#a-2d-convolution-kernel-using-constant-memory-for-f" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-35-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-35-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-35-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-35-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-35-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-35-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-35-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-35-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-35-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-35-10">10</a></span>
<span class="normal"><a href="#__codelineno-35-11">11</a></span>
<span class="normal"><a href="#__codelineno-35-12">12</a></span>
<span class="normal"><a href="#__codelineno-35-13">13</a></span>
<span class="normal"><a href="#__codelineno-35-14">14</a></span>
<span class="normal"><a href="#__codelineno-35-15">15</a></span>
<span class="normal"><a href="#__codelineno-35-16">16</a></span>
<span class="normal"><a href="#__codelineno-35-17">17</a></span>
<span class="normal"><a href="#__codelineno-35-18">18</a></span>
<span class="normal"><a href="#__codelineno-35-19">19</a></span>
<span class="normal"><a href="#__codelineno-35-20">20</a></span>
<span class="normal"><a href="#__codelineno-35-21">21</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1"></a><span class="n">__constant__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">F</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="o">*</span><span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span><span class="w"> </span><span class="c1">// r is the radius of the filter</span>
</span><span id="__span-35-2"><a id="__codelineno-35-2" name="__codelineno-35-2"></a>
</span><span id="__span-35-3"><a id="__codelineno-35-3" name="__codelineno-35-3"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">convolution_2D_const_mem_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">r</span><span class="p">,</span>
</span><span id="__span-35-4"><a id="__codelineno-35-4" name="__codelineno-35-4"></a><span class="w">                                                </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-35-5"><a id="__codelineno-35-5" name="__codelineno-35-5"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">outCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-35-6"><a id="__codelineno-35-6" name="__codelineno-35-6"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">outRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-35-7"><a id="__codelineno-35-7" name="__codelineno-35-7"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-35-8"><a id="__codelineno-35-8" name="__codelineno-35-8"></a>
</span><span id="__span-35-9"><a id="__codelineno-35-9" name="__codelineno-35-9"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">fRow</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">fRow</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-35-10"><a id="__codelineno-35-10" name="__codelineno-35-10"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">fCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">fCol</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-35-11"><a id="__codelineno-35-11" name="__codelineno-35-11"></a><span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">inRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outRow</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fRow</span><span class="p">;</span>
</span><span id="__span-35-12"><a id="__codelineno-35-12" name="__codelineno-35-12"></a><span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outCol</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fCol</span><span class="p">;</span>
</span><span id="__span-35-13"><a id="__codelineno-35-13" name="__codelineno-35-13"></a>
</span><span id="__span-35-14"><a id="__codelineno-35-14" name="__codelineno-35-14"></a><span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inRow</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inRow</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span>
</span><span id="__span-35-15"><a id="__codelineno-35-15" name="__codelineno-35-15"></a><span class="w">                </span><span class="n">inCol</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-35-16"><a id="__codelineno-35-16" name="__codelineno-35-16"></a><span class="w">                </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">F</span><span class="p">[</span><span class="n">fRow</span><span class="p">][</span><span class="n">fCol</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">inRow</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">inCol</span><span class="p">];</span>
</span><span id="__span-35-17"><a id="__codelineno-35-17" name="__codelineno-35-17"></a><span class="w">            </span><span class="p">}</span>
</span><span id="__span-35-18"><a id="__codelineno-35-18" name="__codelineno-35-18"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-35-19"><a id="__codelineno-35-19" name="__codelineno-35-19"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-35-20"><a id="__codelineno-35-20" name="__codelineno-35-20"></a><span class="w">    </span><span class="n">P</span><span class="p">[</span><span class="n">outRow</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">outCol</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-35-21"><a id="__codelineno-35-21" name="__codelineno-35-21"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>For constant memory, you must copy the filter to the GPU before launching the kernel ÂØπ‰∫éÂ∏∏ÈáèÂÜÖÂ≠òÔºåÊÇ®ÂøÖÈ°ªÂú®ÂêØÂä®ÂÜÖÊ†∏‰πãÂâçÂ∞ÜËøáÊª§Âô®Â§çÂà∂Âà∞ GPUÔºö</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-36-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1"></a><span class="n">cudaMemcpyToSymbol</span><span class="p">(</span><span class="n">F_const</span><span class="p">,</span><span class="w"> </span><span class="n">h_F</span><span class="p">,</span><span class="w"> </span><span class="n">filterSize</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="cache">Cache<a class="headerlink" href="#cache" title="Permanent link">&para;</a></h3>
<p>Recall: <strong>memory bursts</strong> </p>
<ul>
<li>contain around <strong>1024 bits</strong> (<strong>128B</strong>) fromconsecutive (linear) addresses</li>
<li>Let‚Äôs call a single burst a <strong>line</strong></li>
</ul>
<p>A <strong>cache</strong> is <strong>an 'array' of cache lines</strong></p>
<ul>
<li>A cache line can usually hold data from several consecutive memory addresses</li>
<li>When data is requested from the global memory, an entire cache line that includes the data being accessed is loaded into the cache, in an attempt to reduce global memory requests</li>
<li>The data in the cache is a <strong>‚Äúcopy‚Äù of the original data in global memory</strong></li>
<li>Additional hardware is used to remember the addresses of the data in the cache line</li>
</ul>
<blockquote>
<p>[!NOTE]</p>
<p><strong>Memory read</strong> <em>produces</em> <strong>a line</strong>, <strong>cache</strong> <em>stores</em> <strong>a copy of the line</strong>, and <strong>tag</strong> <em>records</em> <strong>the line‚Äôs memory address</strong></p>
</blockquote>
<h4 id="caches-and-locality">Caches and Locality<a class="headerlink" href="#caches-and-locality" title="Permanent link">&para;</a></h4>
<p><strong>Spatial locality Á©∫Èó¥Â±ÄÈÉ®ÊÄß</strong>: when the data elements stored in consecutive memory locations are accessed consecutively</p>
<p><strong>Temporal locality Êó∂Èó¥Â±ÄÈÉ®ÊÄß</strong>: when the same data element is accessed multiple times in a short period of time</p>
<ul>
<li>Both spatial locality and temporal locality improve the performance of caches</li>
</ul>
<p>An executing program loads and stores data from memory.</p>
<p>Consider <strong>a sequence of addresses</strong> accessed.</p>
<ul>
<li><strong>Sequence</strong> usually <strong>shows</strong> both types of <strong>locality</strong>:<ul>
<li><strong>spatial</strong>: accessing <strong>X implies</strong> accessing <strong>X+1</strong> (and X+2, and so forth) <strong>soon</strong></li>
<li><em>temporal</em><em>: accessing X</em><em> implies accessing </em><em>X again soon</em>*</li>
</ul>
</li>
<li>Caches improve performance for both types.</li>
</ul>
<h4 id="caches-cant-hold-everything">Caches Can‚Äôt Hold Everything<a class="headerlink" href="#caches-cant-hold-everything" title="Permanent link">&para;</a></h4>
<p>Caches are smaller than memory.</p>
<ul>
<li>When the cache is full, it must make room for a new line, usually by <strong>discarding the least recently used line</strong>.</li>
</ul>
<h4 id="shared-memory-vs-cache">Shared Memory vs. Cache<a class="headerlink" href="#shared-memory-vs-cache" title="Permanent link">&para;</a></h4>
<p>Shared memory in CUDA is another type of temporary storage used to relieve main memory contention</p>
<ul>
<li>In terms of distance from the SMs, shared memory is similar to L1 cache </li>
<li>Unlike cache, shared memory doesn't necessarily hold a copy of data that is also in main memory </li>
<li>Shared memory requires <strong>explicit data transfer</strong> instructions into locations in the shared memory, whereas cache doesn‚Äôt. ÂÖ±‰∫´ÂÜÖÂ≠òÈúÄË¶ÅÂ£∞ÊòéÂèòÈáè<code>__shared__</code>Âπ∂ÊòæÁ§∫Âú∞Â∞ÜÂÖ®Â±ÄÂÜÖÂ≠òÂèòÈáèÁöÑÂÄºÂ§çÂà∂Âà∞ÂÖ±‰∫´ÂÜÖÂ≠òÂèòÈáè‰∏≠Ôºõ‰ΩøÁî®ÁºìÂ≠òÊó∂ÔºåÁ®ãÂ∫è‰ºöËá™Âä®‰øùÂ≠òÊúÄËøë‰ΩøÁî®ÁöÑÂèòÈáèÂπ∂ËÆ∞‰ΩèÂÆÉ‰ª¨ÂéüÂßãÂÖ®Â±ÄÂÜÖÂ≠òÂú∞ÂùÄ</li>
</ul>
<p>Caches vs. shared memory</p>
<ul>
<li>Both on <em>chip</em>, with similar performance (As of Volta generation, both using the same physical resources, </li>
</ul>
<p>allocated dynamically!)</p>
<p><strong>Difference</strong></p>
<ul>
<li><strong>Programmer controls shared memory</strong> contents (called a scratchpad)</li>
<li><strong>Microarchitecture</strong> automatically <strong>determines the contents of the cache</strong>. (<strong>static RAM</strong>, not DRAM)</li>
</ul>
<h4 id="constant-cache-in-gpus">Constant cache in GPUs<a class="headerlink" href="#constant-cache-in-gpus" title="Permanent link">&para;</a></h4>
<p><strong>Modification to cached data</strong> needs to be (eventually) <strong>reflected back</strong> to the original data in global memory</p>
<ul>
<li>Requires logic to track the modified status, etc.</li>
</ul>
<p><strong>Constant cache</strong> is a special cache for constant data that will <strong>not be modified</strong> during kernel execution by a grid</p>
<ul>
<li>Data declared in the constant memory is not modified during kernel execution.</li>
<li>Constant cache can be accessed with higher throughput than L1 cache for some common patterns</li>
<li>L1 cache may write back, constant doesn't need to support writes</li>
</ul>
<p><strong>To support writes</strong> (modification of lines), <strong>changes</strong> must be <strong>copied back to memory</strong>, and cache must <strong>track</strong> modification <strong>status.</strong></p>
<ul>
<li><strong>L1 cache</strong> in GPU (for global memory accesses) <strong>supports writes</strong>.</li>
<li><strong>Cache for constant</strong> / texture <strong>memory</strong></li>
</ul>
<p>Special case: <strong>lines are read-only</strong></p>
<ul>
<li>Enables higher-throughput access than L1 for common GPU kernel access patterns</li>
</ul>
<hr />
<p>GPU L2/L1 Caches</p>
<p><img src="./assets/image-20250918101255648.png" alt="image-20250918101255648" style="zoom:40%;" /></p>
<ul>
<li>L1 ÁöÑÂª∂ËøüÂíåÂ∏¶ÂÆΩÈÄüÂ∫¶ÈÉΩÊé•ËøëÂ§ÑÁêÜÂô®ÁöÑÈÄüÂ∫¶ÔºõL2 ÁºìÂ≠òÊõ¥Â§ßÔºåËÆøÈóÆÊó∂Èó¥ÈúÄË¶ÅÂçÅÂá†‰∏™Êó∂ÈíüÂë®ÊúüÔºåÈÄöÂ∏∏Âú®Â§ö‰∏™Â§ÑÁêÜÂô®Ê†∏ÂøÉ‰πãÈó¥ÂÖ±‰∫´</li>
<li>Global memory variables and constant memory variables are all in DRAM</li>
</ul>
<h4 id="using-constant-memory">Using Constant Memory<a class="headerlink" href="#using-constant-memory" title="Permanent link">&para;</a></h4>
<p>Declare constant memory array as global variable outside the CUDA kernel and any host function</p>
<ul>
<li><code>__constant__ float filter_c[FILTER_DIM];</code></li>
</ul>
<p>Must initialize constant memory from the host, and cannot modify it during execution</p>
<ul>
<li><code>cudaMemcpyToSymbol(filter_c, filter, FILTER_DIM * sizeof(float), offset = 0, kind = cudaMemcpyHostToDevice);</code></li>
</ul>
<p>General use: <code>cudaMemcpyToSymbol(dest, src, size)</code></p>
<ul>
<li>dest ÊåáÂêëÂ∏∏‰∫ÆÂÜÖÂ≠ò‰∏≠ÁõÆÊ†á‰ΩçÁΩÆÁöÑÊåáÈíàÔºåsrcÊåáÂêë‰∏ªÊú∫ÂÜÖÂ≠òÊ∫êÊï∞ÊçÆÔºåsizeË¶ÅÂ§çÂà∂ÁöÑÂ≠óËäÇÊï∞Èáè</li>
</ul>
<p>Can only allocate up to 64KB; Otherwise, input is also constant, but it is too large to put in constant memory</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-37-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-37-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-37-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-37-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-37-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-37-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-37-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-37-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-37-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-37-10">10</a></span>
<span class="normal"><a href="#__codelineno-37-11">11</a></span>
<span class="normal"><a href="#__codelineno-37-12">12</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1"></a><span class="cm">/*Host Example*/</span>
</span><span id="__span-37-2"><a id="__codelineno-37-2" name="__codelineno-37-2"></a><span class="c1">// MASK_WIDTH is the size of the mask</span>
</span><span id="__span-37-3"><a id="__codelineno-37-3" name="__codelineno-37-3"></a><span class="c1">// global variable, outside any kernel/function</span>
</span><span id="__span-37-4"><a id="__codelineno-37-4" name="__codelineno-37-4"></a><span class="n">__constant__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">Mc</span><span class="p">[</span><span class="n">MASK_WIDTH</span><span class="p">];</span>
</span><span id="__span-37-5"><a id="__codelineno-37-5" name="__codelineno-37-5"></a><span class="c1">// Initialize Mask</span>
</span><span id="__span-37-6"><a id="__codelineno-37-6" name="__codelineno-37-6"></a><span class="kt">float</span><span class="w"> </span><span class="n">Mask</span><span class="p">[</span><span class="n">MASK_WIDTH</span><span class="p">];</span>
</span><span id="__span-37-7"><a id="__codelineno-37-7" name="__codelineno-37-7"></a><span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">MASK_WIDTH</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-37-8"><a id="__codelineno-37-8" name="__codelineno-37-8"></a><span class="w">    </span><span class="n">Mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">rand</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">RAND_MAX</span><span class="p">);</span>
</span><span id="__span-37-9"><a id="__codelineno-37-9" name="__codelineno-37-9"></a><span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">rand</span><span class="p">()</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="n">Mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Mask</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-37-10"><a id="__codelineno-37-10" name="__codelineno-37-10"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-37-11"><a id="__codelineno-37-11" name="__codelineno-37-11"></a><span class="n">cudaMemcpyToSymbol</span><span class="p">(</span><span class="n">Mc</span><span class="p">,</span><span class="w"> </span><span class="n">Mask</span><span class="p">,</span><span class="w"> </span><span class="n">MASK_WIDTH</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</span><span id="__span-37-12"><a id="__codelineno-37-12" name="__codelineno-37-12"></a><span class="n">ConvolutionKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="w"> </span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">Nd</span><span class="p">,</span><span class="w"> </span><span class="n">Pd</span><span class="p">,</span><span class="w"> </span><span class="n">MASK_WIDTH</span><span class="p">,</span><span class="w"> </span><span class="n">WIDTH</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<p>We are <strong>memory-limited</strong> ÂÜÖÂ≠òÂèóÈôê</p>
<ul>
<li>For the 1D case, every output element requires <code>2*MASK_WIDTH</code> loads (of M and N each) and <code>2*MASK_WIDTH</code> floating-point operations. </li>
<li>For the 2D case, every output element requires <code>2*MASK_WIDTH^2</code> loads and <code>2*MASK_WIDTH^2</code> floating-point operations.</li>
</ul>
<h3 id="tiled-convolution-with-halo-cells">Tiled convolution with halo cells<a class="headerlink" href="#tiled-convolution-with-halo-cells" title="Permanent link">&para;</a></h3>
<h4 id="tiled-1d-convolution-basic-idea">Tiled 1D Convolution Basic Idea<a class="headerlink" href="#tiled-1d-convolution-basic-idea" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250919134811711.png" alt="image-20250919134811711" style="zoom:33%;" /></p>
<p><strong>Reuse data read from global memory(use shared memory)</strong></p>
<p><img src="./assets/image-20250919135650456.png" alt="image-20250919135650456" style="zoom:25%;" /></p>
<p><strong>What About the Halos? Do we also copy halos into shared memory?</strong></p>
<p><img src="./assets/image-20250919135736591.png" alt="image-20250919135736591" style="zoom:33%;" /></p>
<p><strong>Approach 1</strong>: Can Access Halo from Global Memory</p>
<ul>
<li>threads <strong>read halo values</strong> directly <strong>from global memory</strong></li>
<li>Advantage: optimize reuse of shared memory(halo reuse is smaller).</li>
<li>Disadvantages:<ul>
<li><strong>Branch divergence</strong>! (shared vs. global reads) ÂàÜÊîØÂàÜÊ≠ß</li>
<li>Halo <strong>too narrow to fill</strong> a memory <strong>burst</strong></li>
</ul>
</li>
</ul>
<p><strong>Approach 2</strong>: Can Load Halo to Shared Memory</p>
<ul>
<li><strong>load halos to shared memory</strong></li>
<li>Advantages: <ul>
<li>Coalesce global memory accesses ÂêàÂπ∂ÂÖ®Â±ÄÂÜÖÂ≠òËÆøÈóÆ</li>
<li><strong>No branch divergence</strong> during computation</li>
</ul>
</li>
<li>Disadvantages:<ul>
<li>Some threads must do &gt;1 load, so some branch divergence in reading data.</li>
<li>Slightly more shared memory is needed.</li>
</ul>
</li>
</ul>
<h4 id="three-tiling-strategies">Three Tiling Strategies<a class="headerlink" href="#three-tiling-strategies" title="Permanent link">&para;</a></h4>
<h5 id="strategy-1">Strategy 1<a class="headerlink" href="#strategy-1" title="Permanent link">&para;</a></h5>
<p>Variable Meanings for a Block</p>
<p><img src="./assets/image-20250919140806644.png" alt="image-20250919140806644" style="zoom: 40%;" /><img src="./assets/image-20250919141526332.png" alt="image-20250919141526332" style="zoom:25%;" /></p>
<ol>
<li>
<p>Loading the Left Halo</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-38-1">1</a></span>
<span class="normal"><a href="#__codelineno-38-2">2</a></span>
<span class="normal"><a href="#__codelineno-38-3">3</a></span>
<span class="normal"><a href="#__codelineno-38-4">4</a></span>
<span class="normal"><a href="#__codelineno-38-5">5</a></span>
<span class="normal"><a href="#__codelineno-38-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">radius</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Mask_Width</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
</span><span id="__span-38-2"><a id="__codelineno-38-2" name="__codelineno-38-2"></a><span class="kt">int</span><span class="w"> </span><span class="n">halo_index_left</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-38-3"><a id="__codelineno-38-3" name="__codelineno-38-3"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">radius</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-38-4"><a id="__codelineno-38-4" name="__codelineno-38-4"></a><span class="w">  </span><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">radius</span><span class="p">)]</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-38-5"><a id="__codelineno-38-5" name="__codelineno-38-5"></a><span class="w">    </span><span class="p">(</span><span class="n">halo_index_left</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">halo_index_left</span><span class="p">];</span>
</span><span id="__span-38-6"><a id="__codelineno-38-6" name="__codelineno-38-6"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
</li>
<li>
<p>Loading the Right Halo</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-39-1">1</a></span>
<span class="normal"><a href="#__codelineno-39-2">2</a></span>
<span class="normal"><a href="#__codelineno-39-3">3</a></span>
<span class="normal"><a href="#__codelineno-39-4">4</a></span>
<span class="normal"><a href="#__codelineno-39-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-39-2"><a id="__codelineno-39-2" name="__codelineno-39-2"></a><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-39-3"><a id="__codelineno-39-3" name="__codelineno-39-3"></a><span class="w">  </span><span class="n">N_ds</span><span class="p">[</span><span class="n">radius</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span><span id="__span-39-4"><a id="__codelineno-39-4" name="__codelineno-39-4"></a><span class="k">else</span>
</span><span id="__span-39-5"><a id="__codelineno-39-5" name="__codelineno-39-5"></a><span class="w">  </span><span class="n">N_ds</span><span class="p">[</span><span class="n">radius</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span></code></pre></div></td></tr></table></div>
</li>
<li>
<p>Loading the Internal Elements</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-40-1">1</a></span>
<span class="normal"><a href="#__codelineno-40-2">2</a></span>
<span class="normal"><a href="#__codelineno-40-3">3</a></span>
<span class="normal"><a href="#__codelineno-40-4">4</a></span>
<span class="normal"><a href="#__codelineno-40-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-40-1"><a id="__codelineno-40-1" name="__codelineno-40-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">halo_index_right</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-40-2"><a id="__codelineno-40-2" name="__codelineno-40-2"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">radius</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-40-3"><a id="__codelineno-40-3" name="__codelineno-40-3"></a><span class="w">  </span><span class="n">N_ds</span><span class="p">[</span><span class="n">radius</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-40-4"><a id="__codelineno-40-4" name="__codelineno-40-4"></a><span class="w">    </span><span class="p">(</span><span class="n">halo_index_right</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">halo_index_right</span><span class="p">];</span>
</span><span id="__span-40-5"><a id="__codelineno-40-5" name="__codelineno-40-5"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
</li>
<li>
<p>Put it together</p>
</li>
</ol>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-41-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-41-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-41-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-41-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-41-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-41-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-41-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-41-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-41-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-41-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-41-1"><a id="__codelineno-41-1" name="__codelineno-41-1"></a><span class="c1">// Load left halo </span>
</span><span id="__span-41-2"><a id="__codelineno-41-2" name="__codelineno-41-2"></a><span class="c1">// Load internal elements</span>
</span><span id="__span-41-3"><a id="__codelineno-41-3" name="__codelineno-41-3"></a><span class="c1">// Load right halo </span>
</span><span id="__span-41-4"><a id="__codelineno-41-4" name="__codelineno-41-4"></a><span class="c1">// Compute and store results</span>
</span><span id="__span-41-5"><a id="__codelineno-41-5" name="__codelineno-41-5"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-41-6"><a id="__codelineno-41-6" name="__codelineno-41-6"></a><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-41-7"><a id="__codelineno-41-7" name="__codelineno-41-7"></a><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Mask_Width</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-41-8"><a id="__codelineno-41-8" name="__codelineno-41-8"></a><span class="w">  </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Mc</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
</span><span id="__span-41-9"><a id="__codelineno-41-9" name="__codelineno-41-9"></a><span class="p">}</span>
</span><span id="__span-41-10"><a id="__codelineno-41-10" name="__codelineno-41-10"></a><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span></code></pre></div></td></tr></table></div>
<hr />
<p><strong>Alternative Implementation of Strategy 1</strong></p>
<p><img src="./assets/image-20250919142036598.png" alt="image-20250919142036598" style="zoom:25%;" /></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-42-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-42-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-42-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-42-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-42-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-42-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-42-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-42-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-42-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-42-10">10</a></span>
<span class="normal"><a href="#__codelineno-42-11">11</a></span>
<span class="normal"><a href="#__codelineno-42-12">12</a></span>
<span class="normal"><a href="#__codelineno-42-13">13</a></span>
<span class="normal"><a href="#__codelineno-42-14">14</a></span>
<span class="normal"><a href="#__codelineno-42-15">15</a></span>
<span class="normal"><a href="#__codelineno-42-16">16</a></span>
<span class="normal"><a href="#__codelineno-42-17">17</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-42-1"><a id="__codelineno-42-1" name="__codelineno-42-1"></a><span class="c1">//STEP1</span>
</span><span id="__span-42-2"><a id="__codelineno-42-2" name="__codelineno-42-2"></a><span class="kt">int</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="n">radius</span><span class="p">;</span>
</span><span id="__span-42-3"><a id="__codelineno-42-3" name="__codelineno-42-3"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">Width</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// all threads</span>
</span><span id="__span-42-4"><a id="__codelineno-42-4" name="__codelineno-42-4"></a><span class="w">  </span><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">start</span><span class="p">];</span>
</span><span id="__span-42-5"><a id="__codelineno-42-5" name="__codelineno-42-5"></a><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-42-6"><a id="__codelineno-42-6" name="__codelineno-42-6"></a><span class="w">  </span><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-42-7"><a id="__codelineno-42-7" name="__codelineno-42-7"></a><span class="p">}</span>
</span><span id="__span-42-8"><a id="__codelineno-42-8" name="__codelineno-42-8"></a>
</span><span id="__span-42-9"><a id="__codelineno-42-9" name="__codelineno-42-9"></a><span class="c1">//STEP2</span>
</span><span id="__span-42-10"><a id="__codelineno-42-10" name="__codelineno-42-10"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">MASK_WIDTH</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// some threads</span>
</span><span id="__span-42-11"><a id="__codelineno-42-11" name="__codelineno-42-11"></a><span class="w">  </span><span class="n">start</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">TILE_SIZE</span><span class="p">;</span>
</span><span id="__span-42-12"><a id="__codelineno-42-12" name="__codelineno-42-12"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">Width</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-42-13"><a id="__codelineno-42-13" name="__codelineno-42-13"></a><span class="w">    </span><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">TILE_SIZE</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">start</span><span class="p">];</span>
</span><span id="__span-42-14"><a id="__codelineno-42-14" name="__codelineno-42-14"></a><span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-42-15"><a id="__codelineno-42-15" name="__codelineno-42-15"></a><span class="w">    </span><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">TILE_SIZE</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-42-16"><a id="__codelineno-42-16" name="__codelineno-42-16"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-42-17"><a id="__codelineno-42-17" name="__codelineno-42-17"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="strategy-2">Strategy 2<a class="headerlink" href="#strategy-2" title="Permanent link">&para;</a></h5>
<p><img src="./assets/image-20250919140948710.png" alt="image-20250919140948710" style="zoom:40%;" /></p>
<blockquote>
<p>See in <a href="# Strategy 2: Parallelize Loading of a Tile">next chapter</a></p>
</blockquote>
<h5 id="strategy-3">Strategy 3<a class="headerlink" href="#strategy-3" title="Permanent link">&para;</a></h5>
<p><img src="./assets/image-20250919141017716.png" alt="image-20250919141017716" style="zoom: 40%;" /></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-43-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-43-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-43-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-43-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-43-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-43-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-43-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-43-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-43-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-43-10">10</a></span>
<span class="normal"><a href="#__codelineno-43-11">11</a></span>
<span class="normal"><a href="#__codelineno-43-12">12</a></span>
<span class="normal"><a href="#__codelineno-43-13">13</a></span>
<span class="normal"><a href="#__codelineno-43-14">14</a></span>
<span class="normal"><a href="#__codelineno-43-15">15</a></span>
<span class="normal"><a href="#__codelineno-43-16">16</a></span>
<span class="normal"><a href="#__codelineno-43-17">17</a></span>
<span class="normal"><a href="#__codelineno-43-18">18</a></span>
<span class="normal"><a href="#__codelineno-43-19">19</a></span>
<span class="normal"><a href="#__codelineno-43-20">20</a></span>
<span class="normal"><a href="#__codelineno-43-21">21</a></span>
<span class="normal"><a href="#__codelineno-43-22">22</a></span>
<span class="normal"><a href="#__codelineno-43-23">23</a></span>
<span class="normal"><a href="#__codelineno-43-24">24</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-43-1"><a id="__codelineno-43-1" name="__codelineno-43-1"></a><span class="c1">// Loading data</span>
</span><span id="__span-43-2"><a id="__codelineno-43-2" name="__codelineno-43-2"></a><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-43-3"><a id="__codelineno-43-3" name="__codelineno-43-3"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">N_ds</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="p">];</span><span class="w"> </span><span class="c1">// variable initilization and shared memory declaration</span>
</span><span id="__span-43-4"><a id="__codelineno-43-4" name="__codelineno-43-4"></a><span class="c1">// load from global to shared</span>
</span><span id="__span-43-5"><a id="__codelineno-43-5" name="__codelineno-43-5"></a><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"> </span><span class="c1">// boundary checking is missing here</span>
</span><span id="__span-43-6"><a id="__codelineno-43-6" name="__codelineno-43-6"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-43-7"><a id="__codelineno-43-7" name="__codelineno-43-7"></a>
</span><span id="__span-43-8"><a id="__codelineno-43-8" name="__codelineno-43-8"></a><span class="c1">//Computing</span>
</span><span id="__span-43-9"><a id="__codelineno-43-9" name="__codelineno-43-9"></a><span class="kt">int</span><span class="w"> </span><span class="n">radius</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Mask_Width</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
</span><span id="__span-43-10"><a id="__codelineno-43-10" name="__codelineno-43-10"></a><span class="kt">int</span><span class="w"> </span><span class="n">This_tile_start_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-43-11"><a id="__codelineno-43-11" name="__codelineno-43-11"></a><span class="kt">int</span><span class="w"> </span><span class="n">Next_tile_start_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-43-12"><a id="__codelineno-43-12" name="__codelineno-43-12"></a><span class="kt">int</span><span class="w"> </span><span class="n">N_start_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">radius</span><span class="p">;</span>
</span><span id="__span-43-13"><a id="__codelineno-43-13" name="__codelineno-43-13"></a><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-43-14"><a id="__codelineno-43-14" name="__codelineno-43-14"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Mask_Width</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-43-15"><a id="__codelineno-43-15" name="__codelineno-43-15"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">N_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N_start_point</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
</span><span id="__span-43-16"><a id="__codelineno-43-16" name="__codelineno-43-16"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">N_index</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">N_index</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-43-17"><a id="__codelineno-43-17" name="__codelineno-43-17"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="n">N_index</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">This_tile_start_point</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>
</span><span id="__span-43-18"><a id="__codelineno-43-18" name="__codelineno-43-18"></a><span class="w">        </span><span class="p">(</span><span class="n">N_index</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Next_tile_start_point</span><span class="p">))</span><span class="w"> </span>
</span><span id="__span-43-19"><a id="__codelineno-43-19" name="__codelineno-43-19"></a><span class="w">      </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">N_ds</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">-</span><span class="n">radius</span><span class="o">+</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">M</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
</span><span id="__span-43-20"><a id="__codelineno-43-20" name="__codelineno-43-20"></a><span class="w">    </span><span class="k">else</span><span class="w"> </span>
</span><span id="__span-43-21"><a id="__codelineno-43-21" name="__codelineno-43-21"></a><span class="w">      </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">N_index</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Mc</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
</span><span id="__span-43-22"><a id="__codelineno-43-22" name="__codelineno-43-22"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-43-23"><a id="__codelineno-43-23" name="__codelineno-43-23"></a><span class="p">}</span>
</span><span id="__span-43-24"><a id="__codelineno-43-24" name="__codelineno-43-24"></a><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span></code></pre></div></td></tr></table></div>
<blockquote>
<p>[!CAUTION]</p>
<p>What Shall We Parallelize?</p>
<ul>
<li>Strategies 1 and 3</li>
</ul>
</blockquote>
<h2 id="9-2d-tiled-convolution-kernel-reuse-analysis">9 2D Tiled Convolution Kernel; Reuse Analysis<a class="headerlink" href="#9-2d-tiled-convolution-kernel-reuse-analysis" title="Permanent link">&para;</a></h2>
<h3 id="stencil-algorithms">Stencil Algorithms<a class="headerlink" href="#stencil-algorithms" title="Permanent link">&para;</a></h3>
<p>Numerical data processing algorithms which update array elements according to some fixed pattern, called a <em>stencil</em> Ê†πÊçÆÊüêÁßçÂõ∫ÂÆöÊ®°ÂºèÔºàÁß∞‰∏∫Ê®°ÊùøÔºâÊõ¥Êñ∞Êï∞ÁªÑÂÖÉÁ¥†ÁöÑÊï∞ÂÄºÊï∞ÊçÆÂ§ÑÁêÜÁÆóÊ≥ï</p>
<p><img src="./assets/image-20250923093928016.png" alt="image-20250923093928016" style="zoom: 33%;" /></p>
<h3 id="strategy-2-parallelize-loading-of-a-tile">Strategy 2: Parallelize Loading of a Tile<a class="headerlink" href="#strategy-2-parallelize-loading-of-a-tile" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250919140948710.png" alt="image-20250919140948710" style="zoom: 40%;" /></p>
<p>Alternately,</p>
<ul>
<li>Thread block matches input tile size</li>
<li>Each thread loads one element of input tile</li>
<li>Some threads do not participate in calculating output</li>
</ul>
<p><strong>Advantage</strong>:</p>
<ul>
<li><mark>No branch divergence for load</mark> (high latency).</li>
<li><strong>Avoid narrow global access</strong> (2 √ó halo width).</li>
</ul>
<p><strong>Disadvantage</strong>:</p>
<ul>
<li>Branch divergence for compute (low latency).</li>
</ul>
<h4 id="parallelizing-tile-loading">Parallelizing Tile Loading<a class="headerlink" href="#parallelizing-tile-loading" title="Permanent link">&para;</a></h4>
<p>Load a tile of N into shared memory</p>
<ul>
<li>All threads participate in loading</li>
<li>A subset of threads then use each N element in shared memory</li>
<li>Output Tiles Still Cover the Output!</li>
<li>Input Tiles Need to be Larger than Output Tiles</li>
</ul>
<h4 id="setting-block-dimensions">Setting Block Dimensions<a class="headerlink" href="#setting-block-dimensions" title="Permanent link">&para;</a></h4>
<p><code>dim3 dimBlock(TILE_WIDTH + 4,TILE_WIDTH + 4, 1);</code></p>
<p>In general, <strong>block width</strong> (square blocks) should be <code>TILE_WIDTH + (MASK_WIDTH-1)</code></p>
<p><code>dim3 dimGrid(ceil(ceil(P.widthP.height/(1.0*TILE_WIDTH)),/(1.0*TILE_WIDTH)), 1)</code></p>
<ul>
<li>There need to be enough thread blocks to generate all P elements</li>
<li>There need to be enough threads to load entire tile of input</li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-44-1">1</a></span>
<span class="normal"><a href="#__codelineno-44-2">2</a></span>
<span class="normal"><a href="#__codelineno-44-3">3</a></span>
<span class="normal"><a href="#__codelineno-44-4">4</a></span>
<span class="normal"><a href="#__codelineno-44-5">5</a></span>
<span class="normal"><a href="#__codelineno-44-6">6</a></span>
<span class="normal"><a href="#__codelineno-44-7">7</a></span>
<span class="normal"><a href="#__codelineno-44-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-44-1"><a id="__codelineno-44-1" name="__codelineno-44-1"></a><span class="cm">/* Shifting From Output Coordinates To Input Coordinates */</span>
</span><span id="__span-44-2"><a id="__codelineno-44-2" name="__codelineno-44-2"></a>
</span><span id="__span-44-3"><a id="__codelineno-44-3" name="__codelineno-44-3"></a><span class="kt">int</span><span class="w"> </span><span class="n">tx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-44-4"><a id="__codelineno-44-4" name="__codelineno-44-4"></a><span class="kt">int</span><span class="w"> </span><span class="n">ty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-44-5"><a id="__codelineno-44-5" name="__codelineno-44-5"></a><span class="kt">int</span><span class="w"> </span><span class="n">row_o</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ty</span><span class="p">;</span>
</span><span id="__span-44-6"><a id="__codelineno-44-6" name="__codelineno-44-6"></a><span class="kt">int</span><span class="w"> </span><span class="n">col_o</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tx</span><span class="p">;</span>
</span><span id="__span-44-7"><a id="__codelineno-44-7" name="__codelineno-44-7"></a><span class="kt">int</span><span class="w"> </span><span class="n">row_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">row_o</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="c1">// MASK_WIDTH / 2</span>
</span><span id="__span-44-8"><a id="__codelineno-44-8" name="__codelineno-44-8"></a><span class="kt">int</span><span class="w"> </span><span class="n">col_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">col_o</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="c1">// (radius in prev. code)</span>
</span></code></pre></div></td></tr></table></div>
<p>Threads That Loads Halos Outside N Should Return 0.0</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-45-1">1</a></span>
<span class="normal"><a href="#__codelineno-45-2">2</a></span>
<span class="normal"><a href="#__codelineno-45-3">3</a></span>
<span class="normal"><a href="#__codelineno-45-4">4</a></span>
<span class="normal"><a href="#__codelineno-45-5">5</a></span>
<span class="normal"><a href="#__codelineno-45-6">6</a></span>
<span class="normal"><a href="#__codelineno-45-7">7</a></span>
<span class="normal"><a href="#__codelineno-45-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-45-1"><a id="__codelineno-45-1" name="__codelineno-45-1"></a><span class="cm">/*  Taking Care of Boundaries */</span>
</span><span id="__span-45-2"><a id="__codelineno-45-2" name="__codelineno-45-2"></a>
</span><span id="__span-45-3"><a id="__codelineno-45-3" name="__codelineno-45-3"></a><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="n">row_i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">row_i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">col_i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">col_i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-45-4"><a id="__codelineno-45-4" name="__codelineno-45-4"></a><span class="w">    </span><span class="n">tile</span><span class="p">[</span><span class="n">ty</span><span class="p">][</span><span class="n">tx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">row_i</span><span class="o">*</span><span class="n">Width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col_i</span><span class="p">];</span>
</span><span id="__span-45-5"><a id="__codelineno-45-5" name="__codelineno-45-5"></a><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-45-6"><a id="__codelineno-45-6" name="__codelineno-45-6"></a><span class="w">    </span><span class="n">tile</span><span class="p">[</span><span class="n">ty</span><span class="p">][</span><span class="n">tx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-45-7"><a id="__codelineno-45-7" name="__codelineno-45-7"></a><span class="p">}</span>
</span><span id="__span-45-8"><a id="__codelineno-45-8" name="__codelineno-45-8"></a><span class="n">__syncthreads</span><span class="w"> </span><span class="p">();</span><span class="w"> </span><span class="c1">// wait for tile</span>
</span></code></pre></div></td></tr></table></div>
<p>Not All Threads Calculate and Write Output</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-46-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-46-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-46-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-46-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-46-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-46-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-46-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-46-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-46-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-46-10">10</a></span>
<span class="normal"><a href="#__codelineno-46-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-46-1"><a id="__codelineno-46-1" name="__codelineno-46-1"></a><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-46-2"><a id="__codelineno-46-2" name="__codelineno-46-2"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ty</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-46-3"><a id="__codelineno-46-3" name="__codelineno-46-3"></a><span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-46-4"><a id="__codelineno-46-4" name="__codelineno-46-4"></a><span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-46-5"><a id="__codelineno-46-5" name="__codelineno-46-5"></a><span class="w">      </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">Mc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">ty</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="n">tx</span><span class="p">];</span>
</span><span id="__span-46-6"><a id="__codelineno-46-6" name="__codelineno-46-6"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-46-7"><a id="__codelineno-46-7" name="__codelineno-46-7"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-46-8"><a id="__codelineno-46-8" name="__codelineno-46-8"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row_o</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col_o</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-46-9"><a id="__codelineno-46-9" name="__codelineno-46-9"></a><span class="w">    </span><span class="n">P</span><span class="p">[</span><span class="n">row_o</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col_o</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-46-10"><a id="__codelineno-46-10" name="__codelineno-46-10"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-46-11"><a id="__codelineno-46-11" name="__codelineno-46-11"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="2d-tiled-convolution-kernel-with-constant-memory">2D Tiled Convolution Kernel (with constant memory)<a class="headerlink" href="#2d-tiled-convolution-kernel-with-constant-memory" title="Permanent link">&para;</a></h3>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-47-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-47-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-47-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-47-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-47-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-47-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-47-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-47-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-47-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-47-10">10</a></span>
<span class="normal"><a href="#__codelineno-47-11">11</a></span>
<span class="normal"><a href="#__codelineno-47-12">12</a></span>
<span class="normal"><a href="#__codelineno-47-13">13</a></span>
<span class="normal"><a href="#__codelineno-47-14">14</a></span>
<span class="normal"><a href="#__codelineno-47-15">15</a></span>
<span class="normal"><a href="#__codelineno-47-16">16</a></span>
<span class="normal"><a href="#__codelineno-47-17">17</a></span>
<span class="normal"><a href="#__codelineno-47-18">18</a></span>
<span class="normal"><a href="#__codelineno-47-19">19</a></span>
<span class="normal"><a href="#__codelineno-47-20">20</a></span>
<span class="normal"><a href="#__codelineno-47-21">21</a></span>
<span class="normal"><a href="#__codelineno-47-22">22</a></span>
<span class="normal"><a href="#__codelineno-47-23">23</a></span>
<span class="normal"><a href="#__codelineno-47-24">24</a></span>
<span class="normal"><a href="#__codelineno-47-25">25</a></span>
<span class="normal"><a href="#__codelineno-47-26">26</a></span>
<span class="normal"><a href="#__codelineno-47-27">27</a></span>
<span class="normal"><a href="#__codelineno-47-28">28</a></span>
<span class="normal"><a href="#__codelineno-47-29">29</a></span>
<span class="normal"><a href="#__codelineno-47-30">30</a></span>
<span class="normal"><a href="#__codelineno-47-31">31</a></span>
<span class="normal"><a href="#__codelineno-47-32">32</a></span>
<span class="normal"><a href="#__codelineno-47-33">33</a></span>
<span class="normal"><a href="#__codelineno-47-34">34</a></span>
<span class="normal"><a href="#__codelineno-47-35">35</a></span>
<span class="normal"><a href="#__codelineno-47-36">36</a></span>
<span class="normal"><a href="#__codelineno-47-37">37</a></span>
<span class="normal"><a href="#__codelineno-47-38">38</a></span>
<span class="normal"><a href="#__codelineno-47-39">39</a></span>
<span class="normal"><a href="#__codelineno-47-40">40</a></span>
<span class="normal"><a href="#__codelineno-47-41">41</a></span>
<span class="normal"><a href="#__codelineno-47-42">42</a></span>
<span class="normal"><a href="#__codelineno-47-43">43</a></span>
<span class="normal"><a href="#__codelineno-47-44">44</a></span>
<span class="normal"><a href="#__codelineno-47-45">45</a></span>
<span class="normal"><a href="#__codelineno-47-46">46</a></span>
<span class="normal"><a href="#__codelineno-47-47">47</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-47-1"><a id="__codelineno-47-1" name="__codelineno-47-1"></a><span class="cp">#define IN_TILE_DIM 32</span>
</span><span id="__span-47-2"><a id="__codelineno-47-2" name="__codelineno-47-2"></a><span class="cp">#define OUT_TILE_DIM (IN_TILE_DIM - 2 * FILTER_RADIUS)</span>
</span><span id="__span-47-3"><a id="__codelineno-47-3" name="__codelineno-47-3"></a><span class="c1">// Tile is split into input (IN_TILE_DIM) and output (OUT_TILE_DIM = IN_TILE_DIM ‚àí 2*r)</span>
</span><span id="__span-47-4"><a id="__codelineno-47-4" name="__codelineno-47-4"></a>
</span><span id="__span-47-5"><a id="__codelineno-47-5" name="__codelineno-47-5"></a><span class="n">__constant__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">F_c</span><span class="p">[</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">];</span><span class="w"> </span><span class="c1">// constant memeory</span>
</span><span id="__span-47-6"><a id="__codelineno-47-6" name="__codelineno-47-6"></a>
</span><span id="__span-47-7"><a id="__codelineno-47-7" name="__codelineno-47-7"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">convolution_tiled_2D_const_mem_kernel</span><span class="p">(</span>
</span><span id="__span-47-8"><a id="__codelineno-47-8" name="__codelineno-47-8"></a><span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span>
</span><span id="__span-47-9"><a id="__codelineno-47-9" name="__codelineno-47-9"></a><span class="p">{</span>
</span><span id="__span-47-10"><a id="__codelineno-47-10" name="__codelineno-47-10"></a><span class="w">    </span><span class="c1">// Compute global indices of input elements (including halo)</span>
</span><span id="__span-47-11"><a id="__codelineno-47-11" name="__codelineno-47-11"></a><span class="w">    </span><span class="c1">// ÂÖ®Â±ÄËæìÂÖ•ÂùêÊ†á</span>
</span><span id="__span-47-12"><a id="__codelineno-47-12" name="__codelineno-47-12"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-47-13"><a id="__codelineno-47-13" name="__codelineno-47-13"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-47-14"><a id="__codelineno-47-14" name="__codelineno-47-14"></a>
</span><span id="__span-47-15"><a id="__codelineno-47-15" name="__codelineno-47-15"></a><span class="w">    </span><span class="c1">// Shared memory tile (input + halo)</span>
</span><span id="__span-47-16"><a id="__codelineno-47-16" name="__codelineno-47-16"></a><span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">N_s</span><span class="p">[</span><span class="n">IN_TILE_DIM</span><span class="p">][</span><span class="n">IN_TILE_DIM</span><span class="p">];</span><span class="c1">// ÊØè‰∏™ÂùóÊúâ IN_TILE_DIM √ó IN_TILE_DIM Á∫øÁ®ã</span>
</span><span id="__span-47-17"><a id="__codelineno-47-17" name="__codelineno-47-17"></a>
</span><span id="__span-47-18"><a id="__codelineno-47-18" name="__codelineno-47-18"></a><span class="w">    </span><span class="c1">// Load input tile from global memory into shared memory</span>
</span><span id="__span-47-19"><a id="__codelineno-47-19" name="__codelineno-47-19"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span>
</span><span id="__span-47-20"><a id="__codelineno-47-20" name="__codelineno-47-20"></a><span class="w">        </span><span class="n">N_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-47-21"><a id="__codelineno-47-21" name="__codelineno-47-21"></a><span class="w">    </span><span class="k">else</span>
</span><span id="__span-47-22"><a id="__codelineno-47-22" name="__codelineno-47-22"></a><span class="w">        </span><span class="n">N_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-47-23"><a id="__codelineno-47-23" name="__codelineno-47-23"></a>
</span><span id="__span-47-24"><a id="__codelineno-47-24" name="__codelineno-47-24"></a><span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-47-25"><a id="__codelineno-47-25" name="__codelineno-47-25"></a>
</span><span id="__span-47-26"><a id="__codelineno-47-26" name="__codelineno-47-26"></a><span class="w">    </span><span class="c1">// Compute output element indices relative to tile</span>
</span><span id="__span-47-27"><a id="__codelineno-47-27" name="__codelineno-47-27"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tileCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-47-28"><a id="__codelineno-47-28" name="__codelineno-47-28"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tileRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-47-29"><a id="__codelineno-47-29" name="__codelineno-47-29"></a>
</span><span id="__span-47-30"><a id="__codelineno-47-30" name="__codelineno-47-30"></a><span class="w">    </span><span class="c1">// Check if this thread computes a valid output element</span>
</span><span id="__span-47-31"><a id="__codelineno-47-31" name="__codelineno-47-31"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tileCol</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tileCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">&amp;&amp;</span>
</span><span id="__span-47-32"><a id="__codelineno-47-32" name="__codelineno-47-32"></a><span class="w">        </span><span class="n">tileRow</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tileRow</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">&amp;&amp;</span>
</span><span id="__span-47-33"><a id="__codelineno-47-33" name="__codelineno-47-33"></a><span class="w">        </span><span class="n">row</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span>
</span><span id="__span-47-34"><a id="__codelineno-47-34" name="__codelineno-47-34"></a><span class="w">    </span><span class="p">{</span>
</span><span id="__span-47-35"><a id="__codelineno-47-35" name="__codelineno-47-35"></a><span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-47-36"><a id="__codelineno-47-36" name="__codelineno-47-36"></a>
</span><span id="__span-47-37"><a id="__codelineno-47-37" name="__codelineno-47-37"></a><span class="w">        </span><span class="c1">// Convolution sum over the filter window</span>
</span><span id="__span-47-38"><a id="__codelineno-47-38" name="__codelineno-47-38"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">fRow</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">fRow</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-47-39"><a id="__codelineno-47-39" name="__codelineno-47-39"></a><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">fCol</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">fCol</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-47-40"><a id="__codelineno-47-40" name="__codelineno-47-40"></a><span class="w">                </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">F_c</span><span class="p">[</span><span class="n">fRow</span><span class="p">][</span><span class="n">fCol</span><span class="p">]</span><span class="w"> </span><span class="o">*</span>
</span><span id="__span-47-41"><a id="__codelineno-47-41" name="__codelineno-47-41"></a><span class="w">                          </span><span class="n">N_s</span><span class="p">[</span><span class="n">tileRow</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fRow</span><span class="p">][</span><span class="n">tileCol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fCol</span><span class="p">];</span>
</span><span id="__span-47-42"><a id="__codelineno-47-42" name="__codelineno-47-42"></a><span class="w">            </span><span class="p">}</span>
</span><span id="__span-47-43"><a id="__codelineno-47-43" name="__codelineno-47-43"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-47-44"><a id="__codelineno-47-44" name="__codelineno-47-44"></a><span class="w">        </span><span class="c1">// Write result to global memory</span>
</span><span id="__span-47-45"><a id="__codelineno-47-45" name="__codelineno-47-45"></a><span class="w">        </span><span class="n">P</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-47-46"><a id="__codelineno-47-46" name="__codelineno-47-46"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-47-47"><a id="__codelineno-47-47" name="__codelineno-47-47"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>Host code</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-48-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-48-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-48-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-48-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-48-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-48-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-48-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-48-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-48-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-48-10">10</a></span>
<span class="normal"><a href="#__codelineno-48-11">11</a></span>
<span class="normal"><a href="#__codelineno-48-12">12</a></span>
<span class="normal"><a href="#__codelineno-48-13">13</a></span>
<span class="normal"><a href="#__codelineno-48-14">14</a></span>
<span class="normal"><a href="#__codelineno-48-15">15</a></span>
<span class="normal"><a href="#__codelineno-48-16">16</a></span>
<span class="normal"><a href="#__codelineno-48-17">17</a></span>
<span class="normal"><a href="#__codelineno-48-18">18</a></span>
<span class="normal"><a href="#__codelineno-48-19">19</a></span>
<span class="normal"><a href="#__codelineno-48-20">20</a></span>
<span class="normal"><a href="#__codelineno-48-21">21</a></span>
<span class="normal"><a href="#__codelineno-48-22">22</a></span>
<span class="normal"><a href="#__codelineno-48-23">23</a></span>
<span class="normal"><a href="#__codelineno-48-24">24</a></span>
<span class="normal"><a href="#__codelineno-48-25">25</a></span>
<span class="normal"><a href="#__codelineno-48-26">26</a></span>
<span class="normal"><a href="#__codelineno-48-27">27</a></span>
<span class="normal"><a href="#__codelineno-48-28">28</a></span>
<span class="normal"><a href="#__codelineno-48-29">29</a></span>
<span class="normal"><a href="#__codelineno-48-30">30</a></span>
<span class="normal"><a href="#__codelineno-48-31">31</a></span>
<span class="normal"><a href="#__codelineno-48-32">32</a></span>
<span class="normal"><a href="#__codelineno-48-33">33</a></span>
<span class="normal"><a href="#__codelineno-48-34">34</a></span>
<span class="normal"><a href="#__codelineno-48-35">35</a></span>
<span class="normal"><a href="#__codelineno-48-36">36</a></span>
<span class="normal"><a href="#__codelineno-48-37">37</a></span>
<span class="normal"><a href="#__codelineno-48-38">38</a></span>
<span class="normal"><a href="#__codelineno-48-39">39</a></span>
<span class="normal"><a href="#__codelineno-48-40">40</a></span>
<span class="normal"><a href="#__codelineno-48-41">41</a></span>
<span class="normal"><a href="#__codelineno-48-42">42</a></span>
<span class="normal"><a href="#__codelineno-48-43">43</a></span>
<span class="normal"><a href="#__codelineno-48-44">44</a></span>
<span class="normal"><a href="#__codelineno-48-45">45</a></span>
<span class="normal"><a href="#__codelineno-48-46">46</a></span>
<span class="normal"><a href="#__codelineno-48-47">47</a></span>
<span class="normal"><a href="#__codelineno-48-48">48</a></span>
<span class="normal"><a href="#__codelineno-48-49">49</a></span>
<span class="normal"><a href="#__codelineno-48-50">50</a></span>
<span class="normal"><a href="#__codelineno-48-51">51</a></span>
<span class="normal"><a href="#__codelineno-48-52">52</a></span>
<span class="normal"><a href="#__codelineno-48-53">53</a></span>
<span class="normal"><a href="#__codelineno-48-54">54</a></span>
<span class="normal"><a href="#__codelineno-48-55">55</a></span>
<span class="normal"><a href="#__codelineno-48-56">56</a></span>
<span class="normal"><a href="#__codelineno-48-57">57</a></span>
<span class="normal"><a href="#__codelineno-48-58">58</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-48-1"><a id="__codelineno-48-1" name="__codelineno-48-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
</span><span id="__span-48-2"><a id="__codelineno-48-2" name="__codelineno-48-2"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
</span><span id="__span-48-3"><a id="__codelineno-48-3" name="__codelineno-48-3"></a>
</span><span id="__span-48-4"><a id="__codelineno-48-4" name="__codelineno-48-4"></a><span class="cp">#define TILE_WIDTH 16</span>
</span><span id="__span-48-5"><a id="__codelineno-48-5" name="__codelineno-48-5"></a><span class="cp">#define MAX_FILTER_SIZE 49 </span><span class="c1">// example</span>
</span><span id="__span-48-6"><a id="__codelineno-48-6" name="__codelineno-48-6"></a>
</span><span id="__span-48-7"><a id="__codelineno-48-7" name="__codelineno-48-7"></a><span class="c1">// Declare constant memory on the device</span>
</span><span id="__span-48-8"><a id="__codelineno-48-8" name="__codelineno-48-8"></a><span class="n">__constant__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">F_const</span><span class="p">[</span><span class="n">MAX_FILTER_SIZE</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">MAX_FILTER_SIZE</span><span class="p">];</span>
</span><span id="__span-48-9"><a id="__codelineno-48-9" name="__codelineno-48-9"></a>
</span><span id="__span-48-10"><a id="__codelineno-48-10" name="__codelineno-48-10"></a><span class="c1">// Kernel declaration</span>
</span><span id="__span-48-11"><a id="__codelineno-48-11" name="__codelineno-48-11"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">convolution_2D_tiled_const_mem_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-48-12"><a id="__codelineno-48-12" name="__codelineno-48-12"></a><span class="w">                                                      </span><span class="kt">int</span><span class="w"> </span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
</span><span id="__span-48-13"><a id="__codelineno-48-13" name="__codelineno-48-13"></a>
</span><span id="__span-48-14"><a id="__codelineno-48-14" name="__codelineno-48-14"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-48-15"><a id="__codelineno-48-15" name="__codelineno-48-15"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">512</span><span class="p">;</span>
</span><span id="__span-48-16"><a id="__codelineno-48-16" name="__codelineno-48-16"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">  </span><span class="c1">// filter radius, e.g. 3x3 filter</span>
</span><span id="__span-48-17"><a id="__codelineno-48-17" name="__codelineno-48-17"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">filterWidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
</span><span id="__span-48-18"><a id="__codelineno-48-18" name="__codelineno-48-18"></a>
</span><span id="__span-48-19"><a id="__codelineno-48-19" name="__codelineno-48-19"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">imgSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
</span><span id="__span-48-20"><a id="__codelineno-48-20" name="__codelineno-48-20"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">filterSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filterWidth</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">filterWidth</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
</span><span id="__span-48-21"><a id="__codelineno-48-21" name="__codelineno-48-21"></a>
</span><span id="__span-48-22"><a id="__codelineno-48-22" name="__codelineno-48-22"></a><span class="w">    </span><span class="c1">// Allocate host memory</span>
</span><span id="__span-48-23"><a id="__codelineno-48-23" name="__codelineno-48-23"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">imgSize</span><span class="p">);</span>
</span><span id="__span-48-24"><a id="__codelineno-48-24" name="__codelineno-48-24"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_P</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">imgSize</span><span class="p">);</span>
</span><span id="__span-48-25"><a id="__codelineno-48-25" name="__codelineno-48-25"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_F</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">filterSize</span><span class="p">);</span>
</span><span id="__span-48-26"><a id="__codelineno-48-26" name="__codelineno-48-26"></a>
</span><span id="__span-48-27"><a id="__codelineno-48-27" name="__codelineno-48-27"></a><span class="w">    </span><span class="c1">// Initialize input and filter (example values, can be omitted)</span>
</span><span id="__span-48-28"><a id="__codelineno-48-28" name="__codelineno-48-28"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="n">h_N</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">;</span>
</span><span id="__span-48-29"><a id="__codelineno-48-29" name="__codelineno-48-29"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">filterWidth</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">filterWidth</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="n">h_F</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">filterWidth</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">filterWidth</span><span class="p">);</span>
</span><span id="__span-48-30"><a id="__codelineno-48-30" name="__codelineno-48-30"></a>
</span><span id="__span-48-31"><a id="__codelineno-48-31" name="__codelineno-48-31"></a><span class="w">    </span><span class="c1">// Allocate device memory</span>
</span><span id="__span-48-32"><a id="__codelineno-48-32" name="__codelineno-48-32"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_N</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_P</span><span class="p">;</span>
</span><span id="__span-48-33"><a id="__codelineno-48-33" name="__codelineno-48-33"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_N</span><span class="p">,</span><span class="w"> </span><span class="n">imgSize</span><span class="p">);</span>
</span><span id="__span-48-34"><a id="__codelineno-48-34" name="__codelineno-48-34"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_P</span><span class="p">,</span><span class="w"> </span><span class="n">imgSize</span><span class="p">);</span>
</span><span id="__span-48-35"><a id="__codelineno-48-35" name="__codelineno-48-35"></a>
</span><span id="__span-48-36"><a id="__codelineno-48-36" name="__codelineno-48-36"></a><span class="w">    </span><span class="c1">// Copy image data to device</span>
</span><span id="__span-48-37"><a id="__codelineno-48-37" name="__codelineno-48-37"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_N</span><span class="p">,</span><span class="w"> </span><span class="n">h_N</span><span class="p">,</span><span class="w"> </span><span class="n">imgSize</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-48-38"><a id="__codelineno-48-38" name="__codelineno-48-38"></a>
</span><span id="__span-48-39"><a id="__codelineno-48-39" name="__codelineno-48-39"></a><span class="w">    </span><span class="c1">// Copy filter to constant memory</span>
</span><span id="__span-48-40"><a id="__codelineno-48-40" name="__codelineno-48-40"></a><span class="w">    </span><span class="n">cudaMemcpyToSymbol</span><span class="p">(</span><span class="n">F_const</span><span class="p">,</span><span class="w"> </span><span class="n">h_F</span><span class="p">,</span><span class="w"> </span><span class="n">filterSize</span><span class="p">);</span>
</span><span id="__span-48-41"><a id="__codelineno-48-41" name="__codelineno-48-41"></a>
</span><span id="__span-48-42"><a id="__codelineno-48-42" name="__codelineno-48-42"></a><span class="w">    </span><span class="c1">// Configure grid and block</span>
</span><span id="__span-48-43"><a id="__codelineno-48-43" name="__codelineno-48-43"></a><span class="w">    </span><span class="n">dim3</span><span class="w"> </span><span class="n">dimBlock</span><span class="p">(</span><span class="n">TILE_WIDTH</span><span class="p">,</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">);</span>
</span><span id="__span-48-44"><a id="__codelineno-48-44" name="__codelineno-48-44"></a><span class="w">    </span><span class="n">dim3</span><span class="w"> </span><span class="n">dimGrid</span><span class="p">((</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">,</span>
</span><span id="__span-48-45"><a id="__codelineno-48-45" name="__codelineno-48-45"></a><span class="w">                 </span><span class="p">(</span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">);</span>
</span><span id="__span-48-46"><a id="__codelineno-48-46" name="__codelineno-48-46"></a>
</span><span id="__span-48-47"><a id="__codelineno-48-47" name="__codelineno-48-47"></a><span class="w">    </span><span class="c1">// Launch kernel</span>
</span><span id="__span-48-48"><a id="__codelineno-48-48" name="__codelineno-48-48"></a><span class="w">    </span><span class="n">convolution_2D_tiled_const_mem_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="w"> </span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_N</span><span class="p">,</span><span class="w"> </span><span class="n">d_P</span><span class="p">,</span><span class="w"> </span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
</span><span id="__span-48-49"><a id="__codelineno-48-49" name="__codelineno-48-49"></a>
</span><span id="__span-48-50"><a id="__codelineno-48-50" name="__codelineno-48-50"></a><span class="w">    </span><span class="c1">// Copy result back to host</span>
</span><span id="__span-48-51"><a id="__codelineno-48-51" name="__codelineno-48-51"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">h_P</span><span class="p">,</span><span class="w"> </span><span class="n">d_P</span><span class="p">,</span><span class="w"> </span><span class="n">imgSize</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
</span><span id="__span-48-52"><a id="__codelineno-48-52" name="__codelineno-48-52"></a>
</span><span id="__span-48-53"><a id="__codelineno-48-53" name="__codelineno-48-53"></a><span class="w">    </span><span class="c1">// Cleanup</span>
</span><span id="__span-48-54"><a id="__codelineno-48-54" name="__codelineno-48-54"></a><span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_N</span><span class="p">);</span><span class="w"> </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_P</span><span class="p">);</span>
</span><span id="__span-48-55"><a id="__codelineno-48-55" name="__codelineno-48-55"></a><span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_N</span><span class="p">);</span><span class="w"> </span><span class="n">free</span><span class="p">(</span><span class="n">h_P</span><span class="p">);</span><span class="n">free</span><span class="p">(</span><span class="n">h_F</span><span class="p">);</span>
</span><span id="__span-48-56"><a id="__codelineno-48-56" name="__codelineno-48-56"></a>
</span><span id="__span-48-57"><a id="__codelineno-48-57" name="__codelineno-48-57"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-48-58"><a id="__codelineno-48-58" name="__codelineno-48-58"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>Kernel (using shared + constant memory)</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-49-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-49-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-49-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-49-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-49-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-49-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-49-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-49-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-49-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-49-10">10</a></span>
<span class="normal"><a href="#__codelineno-49-11">11</a></span>
<span class="normal"><a href="#__codelineno-49-12">12</a></span>
<span class="normal"><a href="#__codelineno-49-13">13</a></span>
<span class="normal"><a href="#__codelineno-49-14">14</a></span>
<span class="normal"><a href="#__codelineno-49-15">15</a></span>
<span class="normal"><a href="#__codelineno-49-16">16</a></span>
<span class="normal"><a href="#__codelineno-49-17">17</a></span>
<span class="normal"><a href="#__codelineno-49-18">18</a></span>
<span class="normal"><a href="#__codelineno-49-19">19</a></span>
<span class="normal"><a href="#__codelineno-49-20">20</a></span>
<span class="normal"><a href="#__codelineno-49-21">21</a></span>
<span class="normal"><a href="#__codelineno-49-22">22</a></span>
<span class="normal"><a href="#__codelineno-49-23">23</a></span>
<span class="normal"><a href="#__codelineno-49-24">24</a></span>
<span class="normal"><a href="#__codelineno-49-25">25</a></span>
<span class="normal"><a href="#__codelineno-49-26">26</a></span>
<span class="normal"><a href="#__codelineno-49-27">27</a></span>
<span class="normal"><a href="#__codelineno-49-28">28</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-49-1"><a id="__codelineno-49-1" name="__codelineno-49-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">convolution_2D_tiled_const_mem_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span>
</span><span id="__span-49-2"><a id="__codelineno-49-2" name="__codelineno-49-2"></a><span class="w">                                                      </span><span class="kt">int</span><span class="w"> </span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-49-3"><a id="__codelineno-49-3" name="__codelineno-49-3"></a><span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">Ns</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="p">][</span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="p">];</span><span class="w"> </span><span class="c1">// input with halo</span>
</span><span id="__span-49-4"><a id="__codelineno-49-4" name="__codelineno-49-4"></a>
</span><span id="__span-49-5"><a id="__codelineno-49-5" name="__codelineno-49-5"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-49-6"><a id="__codelineno-49-6" name="__codelineno-49-6"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-49-7"><a id="__codelineno-49-7" name="__codelineno-49-7"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row_o</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ty</span><span class="p">;</span><span class="w"> </span><span class="c1">// ÂÖ®Â±ÄËæìÂá∫ÂùêÊ†á</span>
</span><span id="__span-49-8"><a id="__codelineno-49-8" name="__codelineno-49-8"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">col_o</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tx</span><span class="p">;</span>
</span><span id="__span-49-9"><a id="__codelineno-49-9" name="__codelineno-49-9"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">row_o</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">r</span><span class="p">;</span><span class="w"> </span><span class="c1">// ËæìÂÖ•</span>
</span><span id="__span-49-10"><a id="__codelineno-49-10" name="__codelineno-49-10"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">col_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">col_o</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">r</span><span class="p">;</span>
</span><span id="__span-49-11"><a id="__codelineno-49-11" name="__codelineno-49-11"></a>
</span><span id="__span-49-12"><a id="__codelineno-49-12" name="__codelineno-49-12"></a><span class="w">    </span><span class="c1">// Load shared memory (with boundary check)</span>
</span><span id="__span-49-13"><a id="__codelineno-49-13" name="__codelineno-49-13"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="n">row_i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">row_i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">col_i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">col_i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">))</span>
</span><span id="__span-49-14"><a id="__codelineno-49-14" name="__codelineno-49-14"></a><span class="w">        </span><span class="n">Ns</span><span class="p">[</span><span class="n">ty</span><span class="p">][</span><span class="n">tx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">[</span><span class="n">row_i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col_i</span><span class="p">];</span>
</span><span id="__span-49-15"><a id="__codelineno-49-15" name="__codelineno-49-15"></a><span class="w">    </span><span class="k">else</span>
</span><span id="__span-49-16"><a id="__codelineno-49-16" name="__codelineno-49-16"></a><span class="w">        </span><span class="n">Ns</span><span class="p">[</span><span class="n">ty</span><span class="p">][</span><span class="n">tx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-49-17"><a id="__codelineno-49-17" name="__codelineno-49-17"></a>
</span><span id="__span-49-18"><a id="__codelineno-49-18" name="__codelineno-49-18"></a><span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-49-19"><a id="__codelineno-49-19" name="__codelineno-49-19"></a>
</span><span id="__span-49-20"><a id="__codelineno-49-20" name="__codelineno-49-20"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-49-21"><a id="__codelineno-49-21" name="__codelineno-49-21"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ty</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">row_o</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col_o</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-49-22"><a id="__codelineno-49-22" name="__codelineno-49-22"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span><span id="__span-49-23"><a id="__codelineno-49-23" name="__codelineno-49-23"></a><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span>
</span><span id="__span-49-24"><a id="__codelineno-49-24" name="__codelineno-49-24"></a><span class="w">                </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">F_const</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Ns</span><span class="p">[</span><span class="n">ty</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">][</span><span class="n">tx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">];</span>
</span><span id="__span-49-25"><a id="__codelineno-49-25" name="__codelineno-49-25"></a>
</span><span id="__span-49-26"><a id="__codelineno-49-26" name="__codelineno-49-26"></a><span class="w">        </span><span class="n">P</span><span class="p">[</span><span class="n">row_o</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col_o</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-49-27"><a id="__codelineno-49-27" name="__codelineno-49-27"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-49-28"><a id="__codelineno-49-28" name="__codelineno-49-28"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="reuse-analysis">Reuse Analysis<a class="headerlink" href="#reuse-analysis" title="Permanent link">&para;</a></h3>
<h4 id="a-small-1d-convolution-example">A Small 1D Convolution Example<a class="headerlink" href="#a-small-1d-convolution-example" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250924225144480.png" alt="image-20250924225144480" style="zoom:33%;" /></p>
<ul>
<li><code>8+(5-1) = 12</code> unique elements of input array N loaded</li>
<li><code>8*5=40</code> global memory accesses potentially replaced by shared memory accesses</li>
<li>This gives a bandwidth reduction of <strong>40/12=3.3</strong></li>
<li>This is independent of the size of <code>N</code></li>
</ul>
<blockquote>
<p>[!IMPORTANT]</p>
<p>In General, for <strong>1D Convolution Kernels</strong>(inner tiles)</p>
<p>Load <code>(TILE_WIDTH + MASK_WIDTH ‚Äì 1)</code> elements from global memory to shared memory</p>
<p>Replace <code>(TILE_WIDTH * MASK_WIDTH)</code> global memory accesses with shared memory accesses</p>
<ul>
<li><strong>Bandwidth reduction</strong> of <code>(TILE_SIZE * MASK_WIDTH) / (TILE_SIZE + MASK_WIDTH - 1)</code></li>
</ul>
</blockquote>
<h5 id="boundary-tiles-ghost-elements-change-ratios">Boundary Tiles (Ghost Elements Change Ratios)<a class="headerlink" href="#boundary-tiles-ghost-elements-change-ratios" title="Permanent link">&para;</a></h5>
<p><img src="./assets/image-20250925173449177.png" alt="image-20250925173449177" style="zoom:33%;" /></p>
<p>For a <strong>boundary tile</strong>, we load <code>TILE_WIDTH + (MASK_WIDTH-1)/2 elements</code></p>
<ul>
<li><code>10</code> in our example of <code>TILE_WIDTH</code> of 8 and <code>MASK_WIDTH</code> of 5</li>
</ul>
<p>Computing boundary elements do not access global memory for ghost cells</p>
<ul>
<li>Total accesses is <code>6*5 + 4 + 3 = 37</code> accesses (when computing the P elements)</li>
</ul>
<p>The reduction is <strong>37/10 = 3.7</strong></p>
<h4 id="example-of-2d-convolution-example">Example of 2D Convolution Example<a class="headerlink" href="#example-of-2d-convolution-example" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250923100747766.png" alt="image-20250923100747766" style="zoom: 25%;" /></p>
<p>Global memory accesses/shared memory accesses</p>
<blockquote>
<p>[!IMPORTANT]</p>
<p>In gerneral, for <strong>2D Convolution Kernel</strong>(<em>inner tiles</em>)</p>
<p><code>(TILE_WIDTH+MASK_WIDTH-1)^2</code> elements need to be loaded from N into shared memory</p>
<ul>
<li>The calculation of each P element needs to access <code>MASK_WIDTH^2</code> elements of N</li>
<li><code>(TILE_WIDTH * MASK_WIDTH)^2</code> global memory accesses converted into shared 
      memory accesses</li>
<li><strong>Bandwidth reduction</strong> of <code>(TILE_WIDTH * MASK_WIDTH)^2 / (TILE_WIDTH + MASK_WIDTH - 1)^2</code></li>
</ul>
</blockquote>
<h5 id="boundary-tiles-ghost-elements-change-ratios_1">Boundary Tiles (Ghost Elements Change Ratios)<a class="headerlink" href="#boundary-tiles-ghost-elements-change-ratios_1" title="Permanent link">&para;</a></h5>
<p>For a <strong>boundary tile</strong>, we load <code>[TILE_WIDTH + (MASK_WIDTH-1)/2]^2 elements</code></p>
<ul>
<li><code>100</code> in our example of <code>TILE_WIDTH</code> of 8 and <code>MASK_WIDTH</code> of 5</li>
</ul>
<p>Computing boundary elements do not access global memory for ghost cells</p>
<ul>
<li>Total accesses is <code>3^2 + (3*4)*2 + (3*5)*12 + 4^2 + (4*5)*12 + 5^2*36=1,369</code> accesses (when computing the P elements)</li>
</ul>
<p>The reduction is <strong>1369/100 = 13.69</strong></p>
<h3 id="2bflop-for-untiled-convolution">2B/FLOP for Untiled Convolution<a class="headerlink" href="#2bflop-for-untiled-convolution" title="Permanent link">&para;</a></h3>
<p><strong>How much global memory per FLOP is in untiled convolution?</strong></p>
<ul>
<li>In untiled convolution Êó†ËæπÁïåÂç∑ÁßØ, each value from <strong>N</strong> (<em>4B</em> from global memory) is multiplied by a value from <strong>M</strong>(<strong>4B</strong> from constant cache, <em>1 FLOP</em>), then added to a running sum (<em>1 FLOP</em>)</li>
<li>That gives <em>2B/FLOP</em></li>
</ul>
<p><img src="./assets/image-20250923101706216.png" alt="image-20250923101706216" style="zoom: 25%;" /></p>
<p><img src="./assets/image-20250925200115825.png" alt="image-20250925200115825" style="zoom: 25%;" /></p>
<p>Shared memory &rarr; better performance</p>
<hr />
<p>Ampere SM Memory Architecture</p>
<p><img src="./assets/image-20250925201333130.png" alt="image-20250925201333130" style="zoom:33%;" /></p>
<h3 id="memory-hierarchy-considerations">Memory Hierarchy Considerations<a class="headerlink" href="#memory-hierarchy-considerations" title="Permanent link">&para;</a></h3>
<p>Register file is highly banked È´òÂ∫¶ÂàÜÁªÑÂåñ, but we can have bank conflicts that cause pipeline stalls ÊµÅÊ∞¥Á∫øÂÅúÈ°ø</p>
<p><strong>Shared memory is highly banked</strong>, but we can have bank conflicts that cause pipeline stalls</p>
<p>Global memory has multiple channels, banks, pages</p>
<ul>
<li>Relies on bursting ‰æùËµñ‰∫éÁ™ÅÂèë</li>
<li>Coalescing is important. ÂêàÂπ∂</li>
<li>Need programmer involvement.</li>
</ul>
<p>L1 Cache is non-coherent Èùû‰∏ÄËá¥ÊÄßÁöÑ</p>
<h3 id="problem-solving_3">Problem Solving<a class="headerlink" href="#problem-solving_3" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250925202400763.png" alt="image-20250925202400763" style="zoom: 33%;" /></p>
<p><img src="./assets/image-20250925203524924.png" alt="image-20250925203524924" style="zoom:33%;" /></p>
<p><a href="# Control Divergence">Control Divergence</a></p>
<p>Why It Happens in This Case</p>
<ol>
<li>
<p><strong>The Setup:</strong> You have a 32√ó32 block of threads. The threads on the outermost border are only responsible for loading the "halo" or "apron" data. Only the inner 30√ó30 threads are responsible for calculating the final output pixels.</p>
</li>
<li>
<p><strong>The <code>if</code> Statement:</strong> To separate these roles, the kernel code must contain an <code>if</code> statement. Conceptually, it looks like this:</p>
<p>C++</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-50-1">1</a></span>
<span class="normal"><a href="#__codelineno-50-2">2</a></span>
<span class="normal"><a href="#__codelineno-50-3">3</a></span>
<span class="normal"><a href="#__codelineno-50-4">4</a></span>
<span class="normal"><a href="#__codelineno-50-5">5</a></span>
<span class="normal"><a href="#__codelineno-50-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-50-1"><a id="__codelineno-50-1" name="__codelineno-50-1"></a><span class="c1">// thread_x and thread_y are the thread&#39;s coordinates (0-31)</span>
</span><span id="__span-50-2"><a id="__codelineno-50-2" name="__codelineno-50-2"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">thread_x</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">thread_x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">31</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">thread_y</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">thread_y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">31</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-50-3"><a id="__codelineno-50-3" name="__codelineno-50-3"></a><span class="w">    </span><span class="c1">// I am an &quot;inner&quot; thread. Do the convolution calculation.</span>
</span><span id="__span-50-4"><a id="__codelineno-50-4" name="__codelineno-50-4"></a><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-50-5"><a id="__codelineno-50-5" name="__codelineno-50-5"></a><span class="w">    </span><span class="c1">// I am a &quot;border&quot; thread. Do nothing.</span>
</span><span id="__span-50-6"><a id="__codelineno-50-6" name="__codelineno-50-6"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
</li>
<li>
<p><strong>Analyzing a Middle Warp (Warps 1-30):</strong> Let's consider Warp 16, which might handle the 17<sup>th</sup> row of the tile (where <code>thread_y = 16</code>). This warp consists of 32 threads with <code>thread_x</code> coordinates from 0 to 31.</p>
<p>When this warp hits the <code>if</code> statement:</p>
<ul>
<li><strong>Thread 0</strong> (<code>thread_x = 0</code>): The condition is <code>false</code>. It wants to take the <code>else</code> path.</li>
<li><strong>Threads 1 through 30</strong> (<code>thread_x</code> is 1-30): The condition is <code>true</code>. These <strong>30 threads</strong> want to take the <code>if</code> path and compute.</li>
<li><strong>Thread 31</strong> (<code>thread_x = 31</code>): The condition is <code>false</code>. It wants to take the <code>else</code> path.</li>
</ul>
<p>Because the 32 threads within this single warp disagree‚Äî30 go one way and 2 go the other‚Äîthe warp experiences <strong>control divergence</strong>. This exact scenario happens for all the warps that handle rows 1 through 30.</p>
</li>
</ol>
<p>By contrast, Warp 0 (handling row 0) and Warp 31 (handling row 31) have <strong>no divergence</strong> because all 32 threads within them uniformly fail the condition and take the <code>else</code> path together.</p>
<hr />
<p><img src="./assets/image-20250925210040891.png" alt="image-20250925210040891" style="zoom: 40%;" /></p>
<h2 id="10-introduction-to-ml-inference-and-training-in-dnns">10 Introduction to ML; Inference and Training in DNNs<a class="headerlink" href="#10-introduction-to-ml-inference-and-training-in-dnns" title="Permanent link">&para;</a></h2>
<h3 id="machine-learning">Machine Learning<a class="headerlink" href="#machine-learning" title="Permanent link">&para;</a></h3>
<p><strong>Machine learning</strong>: important method of building applications whose logic is not fully understood</p>
<p>Typically, by example:</p>
<ul>
<li><strong>use labeled data</strong> (matched input-output pairs)</li>
<li><strong>to represent</strong> desired <strong>relationship</strong></li>
</ul>
<p><strong>Iteratively adjust program logic</strong> to produce desired/approximate answers (called <strong>training</strong>)</p>
<p>Types of Learning Tasks</p>
<ul>
<li>Classification, Regression &lt;- structured data</li>
<li>Transcription, Translation &lt;- unstructured data</li>
</ul>
<p>ML now: computing power(GPU), data, needs</p>
<ul>
<li><strong>Computing Power</strong>: GPU computing hardware and programming interfaces such as CUDA has enabled very fast research cycle of deep neural net training</li>
<li><strong>Data</strong>: Lots of cheap sensors, cloud storage, IoT, photo sharing, etc.</li>
<li><strong>Needs</strong>: Autonomous Vehicles, Smart Devices, Security, Societal Comfort with Tech, Health Care</li>
</ul>
<h3 id="classification">Classification<a class="headerlink" href="#classification" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20250925210619675.png" alt="image-20250925210619675" style="zoom:33%;" /></p>
<h4 id="linear-classificationperceptron">Linear Classification(perceptronÊÑüÁü•Âô®)<a class="headerlink" href="#linear-classificationperceptron" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250925210744039.png" alt="image-20250925210744039" style="zoom:33%;" /></p>
<p>perceptron function: <strong>y = sign (W‚àôx + b)</strong> (-1, 0, 1)</p>
<h3 id="multi-layer-perceptron-mlp-for-digit-recognition">Multi-Layer Perceptron (MLP) for Digit Recognition<a class="headerlink" href="#multi-layer-perceptron-mlp-for-digit-recognition" title="Permanent link">&para;</a></h3>
<p><a href="https://colab.research.google.com/drive/1Y7L_wFvp8ePwsTi7vu74Ni-X8VCANin1?usp=sharing#scrollTo=VgE1LB8I1NS3">https://colab.research.google.com/drive/1Y7L_wFvp8ePwsTi7vu74Ni-X8VCANin1?usp=sharing#scrollTo=VgE1LB8I1NS3</a></p>
<p><img src="./assets/image-20250925212233229.png" alt="image-20250925212233229" style="zoom:33%;" /></p>
<h4 id="how-do-we-determine-the-weights">How Do We Determine the Weights?<a class="headerlink" href="#how-do-we-determine-the-weights" title="Permanent link">&para;</a></h4>
<p>First layer of perceptron:
- <code>784 (28^2)</code> inputs, 10 outputs, fully connected
- <code>[10√ó784]</code> weight matrix <em>W</em>
- <code>[10 x 1]</code> bias vector <em>b</em></p>
<p>Use labeled training data to pick weights.</p>
<ul>
<li>given enough labeled input data</li>
<li>we can approximate the input-output function.</li>
</ul>
<h4 id="forward-and-backward-propagation">Forward and Backward Propagation<a class="headerlink" href="#forward-and-backward-propagation" title="Permanent link">&para;</a></h4>
<p><strong>Forward (inference)</strong>:</p>
<ul>
<li>given input <em>x</em> (for example, an image)</li>
<li>use parameters <em>œ¥</em> (<em>W</em> and <em>b</em> for each layer)</li>
<li>to compute probabilities <code>k[i]</code> (ex: for each digit i).</li>
</ul>
<p><strong>Backward (training)</strong>:</p>
<ul>
<li>given input <em>x</em>, parameters <em>œ¥</em>, and outputs <code>k[i]</code>,</li>
<li>compute error <em>E</em> based on target label <em>t</em>,</li>
<li>Then adjust <em>œ¥</em> proportionally to <em>E</em> to reduce error.</li>
</ul>
<hr />
<p><strong>To propagate error</strong> backwards ÂèçÂêë‰º†Êí≠ËØØÂ∑Æ, we <strong>use the chain rule</strong> ÈìæÂºèÊ≥ïÂàô from calculus. <strong>Smooth functions are useful.</strong> Âπ≥ÊªëÂáΩÊï∞</p>
<h4 id="sigmoidlogistic-function">Sigmoid/Logistic Function<a class="headerlink" href="#sigmoidlogistic-function" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250925214555383.png" alt="image-20250925214555383" style="zoom:33%;" /></p>
<h4 id="reluactivation-functions">ReLU(Activation Functions)<a class="headerlink" href="#reluactivation-functions" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250925214505498.png" alt="image-20250925214505498" style="zoom:33%;" /></p>
<h4 id="use-softmax-to-produce-probabilities">Use Softmax to Produce Probabilities<a class="headerlink" href="#use-softmax-to-produce-probabilities" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250925214729932.png" alt="image-20250925214729932" style="zoom: 25%;" /></p>
<p>Softmax Derivatives</p>
<p><img src="./assets/image-20250925214640388.png" alt="image-20250925214640388" style="zoom: 25%;" /></p>
<h4 id="error-function">Error Function<a class="headerlink" href="#error-function" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250925214339683.png" alt="image-20250925214339683" style="zoom: 25%;" /></p>
<h4 id="stochastic-gradient-descent">Stochastic Gradient Descent ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôç<a class="headerlink" href="#stochastic-gradient-descent" title="Permanent link">&para;</a></h4>
<p><strong>How do we calculate the weights?</strong></p>
<p>One common answer: <strong>stochastic gradient descent</strong>.</p>
<ol>
<li>
<p>Calculate the <strong>derivative</strong> of the sum of error <em>E</em> over all training inputs for all network parameters <em>œ¥</em>.</p>
</li>
<li>
<p>Change <em>œ¥</em> slightly in the opposite direction (to decrease error).</p>
</li>
<li>
<p>Repeat.</p>
</li>
</ol>
<p><img src="./assets/image-20250925213546001.png" alt="image-20250925213546001" style="zoom: 25%;" /></p>
<h4 id="example-gradient-update-with-one-layer">Example: Gradient Update with One Layer<a class="headerlink" href="#example-gradient-update-with-one-layer" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250925213244593.png" alt="image-20250925213244593" style="zoom:33%;" /></p>
<h2 id="11-computation-in-cnns-and-transformers">11 Computation in CNNs and Transformers<a class="headerlink" href="#11-computation-in-cnns-and-transformers" title="Permanent link">&para;</a></h2>
<p><strong>Convolution Naturally Supports Varying Input Size</strong>, while perceptron layers have fixed structure, so number of inputs / outputs is fixed.</p>
<h3 id="example-convolution-inputs">Example convolution Inputs<a class="headerlink" href="#example-convolution-inputs" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251005000016322.png" alt="image-20251005000016322" style="zoom:50%;" /></p>
<h3 id="why-convolution">Why Convolution<a class="headerlink" href="#why-convolution" title="Permanent link">&para;</a></h3>
<p>Sparse interactions</p>
<ul>
<li>Meaningful features in small spatial regions</li>
<li>Need fewer parameters (less storage, better statistical characteristics, faster training)</li>
<li>Need multiple layers for wide receptive field</li>
</ul>
<p>Parameter sharing</p>
<ul>
<li>Kernel mask is applied repeatedly computing layer output</li>
</ul>
<p>Equivariant Representations</p>
<ul>
<li>If input is translated, output is similarly translated</li>
<li>Output is a map of where features appear in input</li>
</ul>
<h4 id="convolution-vs-multi-layer-perceptron">Convolution vs Multi-Layer Perceptron<a class="headerlink" href="#convolution-vs-multi-layer-perceptron" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20250930100153659.png" alt="image-20250930100153659" style="zoom: 25%;" /></p>
<h4 id="anatomy-of-a-convolution-layer">Anatomy of a Convolution Layer Âç∑ÁßØÂ±ÇÂâñÊûê<a class="headerlink" href="#anatomy-of-a-convolution-layer" title="Permanent link">&para;</a></h4>
<p>Input features: A inputs each <span class="arithmatex">\(N_1 √ó N_2\)</span></p>
<p>Convolution Layer: B convolution kernels each <span class="arithmatex">\(K_1 √ó K_2\)</span></p>
<p>Output Features (total of B): A √ó B outputs each <span class="arithmatex">\((N_1 ‚Äì K_1+1) √ó (N_2 ‚Äì K_2+1)\)</span></p>
<h3 id="2-d-pooling-subsampling">2-D Pooling (Subsampling)<a class="headerlink" href="#2-d-pooling-subsampling" title="Permanent link">&para;</a></h3>
<p>A subsampling layer Â≠êÈááÊ†∑Â±Ç</p>
<ul>
<li>Sometimes with bias‰ΩçÁΩÆÂÅèÂ∑Æ and non-linearity ÈùûÁ∫øÊÄß built in</li>
</ul>
<p>Common types</p>
<ul>
<li>max, average, <span class="arithmatex">\(L^2\)</span> norm, weighted average</li>
</ul>
<p>Helps make representation invariant to size scaling and small translations in the input</p>
<p>ÊúâÂä©‰∫é‰ΩøË°®Á§∫ÂØπËæìÂÖ•‰∏≠ÁöÑÂ∞∫ÂØ∏Áº©ÊîæÂíåÂ∞èÂπÖÂπ≥Áßª‰øùÊåÅ‰∏çÂèò </p>
<h3 id="forward-propagation">Forward Propagation<a class="headerlink" href="#forward-propagation" title="Permanent link">&para;</a></h3>
<p>Example of the Forward Path of a Convolution Layer</p>
<p><img alt="image-20251005001113971" src="assets/image-20251005001113971.png" /></p>
<h4 id="sequential-code-forward-pooling-layer">Sequential Code: Forward Pooling Layer<a class="headerlink" href="#sequential-code-forward-pooling-layer" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-51-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-51-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-51-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-51-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-51-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-51-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-51-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-51-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-51-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-51-10">10</a></span>
<span class="normal"><a href="#__codelineno-51-11">11</a></span>
<span class="normal"><a href="#__codelineno-51-12">12</a></span>
<span class="normal"><a href="#__codelineno-51-13">13</a></span>
<span class="normal"><a href="#__codelineno-51-14">14</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-51-1"><a id="__codelineno-51-1" name="__codelineno-51-1"></a><span class="kt">void</span><span class="w"> </span><span class="nf">poolingLayer_forward</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">H_out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">W_out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>
</span><span id="__span-51-2"><a id="__codelineno-51-2" name="__codelineno-51-2"></a><span class="p">{</span>
</span><span id="__span-51-3"><a id="__codelineno-51-3" name="__codelineno-51-3"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">B</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="c1">// for each image</span>
</span><span id="__span-51-4"><a id="__codelineno-51-4" name="__codelineno-51-4"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">M</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="c1">// for each output feature map</span>
</span><span id="__span-51-5"><a id="__codelineno-51-5" name="__codelineno-51-5"></a><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">H_out</span><span class="o">/</span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="c1">// for each output value (two loops)</span>
</span><span id="__span-51-6"><a id="__codelineno-51-6" name="__codelineno-51-6"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">W_out</span><span class="o">/</span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-51-7"><a id="__codelineno-51-7" name="__codelineno-51-7"></a><span class="w">          </span><span class="kt">float</span><span class="w"> </span><span class="n">acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="w"> </span><span class="c1">// initialize sum to 0</span>
</span><span id="__span-51-8"><a id="__codelineno-51-8" name="__codelineno-51-8"></a><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="c1">// loop over NxN block of Y (two loops)</span>
</span><span id="__span-51-9"><a id="__codelineno-51-9" name="__codelineno-51-9"></a><span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">q</span><span class="p">)</span>
</span><span id="__span-51-10"><a id="__codelineno-51-10" name="__codelineno-51-10"></a><span class="w">                </span><span class="n">acc</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">Y</span><span class="p">[</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">q</span><span class="p">];</span>
</span><span id="__span-51-11"><a id="__codelineno-51-11" name="__codelineno-51-11"></a><span class="w">          </span><span class="n">acc</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="c1">// calculate average over block</span>
</span><span id="__span-51-12"><a id="__codelineno-51-12" name="__codelineno-51-12"></a><span class="w">          </span><span class="n">S</span><span class="p">[</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigmoid</span><span class="p">(</span><span class="n">acc</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">bias</span><span class="p">[</span><span class="n">m</span><span class="p">])</span><span class="w"> </span><span class="c1">// bias, non-linearity</span>
</span><span id="__span-51-13"><a id="__codelineno-51-13" name="__codelineno-51-13"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-51-14"><a id="__codelineno-51-14" name="__codelineno-51-14"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="host-code-for-a-basic-kernel-cuda-grid">Host Code for a Basic Kernel: CUDA Grid<a class="headerlink" href="#host-code-for-a-basic-kernel-cuda-grid" title="Permanent link">&para;</a></h4>
<p>Consider an output feature map:</p>
<ul>
<li>width is <strong>W_out</strong>, andheight is <strong>H_out</strong>.</li>
<li>Assume these are multiples of <strong>TILE_WIDTH</strong>.</li>
<li>Let <strong>X_grid</strong> be the number of blocks needed in X dim.</li>
<li>Let <strong>Y_grid</strong> be the number of blocks needed in Y dim</li>
</ul>
<p>Assuming <code>W_out</code> and <code>H_out</code> are multiples of <code>TILE_WIDTH</code></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-52-1">1</a></span>
<span class="normal"><a href="#__codelineno-52-2">2</a></span>
<span class="normal"><a href="#__codelineno-52-3">3</a></span>
<span class="normal"><a href="#__codelineno-52-4">4</a></span>
<span class="normal"><a href="#__codelineno-52-5">5</a></span>
<span class="normal"><a href="#__codelineno-52-6">6</a></span>
<span class="normal"><a href="#__codelineno-52-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-52-1"><a id="__codelineno-52-1" name="__codelineno-52-1"></a><span class="cp">#define TILE_WIDTH 16 </span><span class="c1">// We will use 4 for small examples.</span>
</span><span id="__span-52-2"><a id="__codelineno-52-2" name="__codelineno-52-2"></a><span class="n">W_grid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">W_out</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">;</span><span class="w"> </span><span class="c1">// number of horizontal tiles per output map</span>
</span><span id="__span-52-3"><a id="__codelineno-52-3" name="__codelineno-52-3"></a><span class="n">H_grid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">H_out</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">;</span><span class="w"> </span><span class="c1">// number of vertical tiles per output map</span>
</span><span id="__span-52-4"><a id="__codelineno-52-4" name="__codelineno-52-4"></a><span class="n">Y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">H_grid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W_grid</span><span class="p">;</span>
</span><span id="__span-52-5"><a id="__codelineno-52-5" name="__codelineno-52-5"></a><span class="n">dim3</span><span class="w"> </span><span class="nf">blockDim</span><span class="p">(</span><span class="n">TILE_WIDTH</span><span class="p">,</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"> </span><span class="c1">// output tile for untiled code</span>
</span><span id="__span-52-6"><a id="__codelineno-52-6" name="__codelineno-52-6"></a><span class="n">dim3</span><span class="w"> </span><span class="nf">gridDim</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-52-7"><a id="__codelineno-52-7" name="__codelineno-52-7"></a><span class="n">ConvLayerForward_Kernel</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="n">gridDim</span><span class="p">,</span><span class="w"> </span><span class="n">blockDim</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="err">‚Ä¶</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="forward-convolutional-layer">Forward Convolutional Layer Âç∑ÁßØÂâçÂêë‰º†Êí≠<a class="headerlink" href="#forward-convolutional-layer" title="Permanent link">&para;</a></h4>
<p>CPU‰∏≤Ë°å Sequential Code</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-53-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-53-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-53-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-53-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-53-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-53-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-53-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-53-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-53-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-53-10">10</a></span>
<span class="normal"><a href="#__codelineno-53-11">11</a></span>
<span class="normal"><a href="#__codelineno-53-12">12</a></span>
<span class="normal"><a href="#__codelineno-53-13">13</a></span>
<span class="normal"><a href="#__codelineno-53-14">14</a></span>
<span class="normal"><a href="#__codelineno-53-15">15</a></span>
<span class="normal"><a href="#__codelineno-53-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-53-1"><a id="__codelineno-53-1" name="__codelineno-53-1"></a><span class="kt">void</span><span class="w"> </span><span class="nf">convLayer_forward</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">H</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">K</span><span class="p">,</span>
</span><span id="__span-53-2"><a id="__codelineno-53-2" name="__codelineno-53-2"></a><span class="w">                       </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">Y</span><span class="p">)</span>
</span><span id="__span-53-3"><a id="__codelineno-53-3" name="__codelineno-53-3"></a><span class="p">{</span>
</span><span id="__span-53-4"><a id="__codelineno-53-4" name="__codelineno-53-4"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">H_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="c1">// calculate H_out, W_out</span>
</span><span id="__span-53-5"><a id="__codelineno-53-5" name="__codelineno-53-5"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">W_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
</span><span id="__span-53-6"><a id="__codelineno-53-6" name="__codelineno-53-6"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">B</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="c1">// for each image</span>
</span><span id="__span-53-7"><a id="__codelineno-53-7" name="__codelineno-53-7"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">M</span><span class="p">;</span><span class="w"> </span><span class="n">m</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="c1">// for each output feature map</span>
</span><span id="__span-53-8"><a id="__codelineno-53-8" name="__codelineno-53-8"></a><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">H_out</span><span class="p">;</span><span class="w"> </span><span class="n">h</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="c1">// for each output value (two loops)</span>
</span><span id="__span-53-9"><a id="__codelineno-53-9" name="__codelineno-53-9"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">W_out</span><span class="p">;</span><span class="w"> </span><span class="n">w</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-53-10"><a id="__codelineno-53-10" name="__codelineno-53-10"></a><span class="w">          </span><span class="n">Y</span><span class="p">[</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span><span class="w"> </span><span class="c1">// initialize sum to 0</span>
</span><span id="__span-53-11"><a id="__codelineno-53-11" name="__codelineno-53-11"></a><span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="c1">// sum over all input channels</span>
</span><span id="__span-53-12"><a id="__codelineno-53-12" name="__codelineno-53-12"></a><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="c1">// KxK filter</span>
</span><span id="__span-53-13"><a id="__codelineno-53-13" name="__codelineno-53-13"></a><span class="w">              </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">;</span><span class="w"> </span><span class="n">q</span><span class="o">++</span><span class="p">)</span>
</span><span id="__span-53-14"><a id="__codelineno-53-14" name="__codelineno-53-14"></a><span class="w">                </span><span class="n">Y</span><span class="p">[</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">q</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">];</span>
</span><span id="__span-53-15"><a id="__codelineno-53-15" name="__codelineno-53-15"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-53-16"><a id="__codelineno-53-16" name="__codelineno-53-16"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>ÊúÄÂ§ñ‰æß4‰∏™Âæ™ÁéØÊòØgridËÆ°ÁÆóÔºåÈáåÈù¢4‰∏™Âæ™ÁéØÊòØthreadËÆ°ÁÆó</li>
</ul>
<p>GPUÂπ∂Ë°å Partial Kernel Code for a Convolution Layer</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-54-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-54-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-54-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-54-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-54-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-54-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-54-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-54-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-54-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-54-10">10</a></span>
<span class="normal"><a href="#__codelineno-54-11">11</a></span>
<span class="normal"><a href="#__codelineno-54-12">12</a></span>
<span class="normal"><a href="#__codelineno-54-13">13</a></span>
<span class="normal"><a href="#__codelineno-54-14">14</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-54-1"><a id="__codelineno-54-1" name="__codelineno-54-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ConvLayerForward_Basic_Kernel</span>
</span><span id="__span-54-2"><a id="__codelineno-54-2" name="__codelineno-54-2"></a><span class="w">  </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">W_grid</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">K</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">Y</span><span class="p">)</span><span class="w"> </span><span class="c1">// cudaÂÜÖÊ†∏ÂáΩÊï∞</span>
</span><span id="__span-54-3"><a id="__codelineno-54-3" name="__codelineno-54-3"></a><span class="p">{</span>
</span><span id="__span-54-4"><a id="__codelineno-54-4" name="__codelineno-54-4"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"> </span><span class="c1">// ÊØè‰∏™Á∫øÁ®ãÂùóÔºàBlockÔºâË¥üË¥£ËÆ°ÁÆó‰∏Ä‰∏™ËæìÂá∫ÁâπÂæÅÂõæ</span>
</span><span id="__span-54-5"><a id="__codelineno-54-5" name="__codelineno-54-5"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">W_grid</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-54-6"><a id="__codelineno-54-6" name="__codelineno-54-6"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">W_grid</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-54-7"><a id="__codelineno-54-7" name="__codelineno-54-7"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-54-8"><a id="__codelineno-54-8" name="__codelineno-54-8"></a><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// sum over all input channels</span>
</span><span id="__span-54-9"><a id="__codelineno-54-9" name="__codelineno-54-9"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="c1">// loop over KxK filter</span>
</span><span id="__span-54-10"><a id="__codelineno-54-10" name="__codelineno-54-10"></a><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">;</span><span class="w"> </span><span class="n">q</span><span class="o">++</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-54-11"><a id="__codelineno-54-11" name="__codelineno-54-11"></a><span class="w">        </span><span class="n">acc</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">q</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">];</span>
</span><span id="__span-54-12"><a id="__codelineno-54-12" name="__codelineno-54-12"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-54-13"><a id="__codelineno-54-13" name="__codelineno-54-13"></a><span class="w">  </span><span class="n">Y</span><span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc</span><span class="p">;</span>
</span><span id="__span-54-14"><a id="__codelineno-54-14" name="__codelineno-54-14"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>Image batch is omitted</li>
</ul>
<h2 id="13-atomic-operations-and-histogramming">13  Atomic Operations and Histogramming<a class="headerlink" href="#13-atomic-operations-and-histogramming" title="Permanent link">&para;</a></h2>
<blockquote>
<p>[!NOTE]</p>
<p>To understand atomic operations
  - Read-modify-write in parallel computation
  - A primitive form of ‚Äúcritical regions‚Äù in parallel programs
  - Use of atomic operations in CUDA
  - Why atomic operations reduce memory system throughput
  - How to avoid atomic operations in some parallel algorithms</p>
<p>To learn practical histogram programming techniques
  - Basic histogram algorithm using atomic operations
  - Atomic operation throughput
  - Privatization</p>
</blockquote>
<p>A Common Collaboration Pattern Âêà‰ΩúÊ®°Âºè</p>
<p>Èì∂Ë°åÊØè‰∏™‰∫∫Êï∞‰∏ÄÈÉ®ÂàÜÈí±ÔºåËÆ°Âà∞ÊÄªÊï∞‰∏äÔºå‰ΩÜÊúâ‰∫õÂèØËÉΩÊ≤°ËÆ∞‰∏ä</p>
<p>A Common Arbitration Pattern ‰ª≤Ë£ÅÊ®°Âºè</p>
<p>Â§ö‰∏™‰∫∫ÂçïÁã¨‰π∞Ëá™Â∑±ÁöÑÊú∫Á•®Ôºå‰ΩÜÂèØËÉΩÊúÄÂêéÂêå‰∏Ä‰∏™‰ΩçÁΩÆË¢´ÈáçÂ§çÈ¢ÑÂÆö</p>
<p><img src="./assets/image-20251015142741798.png" alt="image-20251015142741798" style="zoom:50%;" /></p>
<h3 id="data-races">Data Races<a class="headerlink" href="#data-races" title="Permanent link">&para;</a></h3>
<p>A <strong>data race</strong> Á´û‰∫â occurs when multiple threads access the <strong>same memory location concurrently</strong> without ordering, and at least one access is a <strong>write</strong></p>
<ul>
<li>Data races may result in unpredictable program output</li>
<li>To avoid data races, you should use <strong>atomic operations</strong> ÂéüÂ≠êÊìç‰Ωú</li>
</ul>
<p><img src="./assets/image-20251015143017902.png" alt="image-20251015143017902" style="zoom: 67%;" /></p>
<h3 id="mutual-exclusion">Mutual Exclusion ‰∫íÊñ•<a class="headerlink" href="#mutual-exclusion" title="Permanent link">&para;</a></h3>
<p>To avoid data races, concurrent read-modify-write operations to the same memory location need to be made <strong>mutually exclusive</strong> to enforce ordering Âº∫Âà∂ÊéíÂ§ñ</p>
<p>One way to do this on CPUs is using <strong>locks</strong> (mutex)</p>
<p>Example:</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-55-1">1</a></span>
<span class="normal"><a href="#__codelineno-55-2">2</a></span>
<span class="normal"><a href="#__codelineno-55-3">3</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-55-1"><a id="__codelineno-55-1" name="__codelineno-55-1"></a><span class="n">mutex_lock</span><span class="p">(</span><span class="n">lock</span><span class="p">);</span>
</span><span id="__span-55-2"><a id="__codelineno-55-2" name="__codelineno-55-2"></a><span class="o">++</span><span class="n">bins</span><span class="p">[</span><span class="n">b</span><span class="p">];</span>
</span><span id="__span-55-3"><a id="__codelineno-55-3" name="__codelineno-55-3"></a><span class="n">mutex_unlock</span><span class="p">(</span><span class="n">lock</span><span class="p">);</span>
</span></code></pre></div></td></tr></table></div>
<p><img src="./assets/image-20251015144219737.png" alt="image-20251015144219737" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251015144234781.png" alt="image-20251015144234781" style="zoom:50%;" /></p>
<h3 id="atomic-operations">Atomic Operations<a class="headerlink" href="#atomic-operations" title="Permanent link">&para;</a></h3>
<p><strong>Atomic operations</strong> perform read-modify-write with a single ISA instruction(Instruction Set Architecture Êåá‰ª§ÈõÜÊû∂ÊûÑ)</p>
<p>The hardware guarantees that no other thread can access the memory location until the operation completes</p>
<p>Concurrent atomic operations to the same memory location are serialized by the hardware ÂØπÂêå‰∏ÄÂÜÖÂ≠ò‰ΩçÁΩÆÁöÑÂπ∂ÂèëÂéüÂ≠êÊìç‰ΩúÁî±Á°¨‰ª∂Â∫èÂàóÂåñ</p>
<p>When <strong>two threads may write to</strong> the <strong>same memory</strong> location, the program may <strong>need atomic operations</strong>.</p>
<ul>
<li>Sharing is <strong>not always easy to recognize</strong>‚Ä¶</li>
<li>Do two insertions into a hash table share data?</li>
<li>What about two graph node updates based on all of the nodes‚Äô neighbors?</li>
<li>What if nodes are on same side of bipartite graph?</li>
</ul>
<p>Common failure mode:</p>
<ul>
<li><strong>Programmer</strong> <strong>thinks</strong> <strong>operations</strong> are <strong>independent</strong>.</li>
<li>Hasn‚Äôt considered input data for which they are not.</li>
<li>Or another programmer reuses code without understanding assumptions that imply independence.</li>
</ul>
<p>Also: <strong>atomicity does not constrain relative order</strong>.</p>
<h4 id="implementing-atomic-operations">Implementing Atomic Operations<a class="headerlink" href="#implementing-atomic-operations" title="Permanent link">&para;</a></h4>
<p>Many ISAs offer synchronization primitives, instructions with one (or more) address operands</p>
<p>that execute atomically with respect to one another when used on the same address.</p>
<p>Mostly read, modify, write operations</p>
<ul>
<li>Bit test and set</li>
<li>Compare and swap / exchange</li>
<li>Swap / exchange</li>
<li>Fetch and increment / add</li>
</ul>
<h4 id="atomicity-enforced-by-microarchitecture">Atomicity Enforced by Microarchitecture<a class="headerlink" href="#atomicity-enforced-by-microarchitecture" title="Permanent link">&para;</a></h4>
<p>When synchronization primitives execute, <strong>hardware ensures</strong> that <strong>no other</strong> thread <strong>accesses</strong> the location <strong>until</strong> the operation is <strong>complete</strong>.</p>
<p>Other threads that access the locationare typically stalled or held in a queue until their turn.</p>
<p><strong>Threads perform atomic operations serially</strong>. Á∫øÁ®ã‰∏≤Ë°åÂÆûÁé∞ÂéüÂ≠êÊìç‰Ωú</p>
<h4 id="atomic-compare-and-swap-cas">Atomic Compare and Swap (CAS)<a class="headerlink" href="#atomic-compare-and-swap-cas" title="Permanent link">&para;</a></h4>
<p>CAS is an atomic instruction used in multithreading to achieve synchronization. CASÊòØÂ§öÁ∫øÁ®ã‰∏≠Áî®Êù•ÂÆûÁé∞ÂêåÊ≠•ÁöÑÂéüÂ≠êÊåá‰ª§</p>
<p>It compares the contents of a memory location with a given value and, only if they are the same, modifies the contents of that memory location to a new given value. This is done as a single atomic operation.</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-56-1">1</a></span>
<span class="normal"><a href="#__codelineno-56-2">2</a></span>
<span class="normal"><a href="#__codelineno-56-3">3</a></span>
<span class="normal"><a href="#__codelineno-56-4">4</a></span>
<span class="normal"><a href="#__codelineno-56-5">5</a></span>
<span class="normal"><a href="#__codelineno-56-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-56-1"><a id="__codelineno-56-1" name="__codelineno-56-1"></a><span class="kt">bool</span><span class="w"> </span><span class="nf">atomicCAS</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">address</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">old</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">new</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-56-2"><a id="__codelineno-56-2" name="__codelineno-56-2"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">*</span><span class="n">address</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">old</span><span class="p">)</span>
</span><span id="__span-56-3"><a id="__codelineno-56-3" name="__codelineno-56-3"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
</span><span id="__span-56-4"><a id="__codelineno-56-4" name="__codelineno-56-4"></a><span class="w">  </span><span class="o">*</span><span class="n">address</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new</span><span class="p">;</span>
</span><span id="__span-56-5"><a id="__codelineno-56-5" name="__codelineno-56-5"></a><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
</span><span id="__span-56-6"><a id="__codelineno-56-6" name="__codelineno-56-6"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="atomic-operations-in-cuda">Atomic Operations in CUDA<a class="headerlink" href="#atomic-operations-in-cuda" title="Permanent link">&para;</a></h3>
<p>The function performs the action <code>*address ‚Üê *address + value</code> atomically and returns the original value stored at address. </p>
<p>There is no requirement that any sequence of operations is atomic except for atomicCAS. Èô§ atomicCAS Â§ñÔºåÂÖ∂‰ªñÊìç‰ΩúÂ∫èÂàóÂùá‰∏çË¶ÅÊ±ÇÂéüÂ≠êÊÄß„ÄÇ</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-57-1">1</a></span>
<span class="normal"><a href="#__codelineno-57-2">2</a></span>
<span class="normal"><a href="#__codelineno-57-3">3</a></span>
<span class="normal"><a href="#__codelineno-57-4">4</a></span>
<span class="normal"><a href="#__codelineno-57-5">5</a></span>
<span class="normal"><a href="#__codelineno-57-6">6</a></span>
<span class="normal"><a href="#__codelineno-57-7">7</a></span>
<span class="normal"><a href="#__codelineno-57-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-57-1"><a id="__codelineno-57-1" name="__codelineno-57-1"></a><span class="kt">int</span><span class="w"> </span><span class="nf">atomicAdd</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">address</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="p">){</span>
</span><span id="__span-57-2"><a id="__codelineno-57-2" name="__codelineno-57-2"></a><span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">done</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
</span><span id="__span-57-3"><a id="__codelineno-57-3" name="__codelineno-57-3"></a><span class="w">  </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">done</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-57-4"><a id="__codelineno-57-4" name="__codelineno-57-4"></a><span class="w">    </span><span class="n">old_v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">address</span><span class="p">;</span>
</span><span id="__span-57-5"><a id="__codelineno-57-5" name="__codelineno-57-5"></a><span class="w">    </span><span class="n">done</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">atomicCAS</span><span class="p">(</span><span class="n">address</span><span class="p">,</span><span class="w"> </span><span class="n">old_v</span><span class="p">,</span><span class="w"> </span><span class="n">old_v</span><span class="o">+</span><span class="n">value</span><span class="p">);</span>
</span><span id="__span-57-6"><a id="__codelineno-57-6" name="__codelineno-57-6"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-57-7"><a id="__codelineno-57-7" name="__codelineno-57-7"></a><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">old_v</span><span class="p">;</span>
</span><span id="__span-57-8"><a id="__codelineno-57-8" name="__codelineno-57-8"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p><strong><code>T atomicAdd(T* address, T val)</code></strong></p>
<ul>
<li>T can be int, unsigned int, float, double, etc.</li>
<li>Reads the value stored at <code>address</code>, adds <code>val</code> to it, stores the new value at address, and returns the old value originally stored</li>
<li>Function call translated to a single ISA instruction</li>
<li>Such special functions are called <em>intrinsics</em> ÂÜÖÂú®ÂáΩÊï∞</li>
</ul>
<h4 id="code-with-atomic-operations">Code with Atomic Operations<a class="headerlink" href="#code-with-atomic-operations" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251015150915954.png" alt="image-20251015150915954" style="zoom:50%;" /></p>
<h3 id="histogramming">Histogramming Áõ¥ÊñπÂõæ<a class="headerlink" href="#histogramming" title="Permanent link">&para;</a></h3>
<p>A method for extracting notable features and patterns from large data sets</p>
<ul>
<li>Feature extraction for object recognition in images</li>
<li>Fraud detection in credit card transactions</li>
<li>Correlating heavenly object movements in astrophysics</li>
</ul>
<p>Basic histograms - for each element in the data set, use the value to identify a ‚Äúbin‚Äù to increment</p>
<p><img src="./assets/image-20251015153513481.png" alt="image-20251015153513481" style="zoom:50%;" /></p>
<p>Problems: Reads from the input array are <em>not coalesced</em></p>
<ul>
<li>Assign inputs to each thread in a strided pattern</li>
<li>Adjacent threads process adjacent input letters</li>
</ul>
<h4 id="a-histogram-kernel">A Histogram Kernel<a class="headerlink" href="#a-histogram-kernel" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-58-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-58-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-58-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-58-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-58-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-58-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-58-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-58-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-58-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-58-10">10</a></span>
<span class="normal"><a href="#__codelineno-58-11">11</a></span>
<span class="normal"><a href="#__codelineno-58-12">12</a></span>
<span class="normal"><a href="#__codelineno-58-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-58-1"><a id="__codelineno-58-1" name="__codelineno-58-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span>
</span><span id="__span-58-2"><a id="__codelineno-58-2" name="__codelineno-58-2"></a><span class="p">{</span>
</span><span id="__span-58-3"><a id="__codelineno-58-3" name="__codelineno-58-3"></a><span class="w">  </span><span class="n">histo_kernel</span><span class="p">(</span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">histo</span><span class="p">)</span>
</span><span id="__span-58-4"><a id="__codelineno-58-4" name="__codelineno-58-4"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-58-5"><a id="__codelineno-58-5" name="__codelineno-58-5"></a><span class="w">  </span><span class="c1">// stride = total # of threads</span>
</span><span id="__span-58-6"><a id="__codelineno-58-6" name="__codelineno-58-6"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"> </span>
</span><span id="__span-58-7"><a id="__codelineno-58-7" name="__codelineno-58-7"></a><span class="w">  </span><span class="c1">// All threads in the grid collectively handle </span>
</span><span id="__span-58-8"><a id="__codelineno-58-8" name="__codelineno-58-8"></a><span class="w">  </span><span class="c1">// blockDim.x * gridDim.x consecutive elements</span>
</span><span id="__span-58-9"><a id="__codelineno-58-9" name="__codelineno-58-9"></a><span class="w">  </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-58-10"><a id="__codelineno-58-10" name="__codelineno-58-10"></a><span class="w">    </span><span class="n">atomicAdd</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="p">(</span><span class="n">histo</span><span class="p">[</span><span class="n">buf</span><span class="p">[</span><span class="n">i</span><span class="p">]]),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"> </span><span class="c1">//ASCII value is the bin number</span>
</span><span id="__span-58-11"><a id="__codelineno-58-11" name="__codelineno-58-11"></a><span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stride</span><span class="p">;</span>
</span><span id="__span-58-12"><a id="__codelineno-58-12" name="__codelineno-58-12"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-58-13"><a id="__codelineno-58-13" name="__codelineno-58-13"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="atomic-operations-on-dram">Atomic Operations on DRAM<a class="headerlink" href="#atomic-operations-on-dram" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251015155141297.png" alt="image-20251015155141297" style="zoom:50%;" /></p>
<h4 id="high-latency">High Latency<a class="headerlink" href="#high-latency" title="Permanent link">&para;</a></h4>
<p>Atomic operations on global memory have high latency</p>
<ul>
<li>Need to <strong>wait for both read and write</strong> to complete</li>
<li>Need to wait if there are other threads accessing the same location (high probability of contention)</li>
</ul>
<p><strong>Throughput of an atomic operation</strong> ÂéüÂ≠êÊìç‰ΩúÁöÑÂêûÂêêÈáè is the rate at which the application can execute an atomic operation on a particular location.</p>
<p>The rate is <em>limited by the total latency of the read-modify-write sequence</em>, typically more than 1000 cycles for global memory (DRAM) locations.</p>
<p>This means that if many threads attempt to do atomic operation on the same location (contention), the memory bandwidth is reduced to &lt; 1/1000!</p>
<p>ËØ•ÈÄüÁéáÂèóËØªÂèñ-‰øÆÊîπ-ÂÜôÂÖ•Â∫èÂàóÁöÑÊÄªÂª∂ËøüÈôêÂà∂ÔºåÂØπ‰∫éÂÖ®Â±ÄÂÜÖÂ≠ò (DRAM) ‰ΩçÁΩÆÔºåÈÄöÂ∏∏Ë∂ÖËøá 1000 ‰∏™Âë®Êúü„ÄÇ</p>
<p>ËøôÊÑèÂë≥ÁùÄÔºåÂ¶ÇÊûúÂ§ö‰∏™Á∫øÁ®ãÂ∞ùËØïÂú®Âêå‰∏Ä‰ΩçÁΩÆÊâßË°åÂéüÂ≠êÊìç‰ΩúÔºà‰∫âÁî®ÔºâÔºåÂÜÖÂ≠òÂ∏¶ÂÆΩÂ∞ÜÈôç‰ΩéÂà∞ &lt; 1/1000ÔºÅ</p>
<p>Latency ÊØè‰∏™È°æÂÆ¢ÂÖàÂºÄÂßãÁªìË¥¶ÂÜçÂõûÂéªË¥≠Áâ©</p>
<h4 id="hardware-improvements">Hardware Improvements<a class="headerlink" href="#hardware-improvements" title="Permanent link">&para;</a></h4>
<p>Atomic operations on <strong>L2 cache</strong></p>
<ul>
<li>medium latency, but still serialized</li>
<li>Global to all blocks</li>
<li>‚ÄúFree improvement‚Äù on Global Memory atomics</li>
</ul>
<p>Atomic operations on <strong>Shared Memory</strong></p>
<ul>
<li>Very short latency, but still serialized</li>
<li>Private to each thread block</li>
<li>Need algorithm work by programmers (more later)</li>
</ul>
<h4 id="privatizing-the-histogram">Privatizing the Histogram<a class="headerlink" href="#privatizing-the-histogram" title="Permanent link">&para;</a></h4>
<p>È´òÁ∫ß‰ºòÂåñ</p>
<p><img src="./assets/image-20251015185531551.png" alt="image-20251015185531551" style="zoom:50%;" /></p>
<p><strong>Privatization</strong> ÁßÅÊúâÂåñ is an optimization where multiple private copies of an output are maintained, then the public copy is updated on completion</p>
<ul>
<li>Operations on the output must be associative and commutative because the order of updates has changed</li>
<li>Advantage: reduces contention on the public copy ÂáèÂ∞ë‰∫ÜÂØπÂÖ¨ÂÖ±ÂâØÊú¨ÁöÑ‰∫âÁî®</li>
</ul>
<p><strong>Atomics in Shared Memory Requires Privatization</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-59-1">1</a></span>
<span class="normal"><a href="#__codelineno-59-2">2</a></span>
<span class="normal"><a href="#__codelineno-59-3">3</a></span>
<span class="normal"><a href="#__codelineno-59-4">4</a></span>
<span class="normal"><a href="#__codelineno-59-5">5</a></span>
<span class="normal"><a href="#__codelineno-59-6">6</a></span>
<span class="normal"><a href="#__codelineno-59-7">7</a></span>
<span class="normal"><a href="#__codelineno-59-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-59-1"><a id="__codelineno-59-1" name="__codelineno-59-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">histo_kernel</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">buffer</span><span class="p">,</span>
</span><span id="__span-59-2"><a id="__codelineno-59-2" name="__codelineno-59-2"></a><span class="w">                             </span><span class="kt">long</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">histo</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-59-3"><a id="__codelineno-59-3" name="__codelineno-59-3"></a><span class="p">{</span>
</span><span id="__span-59-4"><a id="__codelineno-59-4" name="__codelineno-59-4"></a><span class="w">  </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">histo_private</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>
</span><span id="__span-59-5"><a id="__codelineno-59-5" name="__codelineno-59-5"></a><span class="w">  </span><span class="c1">// warning: this will not work correctly if there are fewer than 256 threads!</span>
</span><span id="__span-59-6"><a id="__codelineno-59-6" name="__codelineno-59-6"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">256</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-59-7"><a id="__codelineno-59-7" name="__codelineno-59-7"></a><span class="w">    </span><span class="n">histo_private</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-59-8"><a id="__codelineno-59-8" name="__codelineno-59-8"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>Create private copies of the <code>histo[]</code> array for each thread block</li>
</ul>
<p><strong>Build Private Histogram</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-60-1">1</a></span>
<span class="normal"><a href="#__codelineno-60-2">2</a></span>
<span class="normal"><a href="#__codelineno-60-3">3</a></span>
<span class="normal"><a href="#__codelineno-60-4">4</a></span>
<span class="normal"><a href="#__codelineno-60-5">5</a></span>
<span class="normal"><a href="#__codelineno-60-6">6</a></span>
<span class="normal"><a href="#__codelineno-60-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-60-1"><a id="__codelineno-60-1" name="__codelineno-60-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-60-2"><a id="__codelineno-60-2" name="__codelineno-60-2"></a><span class="c1">// stride is total number of threads</span>
</span><span id="__span-60-3"><a id="__codelineno-60-3" name="__codelineno-60-3"></a><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-60-4"><a id="__codelineno-60-4" name="__codelineno-60-4"></a><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-60-5"><a id="__codelineno-60-5" name="__codelineno-60-5"></a><span class="w">    </span><span class="n">atomicAdd</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="p">(</span><span class="n">private_histo</span><span class="p">[</span><span class="n">buffer</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-60-6"><a id="__codelineno-60-6" name="__codelineno-60-6"></a><span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stride</span><span class="p">;</span>
</span><span id="__span-60-7"><a id="__codelineno-60-7" name="__codelineno-60-7"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>Use private copies of the <code>histo[]</code> array to compute</li>
</ul>
<p><strong>Build Final Histogram</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-61-1">1</a></span>
<span class="normal"><a href="#__codelineno-61-2">2</a></span>
<span class="normal"><a href="#__codelineno-61-3">3</a></span>
<span class="normal"><a href="#__codelineno-61-4">4</a></span>
<span class="normal"><a href="#__codelineno-61-5">5</a></span>
<span class="normal"><a href="#__codelineno-61-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-61-1"><a id="__codelineno-61-1" name="__codelineno-61-1"></a><span class="c1">// wait for all other threads in the block to finish</span>
</span><span id="__span-61-2"><a id="__codelineno-61-2" name="__codelineno-61-2"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-61-3"><a id="__codelineno-61-3" name="__codelineno-61-3"></a><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">256</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-61-4"><a id="__codelineno-61-4" name="__codelineno-61-4"></a><span class="w">  </span><span class="n">atomicAdd</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="p">(</span><span class="n">histo</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]),</span><span class="w"> </span>
</span><span id="__span-61-5"><a id="__codelineno-61-5" name="__codelineno-61-5"></a><span class="w">            </span><span class="n">private_histo</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="p">);</span>
</span><span id="__span-61-6"><a id="__codelineno-61-6" name="__codelineno-61-6"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>Copy from the <code>histo[]</code> arrays from each thread block to global memory</li>
</ul>
<hr />
<p>Privatization is a powerful and frequently used technique for parallelizing applications</p>
<ul>
<li>The operation needs to be associative and commutative</li>
<li>The histogram add operation is associative and commutative</li>
<li><em>The histogram size needs to be small to fit into shared memory</em></li>
</ul>
<p>What if the histogram is too large to privatizeÔºü</p>
<blockquote>
<p>Part of in the shared memory; some threads to update a certain range of blocks; several runs, may have control divergence</p>
</blockquote>
<p><img src="./assets/image-20251015191802108.png" alt="image-20251015191802108" style="zoom:50%;" /></p>
<p><strong>Latency:</strong></p>
<ul>
<li><strong>DRAM (Global Memory) Atomics:</strong> Very slow. High latency (hundreds of cycles) means low throughput if there is contention. ÈÄüÂ∫¶ÈùûÂ∏∏ÊÖ¢„ÄÇÈ´òÂª∂ËøüÔºàÊï∞Áôæ‰∏™Âë®ÊúüÔºâÊÑèÂë≥ÁùÄÂ¶ÇÊûúÂá∫Áé∞‰∫âÁî®ÔºåÂêûÂêêÈáè‰ºöÂæà‰Ωé„ÄÇ</li>
<li><strong>L2 Cache Atomics:</strong> Faster than DRAM, but still global scope. ÊØî DRAM Êõ¥Âø´Ôºå‰ΩÜ‰ªçÁÑ∂ÊòØÂÖ®Â±Ä‰ΩúÁî®Âüü„ÄÇ</li>
<li><strong>Shared Memory Atomics:</strong> Very fast (low latency), but the scope is limited to the thread block. ÈÄüÂ∫¶ÈùûÂ∏∏Âø´ÔºàÂª∂Ëøü‰ΩéÔºâÔºå‰ΩÜ‰ΩúÁî®ËåÉÂõ¥‰ªÖÈôê‰∫éÁ∫øÁ®ãÂùó„ÄÇ</li>
</ul>
<h3 id="problem-solving_4">Problem Solving<a class="headerlink" href="#problem-solving_4" title="Permanent link">&para;</a></h3>
<p><img alt="image-20251014233136201" src="assets/image-20251014233136201.png" /></p>
<blockquote>
<p>The total time taken by a thread for all operations, assuming all atomic operations are in L2 cache, is: 5 atomic  operations * 5ns/atomic operation + 100 floating-point operations * 1ns/floating-point operation = 25ns + 100ns = 125ns</p>
<p>Similarly, the total time taken by a thread for all operations, assuming all atomic operations are in DRAM, is: 5 atomic  operations * 120ns/atomic operation + 100 floating-point operations * 1ns/floating-point operation = 600ns + 100ns = 700ns</p>
<p>Let's denote the percentage of atomic operations that happened in DRAM as x. Therefore, operations that happened in L2 cache is 1 ‚Äì <em>x</em> and the total execution time of a thread is: (1-<em>x</em>) * 125ns/thread + <em>x</em> * 700ns/thread</p>
<p>Given that the floating point taken for all operations is 0.2424 GFLOPS, we can calculate the total time in a thread (1 GFLOP = 1 billion floating-point operations): 0.2424 GFLOPS = 0.2424 * 1 billion floating-point operations/second = 242.4 million floating-point operations/second. </p>
<p>Since every thread performs 100 floating 242.4 million threads/second = 242.4 million floating -point operations, the number of threads that can be executed per second is:  -point operations/second / 100 floating-point operations/thread = 2.424 million threads/second.</p>
<p>Therefore, the total time taken for all operations in a thread is: 1 / 2.424 million threads/second = 0.0000004125  seconds/thread = 412.5ns/thread.</p>
<ul>
<li>Thus: (1 ‚Äì <em>x</em>) * 125ns/thread + <em>x</em> * 700ns/thread = 412.5ns/thread. Solving this for x gives us 50%.</li>
</ul>
</blockquote>
<h5 id="1-why-does-x-cause-a-race-condition">1. Why does <code>x++</code> cause a race condition?<a class="headerlink" href="#1-why-does-x-cause-a-race-condition" title="Permanent link">&para;</a></h5>
<p>The operation <code>x++</code> (or <code>bins[i]++</code>) is not a single step. It consists of three distinct steps: <strong>Read</strong>, <strong>Modify</strong>, and <strong>Write</strong> .</p>
<ul>
<li><strong>The Scenario:</strong> Thread A reads the value of <code>x</code> (say, 0) into a register. Before Thread A can write the updated value (1) back to memory, Thread B <em>also</em> reads <code>x</code> (still 0).</li>
<li><strong>The Result:</strong> Both threads increment their local copy to 1 and write 1 back to memory. Even though two threads ran the code, the value only increased by 1 instead of 2. The update from one thread is effectively lost .</li>
</ul>
<h5 id="2-what-is-the-syntax-and-return-value-of-atomicadd">2. What is the syntax and return value of <code>atomicAdd</code>?<a class="headerlink" href="#2-what-is-the-syntax-and-return-value-of-atomicadd" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>Syntax:</strong> <code>T atomicAdd(T* address, T val)</code><ul>
<li><code>address</code>: A pointer to the memory location you want to update.</li>
<li><code>val</code>: The value to add.</li>
<li><code>T</code> can be <code>int</code>, <code>unsigned int</code>, <code>float</code>, etc. .</li>
</ul>
</li>
<li><strong>Return Value:</strong> It returns the <strong>old value</strong> that was stored at the address <em>before</em> the addition occurred .</li>
</ul>
<h5 id="3-kernel-code-for-a-privatized-histogram">3. Kernel code for a privatized histogram<a class="headerlink" href="#3-kernel-code-for-a-privatized-histogram" title="Permanent link">&para;</a></h5>
<p>This involves three phases: Initialize, Compute, and Merge.</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-62-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-62-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-62-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-62-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-62-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-62-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-62-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-62-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-62-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-62-10">10</a></span>
<span class="normal"><a href="#__codelineno-62-11">11</a></span>
<span class="normal"><a href="#__codelineno-62-12">12</a></span>
<span class="normal"><a href="#__codelineno-62-13">13</a></span>
<span class="normal"><a href="#__codelineno-62-14">14</a></span>
<span class="normal"><a href="#__codelineno-62-15">15</a></span>
<span class="normal"><a href="#__codelineno-62-16">16</a></span>
<span class="normal"><a href="#__codelineno-62-17">17</a></span>
<span class="normal"><a href="#__codelineno-62-18">18</a></span>
<span class="normal"><a href="#__codelineno-62-19">19</a></span>
<span class="normal"><a href="#__codelineno-62-20">20</a></span>
<span class="normal"><a href="#__codelineno-62-21">21</a></span>
<span class="normal"><a href="#__codelineno-62-22">22</a></span>
<span class="normal"><a href="#__codelineno-62-23">23</a></span>
<span class="normal"><a href="#__codelineno-62-24">24</a></span>
<span class="normal"><a href="#__codelineno-62-25">25</a></span>
<span class="normal"><a href="#__codelineno-62-26">26</a></span>
<span class="normal"><a href="#__codelineno-62-27">27</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-62-1"><a id="__codelineno-62-1" name="__codelineno-62-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">histo_kernel</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">histo</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-62-2"><a id="__codelineno-62-2" name="__codelineno-62-2"></a><span class="w">    </span><span class="c1">// 1. Allocate and Initialize Private Histogram in Shared Memory</span>
</span><span id="__span-62-3"><a id="__codelineno-62-3" name="__codelineno-62-3"></a><span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">histo_private</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>
</span><span id="__span-62-4"><a id="__codelineno-62-4" name="__codelineno-62-4"></a>
</span><span id="__span-62-5"><a id="__codelineno-62-5" name="__codelineno-62-5"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">256</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-62-6"><a id="__codelineno-62-6" name="__codelineno-62-6"></a><span class="w">        </span><span class="n">histo_private</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span>
</span><span id="__span-62-7"><a id="__codelineno-62-7" name="__codelineno-62-7"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-62-8"><a id="__codelineno-62-8" name="__codelineno-62-8"></a><span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span><span class="w"> </span><span class="c1">// Ensure initialization is done before any thread starts adding [cite: 4950-4961]</span>
</span><span id="__span-62-9"><a id="__codelineno-62-9" name="__codelineno-62-9"></a>
</span><span id="__span-62-10"><a id="__codelineno-62-10" name="__codelineno-62-10"></a><span class="w">    </span><span class="c1">// 2. Build Private Histogram (Compute)</span>
</span><span id="__span-62-11"><a id="__codelineno-62-11" name="__codelineno-62-11"></a><span class="w">    </span><span class="c1">// Use stride to handle more data elements than threads (Thread Coarsening)</span>
</span><span id="__span-62-12"><a id="__codelineno-62-12" name="__codelineno-62-12"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-62-13"><a id="__codelineno-62-13" name="__codelineno-62-13"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"> </span>
</span><span id="__span-62-14"><a id="__codelineno-62-14" name="__codelineno-62-14"></a>
</span><span id="__span-62-15"><a id="__codelineno-62-15" name="__codelineno-62-15"></a><span class="w">    </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-62-16"><a id="__codelineno-62-16" name="__codelineno-62-16"></a><span class="w">        </span><span class="c1">// Atomic update to the fast shared memory copy</span>
</span><span id="__span-62-17"><a id="__codelineno-62-17" name="__codelineno-62-17"></a><span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="p">(</span><span class="n">histo_private</span><span class="p">[</span><span class="n">buffer</span><span class="p">[</span><span class="n">i</span><span class="p">]]),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"> </span>
</span><span id="__span-62-18"><a id="__codelineno-62-18" name="__codelineno-62-18"></a><span class="w">        </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stride</span><span class="p">;</span>
</span><span id="__span-62-19"><a id="__codelineno-62-19" name="__codelineno-62-19"></a><span class="w">    </span><span class="p">}</span><span class="w"> </span>
</span><span id="__span-62-20"><a id="__codelineno-62-20" name="__codelineno-62-20"></a><span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span><span class="w"> </span><span class="c1">// Ensure all threads in block have finished their private counts [cite: 4966-4971, 4978]</span>
</span><span id="__span-62-21"><a id="__codelineno-62-21" name="__codelineno-62-21"></a>
</span><span id="__span-62-22"><a id="__codelineno-62-22" name="__codelineno-62-22"></a><span class="w">    </span><span class="c1">// 3. Merge Private Histogram into Global Histogram</span>
</span><span id="__span-62-23"><a id="__codelineno-62-23" name="__codelineno-62-23"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">256</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-62-24"><a id="__codelineno-62-24" name="__codelineno-62-24"></a><span class="w">        </span><span class="c1">// Atomic update to the slow global memory copy</span>
</span><span id="__span-62-25"><a id="__codelineno-62-25" name="__codelineno-62-25"></a><span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="p">(</span><span class="n">histo</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]),</span><span class="w"> </span><span class="n">histo_private</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]);</span><span class="w"> </span>
</span><span id="__span-62-26"><a id="__codelineno-62-26" name="__codelineno-62-26"></a><span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="p">[</span><span class="n">cite</span><span class="o">:</span><span class="w"> </span><span class="mi">4979-4980</span><span class="p">]</span>
</span><span id="__span-62-27"><a id="__codelineno-62-27" name="__codelineno-62-27"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="4-why-are-atomics-on-global-memory-slower-than-shared-memory">4. Why are atomics on Global Memory slower than Shared Memory?<a class="headerlink" href="#4-why-are-atomics-on-global-memory-slower-than-shared-memory" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>Distance &amp; Latency:</strong> Global memory is off-chip DRAM. An atomic operation there requires a signal to travel off-chip, perform a read (hundreds of cycles), do the math, and write back (hundreds of cycles) .</li>
<li><strong>Shared Memory:</strong> Shared memory is on-chip, physically close to the processor cores. Access latency is very low compared to DRAM.</li>
</ul>
<h5 id="5-how-does-contention-affect-throughput">5. How does Contention affect throughput?<a class="headerlink" href="#5-how-does-contention-affect-throughput" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>Serialization:</strong> Hardware enforces "Mutual Exclusion" for atomics. If multiple threads try to update the exact same memory address at the same time, they must form a line and execute one by one.</li>
<li><strong>Throughput Drop:</strong> Because they are serialized, the throughput drops drastically. If operations on global memory take ~1000 cycles, and you have heavy contention, your effective throughput becomes less than 1 operation per 1000 cycles .</li>
<li><strong>Analogy:</strong> It is like a supermarket checkout. If every customer realizes they forgot an item <em>after</em> scanning starts (high latency read-modify-write) and there is only one cashier (serialization), the line moves extremely slowly .</li>
</ul>
<h2 id="14-parallel-computation-patterns-reduction-trees">14 Parallel Computation Patterns ‚Äì Reduction Trees<a class="headerlink" href="#14-parallel-computation-patterns-reduction-trees" title="Permanent link">&para;</a></h2>
<h3 id="reduction">Reduction<a class="headerlink" href="#reduction" title="Permanent link">&para;</a></h3>
<p>A <strong>reduction</strong> operation reduces a set of input values to one value</p>
<ul>
<li>e.g., sum, product, min, max</li>
</ul>
<p>Reduction operations are:</p>
<ul>
<li><strong>Associative</strong></li>
<li><strong>Commutative</strong></li>
<li>Have a well-define identity value</li>
</ul>
<p>meaning they have the same results regardless of ordering and grouping</p>
<p><em>Sequential Reduction</em> is <span class="arithmatex">\(O(N)\)</span></p>
<p>Problem: control divergence, race condition</p>
<h3 id="parallel-reduction-in-logn-steps">Parallel Reduction in <span class="arithmatex">\(\log(N)\)</span> Steps<a class="headerlink" href="#parallel-reduction-in-logn-steps" title="Permanent link">&para;</a></h3>
<ul>
<li>Approach: Every thread adds two elements in each step</li>
<li>Takes <span class="arithmatex">\(\log(N)\)</span> steps and half the threads drop out every step</li>
<li>Pattern is called a reduction tree</li>
</ul>
<p><img src="./assets/image-20251015224847095.png" alt="image-20251015224847095" style="zoom:50%;" /></p>
<p>For <strong>N</strong> <strong>input values</strong>, the <strong>number of operations</strong> is <span class="arithmatex">\(\frac12N+\frac14N+...+\frac1NN=(1-\frac1N)N=N-1\)</span></p>
<p>The parallel algorithm shown is <strong>work-efficient</strong>: requires the <strong>same amount of work as a sequential algorithm</strong>(constant overheads, but nothing dependent on <strong>N</strong>).</p>
<p><img src="./assets/image-20251015225426422.png" alt="image-20251015225426422" style="zoom:50%;" /></p>
<p>In our <strong>parallel reduction</strong>, the <strong>number of operations halves in every step</strong>.</p>
<p>This kind of <strong>narrowing parallelism is common</strong> from combinational logic circuits to basic blocks to high-performance applications.</p>
<p>CUDA kernels allow only a fixed number of threads</p>
<h3 id="segmented-reduction">Segmented Reduction<a class="headerlink" href="#segmented-reduction" title="Permanent link">&para;</a></h3>
<p>Synchronize across threads in different blocks</p>
<p>Every thread block reduces a segment of the input and produces a partial sum</p>
<p>The partial sum is atomically added to the final sum</p>
<p><img src="./assets/image-20251015230746994.png" alt="image-20251015230746994" style="zoom:50%;" /></p>
<h3 id="parallel-strategy-for-cuda">Parallel Strategy for CUDA<a class="headerlink" href="#parallel-strategy-for-cuda" title="Permanent link">&para;</a></h3>
<p><strong>N</strong> values in device global memory</p>
<p>Each <strong>thread block</strong> of <strong>M</strong> threads uses shared memory, to <strong>reduce chunk of 2M</strong> values to one value (2M &lt;&lt; N to produce enough thread blocks).</p>
<p>Blocks operate <strong>within shared memory</strong> to reduce global memory traffic, and <strong>write one value back</strong> to global memory.</p>
<h4 id="cuda-reduction-algorithm">CUDA Reduction Algorithm<a class="headerlink" href="#cuda-reduction-algorithm" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Read</strong> block of <strong>2M values</strong> into shared memory</li>
<li>For each of <strong>log(2M)</strong> steps, <strong>combine two values</strong> per thread in each step, <strong>write result</strong> to shared memory, and <strong>halve</strong> the number of <strong>active threads</strong>.</li>
<li><strong>Write final result</strong> back to global memory.</li>
</ol>
<h4 id="a-simple-mapping-of-data-to-threads">A Simple Mapping of Data to Threads<a class="headerlink" href="#a-simple-mapping-of-data-to-threads" title="Permanent link">&para;</a></h4>
<p>Each <strong>thread</strong> </p>
<ul>
<li>begins with two <strong>adjacent locations</strong> (<strong>stride of 1</strong>),</li>
<li><strong>even index (first)</strong> and an odd index (second).</li>
</ul>
<p>Thread 0 gets 0 and 1, Thread 1 gets 2 and 3, ‚Ä¶</p>
<ul>
<li>Write the <strong>result</strong> back <strong>to</strong> the <strong>even index</strong>.</li>
<li>After each step, <strong>half of</strong> active <strong>threads</strong> are <strong>done</strong>.</li>
<li><strong>Double the stride</strong>.</li>
<li>At the end, the result is at <strong>index 0</strong>.</li>
</ul>
<p><img src="./assets/image-20251015233802080.png" alt="image-20251015233802080" style="zoom:50%;" /></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-63-1">1</a></span>
<span class="normal"><a href="#__codelineno-63-2">2</a></span>
<span class="normal"><a href="#__codelineno-63-3">3</a></span>
<span class="normal"><a href="#__codelineno-63-4">4</a></span>
<span class="normal"><a href="#__codelineno-63-5">5</a></span>
<span class="normal"><a href="#__codelineno-63-6">6</a></span>
<span class="normal"><a href="#__codelineno-63-7">7</a></span>
<span class="normal"><a href="#__codelineno-63-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-63-1"><a id="__codelineno-63-1" name="__codelineno-63-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-63-2"><a id="__codelineno-63-2" name="__codelineno-63-2"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-63-3"><a id="__codelineno-63-3" name="__codelineno-63-3"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-63-4"><a id="__codelineno-63-4" name="__codelineno-63-4"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">%</span><span class="n">stride</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-63-5"><a id="__codelineno-63-5" name="__codelineno-63-5"></a><span class="w">    </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-63-6"><a id="__codelineno-63-6" name="__codelineno-63-6"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-63-7"><a id="__codelineno-63-7" name="__codelineno-63-7"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-63-8"><a id="__codelineno-63-8" name="__codelineno-63-8"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>Problems</p>
<ul>
<li>Accesses to input are not coalesced</li>
<li>Control divergence</li>
</ul>
<h4 id="control-divergence-reduced">Control Divergence Reduced<a class="headerlink" href="#control-divergence-reduced" title="Permanent link">&para;</a></h4>
<p>sequential addressing</p>
<p><img src="./assets/image-20251016001211207.png" alt="image-20251016001211207" style="zoom:50%;" /></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-64-1">1</a></span>
<span class="normal"><a href="#__codelineno-64-2">2</a></span>
<span class="normal"><a href="#__codelineno-64-3">3</a></span>
<span class="normal"><a href="#__codelineno-64-4">4</a></span>
<span class="normal"><a href="#__codelineno-64-5">5</a></span>
<span class="normal"><a href="#__codelineno-64-6">6</a></span>
<span class="normal"><a href="#__codelineno-64-7">7</a></span>
<span class="normal"><a href="#__codelineno-64-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-64-1"><a id="__codelineno-64-1" name="__codelineno-64-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-64-2"><a id="__codelineno-64-2" name="__codelineno-64-2"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-64-3"><a id="__codelineno-64-3" name="__codelineno-64-3"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-64-4"><a id="__codelineno-64-4" name="__codelineno-64-4"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-64-5"><a id="__codelineno-64-5" name="__codelineno-64-5"></a><span class="w">    </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-64-6"><a id="__codelineno-64-6" name="__codelineno-64-6"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-64-7"><a id="__codelineno-64-7" name="__codelineno-64-7"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-64-8"><a id="__codelineno-64-8" name="__codelineno-64-8"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="data-reuse">Data Reuse<a class="headerlink" href="#data-reuse" title="Permanent link">&para;</a></h4>
<p>While specific data values are not reused, the same memory locations are repeatedly read and written</p>
<p><strong>Optimization</strong>: load input to shared memory first and perform reduction tree on shared memory</p>
<p>Also avoids modifying the input if needed in the future</p>
<h4 id="using-shared-memory">Using shared Memory<a class="headerlink" href="#using-shared-memory" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251016002902410.png" alt="image-20251016002902410" style="zoom: 50%;" /></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-65-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-65-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-65-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-65-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-65-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-65-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-65-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-65-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-65-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-65-10">10</a></span>
<span class="normal"><a href="#__codelineno-65-11">11</a></span>
<span class="normal"><a href="#__codelineno-65-12">12</a></span>
<span class="normal"><a href="#__codelineno-65-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-65-1"><a id="__codelineno-65-1" name="__codelineno-65-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-65-2"><a id="__codelineno-65-2" name="__codelineno-65-2"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-65-3"><a id="__codelineno-65-3" name="__codelineno-65-3"></a><span class="c1">// Load data to shared memory</span>
</span><span id="__span-65-4"><a id="__codelineno-65-4" name="__codelineno-65-4"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">input_s</span><span class="p">[</span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-65-5"><a id="__codelineno-65-5" name="__codelineno-65-5"></a><span class="n">input_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-65-6"><a id="__codelineno-65-6" name="__codelineno-65-6"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-65-7"><a id="__codelineno-65-7" name="__codelineno-65-7"></a><span class="c1">// Reduction tree in shared memory</span>
</span><span id="__span-65-8"><a id="__codelineno-65-8" name="__codelineno-65-8"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-65-9"><a id="__codelineno-65-9" name="__codelineno-65-9"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-65-10"><a id="__codelineno-65-10" name="__codelineno-65-10"></a><span class="w">    </span><span class="n">input_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">input_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-65-11"><a id="__codelineno-65-11" name="__codelineno-65-11"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-65-12"><a id="__codelineno-65-12" name="__codelineno-65-12"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-65-13"><a id="__codelineno-65-13" name="__codelineno-65-13"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="reducing-synchronization-with-warp-level-primitives">Reducing Synchronization with Warp-level Primitives<a class="headerlink" href="#reducing-synchronization-with-warp-level-primitives" title="Permanent link">&para;</a></h3>
<p>During the last few iterations, only one warp is active</p>
<ul>
<li>We can take advantage of the special relationship between threads in the same warp to synchronize between them quickly</li>
</ul>
<p>Built-in <strong>warp shuffle functions</strong> enable threads to share data with other threads in the same warp</p>
<p>Faster than using shared memory and <code>__syncthreads()</code> to share across threads in the same block</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-66-1">1</a></span>
<span class="normal"><a href="#__codelineno-66-2">2</a></span>
<span class="normal"><a href="#__codelineno-66-3">3</a></span>
<span class="normal"><a href="#__codelineno-66-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-66-1"><a id="__codelineno-66-1" name="__codelineno-66-1"></a><span class="n">__shfl_sync</span><span class="p">()</span><span class="w"> </span><span class="c1">//Direct copy from indexed lane</span>
</span><span id="__span-66-2"><a id="__codelineno-66-2" name="__codelineno-66-2"></a><span class="n">__shfl_up_sync</span><span class="p">()</span><span class="w"> </span><span class="c1">//Copy from a lane with lower ID relative to caller</span>
</span><span id="__span-66-3"><a id="__codelineno-66-3" name="__codelineno-66-3"></a><span class="n">__shfl_down_sync</span><span class="p">()</span><span class="w"> </span><span class="c1">// Copy from a lane with higher ID relative to caller</span>
</span><span id="__span-66-4"><a id="__codelineno-66-4" name="__codelineno-66-4"></a><span class="n">__shfl_xor_sync</span><span class="p">()</span><span class="w"> </span><span class="c1">// Copy from a lane based on bitwise XOR of own lane ID</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>When one warp remains, use warp shuffle instructions to synchronize within the warp and share data from registers Á∫øÁ®ãÊùüÈáçÊéí</li>
</ul>
<p><img src="./assets/image-20251016003756074.png" alt="image-20251016003756074" style="zoom: 50%;" /></p>
<h4 id="code-for-reduction-with-warp-shuffle">Code for Reduction with Warp Shuffle<a class="headerlink" href="#code-for-reduction-with-warp-shuffle" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-67-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-67-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-67-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-67-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-67-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-67-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-67-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-67-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-67-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-67-10">10</a></span>
<span class="normal"><a href="#__codelineno-67-11">11</a></span>
<span class="normal"><a href="#__codelineno-67-12">12</a></span>
<span class="normal"><a href="#__codelineno-67-13">13</a></span>
<span class="normal"><a href="#__codelineno-67-14">14</a></span>
<span class="normal"><a href="#__codelineno-67-15">15</a></span>
<span class="normal"><a href="#__codelineno-67-16">16</a></span>
<span class="normal"><a href="#__codelineno-67-17">17</a></span>
<span class="normal"><a href="#__codelineno-67-18">18</a></span>
<span class="normal"><a href="#__codelineno-67-19">19</a></span>
<span class="normal"><a href="#__codelineno-67-20">20</a></span>
<span class="normal"><a href="#__codelineno-67-21">21</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-67-1"><a id="__codelineno-67-1" name="__codelineno-67-1"></a><span class="n">__device__</span><span class="w"> </span><span class="n">__inline__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">warpReduce</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-67-2"><a id="__codelineno-67-2" name="__codelineno-67-2"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
</span><span id="__span-67-3"><a id="__codelineno-67-3" name="__codelineno-67-3"></a><span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-67-4"><a id="__codelineno-67-4" name="__codelineno-67-4"></a><span class="w">    </span><span class="n">partialSum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">__shfl_down_sync</span><span class="p">(</span><span class="mh">0xffffffff</span><span class="p">,</span><span class="w"> </span><span class="n">partialSum</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">);</span><span class="w"> </span><span class="c1">// move partialSum from lane index i + delta  to index i</span>
</span><span id="__span-67-5"><a id="__codelineno-67-5" name="__codelineno-67-5"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-67-6"><a id="__codelineno-67-6" name="__codelineno-67-6"></a><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">partialSum</span><span class="p">;</span>
</span><span id="__span-67-7"><a id="__codelineno-67-7" name="__codelineno-67-7"></a><span class="p">}</span>
</span><span id="__span-67-8"><a id="__codelineno-67-8" name="__codelineno-67-8"></a><span class="p">...</span>
</span><span id="__span-67-9"><a id="__codelineno-67-9" name="__codelineno-67-9"></a><span class="w">  </span><span class="c1">// Reduction tree in shared memory</span>
</span><span id="__span-67-10"><a id="__codelineno-67-10" name="__codelineno-67-10"></a><span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-67-11"><a id="__codelineno-67-11" name="__codelineno-67-11"></a><span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-67-12"><a id="__codelineno-67-12" name="__codelineno-67-12"></a><span class="w">      </span><span class="n">input_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">input_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-67-13"><a id="__codelineno-67-13" name="__codelineno-67-13"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-67-14"><a id="__codelineno-67-14" name="__codelineno-67-14"></a><span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-67-15"><a id="__codelineno-67-15" name="__codelineno-67-15"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-67-16"><a id="__codelineno-67-16" name="__codelineno-67-16"></a><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// threads in the first warp</span>
</span><span id="__span-67-17"><a id="__codelineno-67-17" name="__codelineno-67-17"></a><span class="w">  </span><span class="c1">// Reduction tree with shuffle instructions</span>
</span><span id="__span-67-18"><a id="__codelineno-67-18" name="__codelineno-67-18"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span>
</span><span id="__span-67-19"><a id="__codelineno-67-19" name="__codelineno-67-19"></a><span class="w">    </span><span class="o">+</span><span class="w"> </span><span class="n">input_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">];</span><span class="w"> </span><span class="c1">// put values into registers</span>
</span><span id="__span-67-20"><a id="__codelineno-67-20" name="__codelineno-67-20"></a><span class="w">  </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduce</span><span class="p">(</span><span class="n">partialSum</span><span class="p">);</span><span class="w"> </span><span class="c1">// 32 threads</span>
</span><span id="__span-67-21"><a id="__codelineno-67-21" name="__codelineno-67-21"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="warp-level-programming-with-cooperative-groups">Warp-level Programming with Cooperative Groups<a class="headerlink" href="#warp-level-programming-with-cooperative-groups" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251016004724881.png" alt="image-20251016004724881" style="zoom:50%;" /><img src="./assets/image-20251016004805101.png" alt="image-20251016004805101" style="zoom:50%;" /></p>
<h4 id="reduction-with-warp-shuffle-code-using-cooperative-groups">Reduction with Warp Shuffle Code using Cooperative Groups<a class="headerlink" href="#reduction-with-warp-shuffle-code-using-cooperative-groups" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-68-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-68-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-68-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-68-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-68-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-68-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-68-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-68-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-68-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-68-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-68-1"><a id="__codelineno-68-1" name="__codelineno-68-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cooperative_groups.h&gt;</span>
</span><span id="__span-68-2"><a id="__codelineno-68-2" name="__codelineno-68-2"></a><span class="n">using</span><span class="w"> </span><span class="n">namespace</span><span class="w"> </span><span class="n">cooperative_groups</span><span class="p">;</span>
</span><span id="__span-68-3"><a id="__codelineno-68-3" name="__codelineno-68-3"></a><span class="n">__device__</span><span class="w"> </span><span class="n">__inline__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">warpReduce</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-68-4"><a id="__codelineno-68-4" name="__codelineno-68-4"></a><span class="w">  </span><span class="n">thread_block_tile</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="w"> </span><span class="n">warp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tiled_partition</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="p">(</span><span class="n">this_thread_block</span><span class="p">());</span>
</span><span id="__span-68-5"><a id="__codelineno-68-5" name="__codelineno-68-5"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
</span><span id="__span-68-6"><a id="__codelineno-68-6" name="__codelineno-68-6"></a><span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warp</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-68-7"><a id="__codelineno-68-7" name="__codelineno-68-7"></a><span class="w">    </span><span class="n">partialSum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">warp</span><span class="p">.</span><span class="n">shfl_down</span><span class="p">(</span><span class="n">partialSum</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">);</span>
</span><span id="__span-68-8"><a id="__codelineno-68-8" name="__codelineno-68-8"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-68-9"><a id="__codelineno-68-9" name="__codelineno-68-9"></a><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">partialSum</span><span class="p">;</span>
</span><span id="__span-68-10"><a id="__codelineno-68-10" name="__codelineno-68-10"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p>Synchronization in Reduction with Warp Shuffle</p>
<ul>
<li>Still incur block-wide synchronization overhead in the first half of the iterations</li>
</ul>
<p><img src="./assets/image-20251016005301541.png" alt="image-20251016005301541" style="zoom:50%;" /></p>
<h4 id="code-for-reduction-with-two-stage-warp-reductions">Code for Reduction with Two-Stage Warp Reductions<a class="headerlink" href="#code-for-reduction-with-two-stage-warp-reductions" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-69-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-69-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-69-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-69-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-69-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-69-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-69-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-69-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-69-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-69-10">10</a></span>
<span class="normal"><a href="#__codelineno-69-11">11</a></span>
<span class="normal"><a href="#__codelineno-69-12">12</a></span>
<span class="normal"><a href="#__codelineno-69-13">13</a></span>
<span class="normal"><a href="#__codelineno-69-14">14</a></span>
<span class="normal"><a href="#__codelineno-69-15">15</a></span>
<span class="normal"><a href="#__codelineno-69-16">16</a></span>
<span class="normal"><a href="#__codelineno-69-17">17</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-69-1"><a id="__codelineno-69-1" name="__codelineno-69-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-69-2"><a id="__codelineno-69-2" name="__codelineno-69-2"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-69-3"><a id="__codelineno-69-3" name="__codelineno-69-3"></a><span class="c1">// Load data to registers</span>
</span><span id="__span-69-4"><a id="__codelineno-69-4" name="__codelineno-69-4"></a><span class="kt">float</span><span class="w"> </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-69-5"><a id="__codelineno-69-5" name="__codelineno-69-5"></a><span class="c1">// Reduction tree with shuffle instructions</span>
</span><span id="__span-69-6"><a id="__codelineno-69-6" name="__codelineno-69-6"></a><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduce</span><span class="p">(</span><span class="n">partialSum</span><span class="p">);</span>
</span><span id="__span-69-7"><a id="__codelineno-69-7" name="__codelineno-69-7"></a><span class="c1">// Combine partial sums in shared memory</span>
</span><span id="__span-69-8"><a id="__codelineno-69-8" name="__codelineno-69-8"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">partialSums_s</span><span class="p">[</span><span class="n">BLOCK_DIM</span><span class="o">/</span><span class="n">WARP_SIZE</span><span class="p">];</span>
</span><span id="__span-69-9"><a id="__codelineno-69-9" name="__codelineno-69-9"></a><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">%</span><span class="n">WARP_SIZE</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-69-10"><a id="__codelineno-69-10" name="__codelineno-69-10"></a><span class="w">  </span><span class="n">partialSums_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="n">WARP_SIZE</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partialSum</span><span class="p">;</span>
</span><span id="__span-69-11"><a id="__codelineno-69-11" name="__codelineno-69-11"></a><span class="p">}</span>
</span><span id="__span-69-12"><a id="__codelineno-69-12" name="__codelineno-69-12"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-69-13"><a id="__codelineno-69-13" name="__codelineno-69-13"></a><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="c1">// the first warp</span>
</span><span id="__span-69-14"><a id="__codelineno-69-14" name="__codelineno-69-14"></a><span class="w">  </span><span class="c1">// Reduction tree with shuffle instructions</span>
</span><span id="__span-69-15"><a id="__codelineno-69-15" name="__codelineno-69-15"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partialSums_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-69-16"><a id="__codelineno-69-16" name="__codelineno-69-16"></a><span class="w">  </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduce</span><span class="p">(</span><span class="n">partialSum</span><span class="p">);</span>
</span><span id="__span-69-17"><a id="__codelineno-69-17" name="__codelineno-69-17"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="divergence-in-reduction-with-two-stage-warp-reductions">Divergence in Reduction with Two-Stage Warp Reductions<a class="headerlink" href="#divergence-in-reduction-with-two-stage-warp-reductions" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251016005807944.png" alt="image-20251016005807944" style="zoom:50%;" /></p>
<h4 id="thread-coarsening_1">Thread Coarsening<a class="headerlink" href="#thread-coarsening_1" title="Permanent link">&para;</a></h4>
<p>Cost of parallelization:</p>
<ul>
<li>Synchronization every step</li>
<li>Control divergence in the final steps</li>
<li>Better to coarsen threads if there are many more blocks than resources available</li>
</ul>
<p><img src="./assets/image-20251016010409864.png" alt="image-20251016010409864" style="zoom:50%;" /></p>
<p>Code for Reduction with Thread Coarsening</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-70-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-70-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-70-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-70-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-70-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-70-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-70-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-70-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-70-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-70-10">10</a></span>
<span class="normal"><a href="#__codelineno-70-11">11</a></span>
<span class="normal"><a href="#__codelineno-70-12">12</a></span>
<span class="normal"><a href="#__codelineno-70-13">13</a></span>
<span class="normal"><a href="#__codelineno-70-14">14</a></span>
<span class="normal"><a href="#__codelineno-70-15">15</a></span>
<span class="normal"><a href="#__codelineno-70-16">16</a></span>
<span class="normal"><a href="#__codelineno-70-17">17</a></span>
<span class="normal"><a href="#__codelineno-70-18">18</a></span>
<span class="normal"><a href="#__codelineno-70-19">19</a></span>
<span class="normal"><a href="#__codelineno-70-20">20</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-70-1"><a id="__codelineno-70-1" name="__codelineno-70-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">COARSE_FACTOR</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-70-2"><a id="__codelineno-70-2" name="__codelineno-70-2"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">segment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-70-3"><a id="__codelineno-70-3" name="__codelineno-70-3"></a><span class="c1">// Load data to registers</span>
</span><span id="__span-70-4"><a id="__codelineno-70-4" name="__codelineno-70-4"></a><span class="kt">float</span><span class="w"> </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-70-5"><a id="__codelineno-70-5" name="__codelineno-70-5"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">tile</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">COARSE_FACTOR</span><span class="o">*</span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">tile</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-70-6"><a id="__codelineno-70-6" name="__codelineno-70-6"></a><span class="w">  </span><span class="n">partialSum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tile</span><span class="o">*</span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-70-7"><a id="__codelineno-70-7" name="__codelineno-70-7"></a><span class="p">}</span>
</span><span id="__span-70-8"><a id="__codelineno-70-8" name="__codelineno-70-8"></a><span class="c1">// Reduction tree with shuffle instructions</span>
</span><span id="__span-70-9"><a id="__codelineno-70-9" name="__codelineno-70-9"></a><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduce</span><span class="p">(</span><span class="n">partialSum</span><span class="p">);</span>
</span><span id="__span-70-10"><a id="__codelineno-70-10" name="__codelineno-70-10"></a><span class="c1">// Combine partial sums in shared memory</span>
</span><span id="__span-70-11"><a id="__codelineno-70-11" name="__codelineno-70-11"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">partialSums_s</span><span class="p">[</span><span class="n">BLOCK_DIM</span><span class="o">/</span><span class="n">WARP_SIZE</span><span class="p">];</span>
</span><span id="__span-70-12"><a id="__codelineno-70-12" name="__codelineno-70-12"></a><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">%</span><span class="n">WARP_SIZE</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-70-13"><a id="__codelineno-70-13" name="__codelineno-70-13"></a><span class="w">  </span><span class="n">partialSums_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="n">WARP_SIZE</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partialSum</span><span class="p">;</span>
</span><span id="__span-70-14"><a id="__codelineno-70-14" name="__codelineno-70-14"></a><span class="p">}</span>
</span><span id="__span-70-15"><a id="__codelineno-70-15" name="__codelineno-70-15"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-70-16"><a id="__codelineno-70-16" name="__codelineno-70-16"></a><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-70-17"><a id="__codelineno-70-17" name="__codelineno-70-17"></a><span class="w">  </span><span class="c1">// Reduction tree with shuffle instructions</span>
</span><span id="__span-70-18"><a id="__codelineno-70-18" name="__codelineno-70-18"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partialSums_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-70-19"><a id="__codelineno-70-19" name="__codelineno-70-19"></a><span class="w">  </span><span class="n">partialSum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduce</span><span class="p">(</span><span class="n">partialSum</span><span class="p">);</span>
</span><span id="__span-70-20"><a id="__codelineno-70-20" name="__codelineno-70-20"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="coarsening-benefits">Coarsening Benefits<a class="headerlink" href="#coarsening-benefits" title="Permanent link">&para;</a></h4>
<p>Let <em>N</em> be the number of elements per original block</p>
<ul>
<li>i.e., <em>N</em> = 2*blockDim.x</li>
</ul>
<p>If blocks are all executed in parallel:</p>
<ul>
<li><em>log(N)</em> steps, <em>log(N)</em> synchronizations</li>
</ul>
<p>If blocks serialized by the hardware by a factor of C:</p>
<ul>
<li><em>C*log(N)</em> steps, <em>C*log(N)</em> synchronizations</li>
</ul>
<p>If blocks are coarsened by a factor of C:</p>
<ul>
<li><em>2*(C ‚Äì 1) + log(N)</em> steps, <em>log(N)</em> synchronizations</li>
</ul>
<hr />
<h2 id="15-parallel-computation-patterns-parallel-scan-prefix-sum">15 <strong>Parallel Computation</strong> Patterns ‚Äì Parallel Scan (Prefix Sum)<a class="headerlink" href="#15-parallel-computation-patterns-parallel-scan-prefix-sum" title="Permanent link">&para;</a></h2>
<blockquote>
<p>[!NOTE]</p>
<p>To learn parallel scan (prefix sum) algorithms based on reductions</p>
<p>Kogge-Stone Parallel Scan</p>
<p>Brent-Kung Parallel Scan</p>
<p>Hierarchical algorithms</p>
<p>To learn the concept of double buffering</p>
<p>To understand tradeoffs between work efficiency and latency</p>
</blockquote>
<h3 id="scan">Scan Êâ´Êèè<a class="headerlink" href="#scan" title="Permanent link">&para;</a></h3>
<p>A <strong>scan</strong> operation:</p>
<p>Takes:</p>
<ol>
<li>An input array <span class="arithmatex">\([x_0, x_1, ‚Ä¶, x_{n-1}]\)</span> </li>
<li>An associative operator <span class="arithmatex">\(‚äï\)</span> Êüê‰∏ÄÁßçËøêÁÆó,  e.g., sum, product, min, max</li>
</ol>
<p>Returns:</p>
<ul>
<li>An output array <span class="arithmatex">\([y_0, y_1, ‚Ä¶, y_{n-1}]\)</span> where<ul>
<li><strong>Inclusive scan</strong>: <span class="arithmatex">\(y_i = x_0 ‚äï x_1 ‚äï ... ‚äï x_i\)</span></li>
<li><strong>Exclusive scan</strong>: <span class="arithmatex">\(y_i = x_0 ‚äï x_1 ‚äï ... ‚äï x_{i-1}\)</span></li>
</ul>
</li>
</ul>
<p><img src="./assets/image-20251017003832269.png" alt="image-20251017003832269" style="zoom:50%;" /></p>
<h4 id="sequential-scan">Sequential scan<a class="headerlink" href="#sequential-scan" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251017003915449.png" alt="image-20251017003915449" style="zoom:50%;" /></p>
<h4 id="segmented-scan">Segmented scan<a class="headerlink" href="#segmented-scan" title="Permanent link">&para;</a></h4>
<p>Parallel scan requires synchronization across parallel workers</p>
<p>Approach: <strong>segmented scan </strong>ÂàÜÊÆµÊâ´Êèè</p>
<ol>
<li>
<p>Scan each block locally and write the block's total sum to an array. (Local Scan)</p>
</li>
<li>
<p>Scan Sums: Perform a scan on that auxiliary array of sums</p>
</li>
<li>Add: Add the scanned auxiliary values back to the elements in the respective blocks.</li>
</ol>
<p>For now, we will focus on implementing a parallel scan in each block, <strong>double buffering</strong> ÂèåÁºìÂÜ≤</p>
<p>How do we consolidate the results of the different thread blocks?</p>
<ul>
<li>Try the same strategy as the warp-level and thread-level decomposition</li>
<li>Scan partial sums, then add scanned partial sums</li>
<li>We can use three separate kernels</li>
</ul>
<h4 id="thee-kernel-scan">Thee-Kernel Scan<a class="headerlink" href="#thee-kernel-scan" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251017205925961.png" alt="image-20251017205925961" style="zoom:50%;" /></p>
<h4 id="using-global-memory-contents-in-cuda">Using Global Memory Contents in CUDA<a class="headerlink" href="#using-global-memory-contents-in-cuda" title="Permanent link">&para;</a></h4>
<p>Data in registers and shared memory of one thread block are not visible to other blocks</p>
<p>To make data visible, the data has to be written into global memory</p>
<p>However, any data written to the global memory are not visible until a memory fence. This is typically done by terminating the kernel execution</p>
<p>Launch another kernel to continue the execution. The global memory writes done by the terminated kernels are visible to all thread blocks.</p>
<p>‰∏Ä‰∏™Á∫øÁ®ãÂùóÁöÑÂØÑÂ≠òÂô®ÂíåÂÖ±‰∫´ÂÜÖÂ≠ò‰∏≠ÁöÑÊï∞ÊçÆÂØπÂÖ∂‰ªñÁ∫øÁ®ãÂùó‰∏çÂèØËßÅ„ÄÇ</p>
<p>Ë¶Å‰ΩøÊï∞ÊçÆÂèØËßÅÔºåÂøÖÈ°ªÂ∞ÜÊï∞ÊçÆÂÜôÂÖ•ÂÖ®Â±ÄÂÜÖÂ≠ò„ÄÇ</p>
<p>‰ΩÜÊòØÔºå‰ªª‰ΩïÂÜôÂÖ•ÂÖ®Â±ÄÂÜÖÂ≠òÁöÑÊï∞ÊçÆÂú®ÂÜÖÂ≠òÊ†ÖÊ†è‰πãÂâçÈÉΩÊòØ‰∏çÂèØËßÅÁöÑ„ÄÇËøôÈÄöÂ∏∏ÊòØÈÄöËøáÁªàÊ≠¢ÂÜÖÊ†∏ÊâßË°åÊù•ÂÆûÁé∞ÁöÑ„ÄÇ</p>
<p>ÂêØÂä®Âè¶‰∏Ä‰∏™ÂÜÖÊ†∏‰ª•ÁªßÁª≠ÊâßË°å„ÄÇÁªàÊ≠¢ÁöÑÂÜÖÊ†∏ÊâßË°åÁöÑÂÖ®Â±ÄÂÜÖÂ≠òÂÜôÂÖ•Êìç‰ΩúÂØπÊâÄÊúâÁ∫øÁ®ãÂùóÈÉΩÂèØËßÅ„ÄÇ</p>
<h3 id="kogge-stone-parallel-inclusive-scan">Kogge-Stone Parallel (Inclusive) Scan<a class="headerlink" href="#kogge-stone-parallel-inclusive-scan" title="Permanent link">&para;</a></h3>
<p>speed approach</p>
<h4 id="parallel-inclusive-scan-using-reduction-trees">Parallel Inclusive Scan using Reduction Trees<a class="headerlink" href="#parallel-inclusive-scan-using-reduction-trees" title="Permanent link">&para;</a></h4>
<ul>
<li>Calculate each output element as the reduction of all previous elements</li>
<li>Some reduction partial sums will be shared among the calculation of output elements</li>
<li>Based on hardware added design by Peter Kogge and Harold Stone at IBM in the 1970s ‚Äì Kogge-Stone Trees</li>
<li>Goal: low latency ‰ΩéÂª∂Ëøü</li>
</ul>
<h4 id="parallel-inclusive-scan">Parallel (Inclusive) Scan<a class="headerlink" href="#parallel-inclusive-scan" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251017191130230.png" alt="image-20251017191130230" style="zoom:50%;" /></p>
<ul>
<li>Another reduction tree gives us more elements</li>
<li>A parallel reduction tree for the last element gives some others as a byproduct ÂâØ‰∫ßÁâ©</li>
<li>Overlap the trees and do them simultaneously</li>
</ul>
<h4 id="kogge-stone-parallel-inclusive-scan_1">Kogge-Stone Parallel (Inclusive) Scan<a class="headerlink" href="#kogge-stone-parallel-inclusive-scan_1" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251017193058795.png" alt="image-20251017193058795" style="zoom:50%;" /></p>
<p>Incorrect code(without sync)</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-71-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-71-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-71-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-71-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-71-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-71-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-71-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-71-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-71-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-71-10">10</a></span>
<span class="normal"><a href="#__codelineno-71-11">11</a></span>
<span class="normal"><a href="#__codelineno-71-12">12</a></span>
<span class="normal"><a href="#__codelineno-71-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-71-1"><a id="__codelineno-71-1" name="__codelineno-71-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-71-2"><a id="__codelineno-71-2" name="__codelineno-71-2"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-71-3"><a id="__codelineno-71-3" name="__codelineno-71-3"></a><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-71-4"><a id="__codelineno-71-4" name="__codelineno-71-4"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-71-5"><a id="__codelineno-71-5" name="__codelineno-71-5"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-71-6"><a id="__codelineno-71-6" name="__codelineno-71-6"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-71-7"><a id="__codelineno-71-7" name="__codelineno-71-7"></a><span class="w">    </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-71-8"><a id="__codelineno-71-8" name="__codelineno-71-8"></a><span class="w">    </span><span class="c1">// Incorrect!</span>
</span><span id="__span-71-9"><a id="__codelineno-71-9" name="__codelineno-71-9"></a><span class="w">    </span><span class="c1">// Different threads are reading and writing the same data location without synchronizing</span>
</span><span id="__span-71-10"><a id="__codelineno-71-10" name="__codelineno-71-10"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-71-11"><a id="__codelineno-71-11" name="__codelineno-71-11"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-71-12"><a id="__codelineno-71-12" name="__codelineno-71-12"></a><span class="p">}</span>
</span><span id="__span-71-13"><a id="__codelineno-71-13" name="__codelineno-71-13"></a><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span></code></pre></div></td></tr></table></div>
<p><strong>Correct</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-72-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-72-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-72-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-72-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-72-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-72-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-72-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-72-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-72-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-72-10">10</a></span>
<span class="normal"><a href="#__codelineno-72-11">11</a></span>
<span class="normal"><a href="#__codelineno-72-12">12</a></span>
<span class="normal"><a href="#__codelineno-72-13">13</a></span>
<span class="normal"><a href="#__codelineno-72-14">14</a></span>
<span class="normal"><a href="#__codelineno-72-15">15</a></span>
<span class="normal"><a href="#__codelineno-72-16">16</a></span>
<span class="normal"><a href="#__codelineno-72-17">17</a></span>
<span class="normal"><a href="#__codelineno-72-18">18</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-72-1"><a id="__codelineno-72-1" name="__codelineno-72-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-72-2"><a id="__codelineno-72-2" name="__codelineno-72-2"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-72-3"><a id="__codelineno-72-3" name="__codelineno-72-3"></a><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-72-4"><a id="__codelineno-72-4" name="__codelineno-72-4"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-72-5"><a id="__codelineno-72-5" name="__codelineno-72-5"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-72-6"><a id="__codelineno-72-6" name="__codelineno-72-6"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">v</span><span class="p">;</span>
</span><span id="__span-72-7"><a id="__codelineno-72-7" name="__codelineno-72-7"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-72-8"><a id="__codelineno-72-8" name="__codelineno-72-8"></a><span class="w">    </span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-72-9"><a id="__codelineno-72-9" name="__codelineno-72-9"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-72-10"><a id="__codelineno-72-10" name="__codelineno-72-10"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span><span class="w"> </span><span class="c1">// Wait for everyone to read before writing</span>
</span><span id="__span-72-11"><a id="__codelineno-72-11" name="__codelineno-72-11"></a><span class="w">  </span><span class="c1">// This synchronization enforces a false dependence (we only need to finish reading before others write because we are using the same buffer)</span>
</span><span id="__span-72-12"><a id="__codelineno-72-12" name="__codelineno-72-12"></a>
</span><span id="__span-72-13"><a id="__codelineno-72-13" name="__codelineno-72-13"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-72-14"><a id="__codelineno-72-14" name="__codelineno-72-14"></a><span class="w">    </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">v</span><span class="p">;</span>
</span><span id="__span-72-15"><a id="__codelineno-72-15" name="__codelineno-72-15"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-72-16"><a id="__codelineno-72-16" name="__codelineno-72-16"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span><span class="w"> </span><span class="c1">// This synchronization enforces a true dependence (we must finish writing before others can read)</span>
</span><span id="__span-72-17"><a id="__codelineno-72-17" name="__codelineno-72-17"></a><span class="p">}</span>
</span><span id="__span-72-18"><a id="__codelineno-72-18" name="__codelineno-72-18"></a><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span></code></pre></div></td></tr></table></div>
<p>The <strong>Kogge-Stone algorithm</strong> is a parallel method used primarily to compute <strong>prefix sums</strong> (also known as a "scan"). <strong>Kogge-Stone ÁÆóÊ≥ï</strong>ÊòØ‰∏ÄÁßçÂπ∂Ë°åÊñπÊ≥ïÔºå‰∏ªË¶ÅÁî®‰∫éËÆ°ÁÆó<strong>ÂâçÁºÄÂíå</strong> Ôºà‰πüÁß∞‰∏∫‚ÄúÊâ´Êèè‚ÄùÔºâ„ÄÇ</p>
<p>Its guiding principle is <strong>Recursive Doubling</strong> (also called pointer jumping).
ÂÖ∂Ê†∏ÂøÉÂéüÂàôÊòØ<strong>ÈÄíÂΩíÂÄçÂ¢û</strong> Ôºà‰πüÁß∞ÊåáÈíàË∑≥Ë∑ÉÔºâ„ÄÇ‰∏éÊ†áÂáÜÂæ™ÁéØÈÄê‰∏™ÂÖÉÁ¥†Âú∞ÈÅçÂéÜÊï∞ÁªÑÁ≠âÂæÖÊ±ÇÂíå‰∏çÂêåÔºåKogge-Stone ÁÆóÊ≥ïÂÖÅËÆ∏ÊØè‰∏™ÂÖÉÁ¥†ÈÄöËøá‰∏çÊñ≠‚ÄúÂÄçÂ¢û‚ÄùÂÖ∂ÂõûÊ∫ØË∑ùÁ¶ªÊù•Âπ∂Ë°åÂú∞ÊâæÂà∞Ëá™Ë∫´ÁöÑÁ≠îÊ°à„ÄÇ</p>
<p>Âú®Ê†áÂáÜÁöÑÈ°∫Â∫èÊâ´Êèè‰∏≠ÔºåÁ¨¨ <span class="arithmatex">\(i\)</span> ‰∏™ÂÖÉÁ¥†‰ºöÁ≠âÂæÖÁ¨¨ <span class="arithmatex">\((i-1)\)</span> ‰∏™ÂÖÉÁ¥†Êâ´ÊèèÂÆåÊØï„ÄÇËøôÈúÄË¶Å <span class="arithmatex">\(O(N)\)</span> Ê≠•„ÄÇ</p>
<p>Kogge-Stone ÁÆóÊ≥ïÈÄöËøáÊâßË°å  <strong><span class="arithmatex">\(\log_2 N\)</span> Ê≠•</strong>Êù•Âä†ÈÄüËøô‰∏ÄËøáÁ®ã„ÄÇÂú®ÊØè‰∏ÄÊ≠•‰∏≠ÔºåÊØè‰∏™ÂÖÉÁ¥†ÈÉΩ‰ºö‰ªé‰∏éÂÖ∂Áõ∏Ë∑ùÁâπÂÆö‚ÄúÊ≠•Èïø‚ÄùË∑ùÁ¶ªÁöÑÁõ∏ÈÇªÂÖÉÁ¥†Êî∂ÈõÜ‰ø°ÊÅØ„ÄÇËØ•Ê≠•ÈïøÂú®ÊØèÊ¨°Ëø≠‰ª£‰∏≠ÈÉΩ‰ºöÁøªÂÄçÔºà <span class="arithmatex">\(1, 2, 4, 8, \dots\)</span> Ôºâ„ÄÇ</p>
<ul>
<li><strong>Ê≠•È™§1ÔºàÊ≠•Èïø1Ôºâ Ôºö</strong> ÊØè‰∏™ÂÖÉÁ¥† <span class="arithmatex">\(i\)</span> Âä†‰∏äÊù•Ëá™ <span class="arithmatex">\(i-1\)</span> ÁöÑÂÄº„ÄÇÔºàÁé∞Âú®ÊØè‰∏™ÂÖÉÁ¥†ÈÉΩÁü•ÈÅìÂÆÉËá™Ë∫´ÂèäÂÖ∂Áõ∏ÈÇªÂÖÉÁ¥†ÁöÑÂíåÔºâ„ÄÇ</li>
<li><strong>Ê≠•È™§ 2ÔºàÊ≠•Èïø 2ÔºâÔºö</strong> ÊØè‰∏™ÂÖÉÁ¥† <span class="arithmatex">\(i\)</span> Âä†‰∏ä <span class="arithmatex">\(i-2\)</span> ‰∏≠ÁöÑÂÄº„ÄÇ</li>
<li><strong>Ê≠•È™§ 3ÔºàÊ≠•Èïø 4ÔºâÔºö</strong> ÊØè‰∏™ÂÖÉÁ¥† <span class="arithmatex">\(i\)</span> Âä†‰∏ä <span class="arithmatex">\(i-4\)</span> ‰∏≠ÁöÑÂÄº„ÄÇ</li>
<li>ÂΩìÊ≠•ÈïøÂ§ß‰∫éÊï∞ÁªÑÂ§ßÂ∞èÊó∂ÔºåÊØè‰∏™‰ΩçÁΩÆ <span class="arithmatex">\(i\)</span> ÈÉΩÂ∑≤ÊàêÂäüÁ¥ØÂä†‰∫Ü‰ªé <span class="arithmatex">\(0\)</span> Âà∞ <span class="arithmatex">\(i\)</span> ÁöÑÊâÄÊúâÂÖÉÁ¥†ÁöÑÊÄªÂíå„ÄÇ</li>
</ul>
<h3 id="double-buffering_1">Double Buffering<a class="headerlink" href="#double-buffering_1" title="Permanent link">&para;</a></h3>
<p><strong>Optimization:</strong> eliminate the synchronization that enforces a false dependence by using separate </p>
<p>buffers for reading and writing, and alternate the buffers each iteration</p>
<p><img src="./assets/image-20251017194945683.png" alt="image-20251017194945683" style="zoom:50%;" /></p>
<p><strong>ÂèåÁºìÂÜ≤</strong> Ôºà‰∫§Êç¢ËæìÂÖ•/ËæìÂá∫Êï∞ÁªÑÔºâ‰ª•Èò≤Ê≠¢Âá∫Áé∞Á∫øÁ®ãË¶ÜÁõñÂè¶‰∏Ä‰∏™Á∫øÁ®ã‰ªçÈúÄËØªÂèñÁöÑÊï∞ÊçÆÁöÑÁ´û‰∫âÊù°‰ª∂</p>
<h4 id="double-buffering-code">Double Buffering Code<a class="headerlink" href="#double-buffering-code" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-73-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-73-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-73-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-73-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-73-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-73-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-73-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-73-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-73-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-73-10">10</a></span>
<span class="normal"><a href="#__codelineno-73-11">11</a></span>
<span class="normal"><a href="#__codelineno-73-12">12</a></span>
<span class="normal"><a href="#__codelineno-73-13">13</a></span>
<span class="normal"><a href="#__codelineno-73-14">14</a></span>
<span class="normal"><a href="#__codelineno-73-15">15</a></span>
<span class="normal"><a href="#__codelineno-73-16">16</a></span>
<span class="normal"><a href="#__codelineno-73-17">17</a></span>
<span class="normal"><a href="#__codelineno-73-18">18</a></span>
<span class="normal"><a href="#__codelineno-73-19">19</a></span>
<span class="normal"><a href="#__codelineno-73-20">20</a></span>
<span class="normal"><a href="#__codelineno-73-21">21</a></span>
<span class="normal"><a href="#__codelineno-73-22">22</a></span>
<span class="normal"><a href="#__codelineno-73-23">23</a></span>
<span class="normal"><a href="#__codelineno-73-24">24</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-73-1"><a id="__codelineno-73-1" name="__codelineno-73-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-73-2"><a id="__codelineno-73-2" name="__codelineno-73-2"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">buffer1_s</span><span class="p">[</span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-73-3"><a id="__codelineno-73-3" name="__codelineno-73-3"></a><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">buffer2_s</span><span class="p">[</span><span class="n">BLOCK_DIM</span><span class="p">];</span>
</span><span id="__span-73-4"><a id="__codelineno-73-4" name="__codelineno-73-4"></a><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">inBuffer_s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer1_s</span><span class="p">;</span>
</span><span id="__span-73-5"><a id="__codelineno-73-5" name="__codelineno-73-5"></a><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">outBuffer_s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer2_s</span><span class="p">;</span>
</span><span id="__span-73-6"><a id="__codelineno-73-6" name="__codelineno-73-6"></a><span class="n">inBuffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-73-7"><a id="__codelineno-73-7" name="__codelineno-73-7"></a>
</span><span id="__span-73-8"><a id="__codelineno-73-8" name="__codelineno-73-8"></a><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-73-9"><a id="__codelineno-73-9" name="__codelineno-73-9"></a>
</span><span id="__span-73-10"><a id="__codelineno-73-10" name="__codelineno-73-10"></a><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">BLOCK_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-73-11"><a id="__codelineno-73-11" name="__codelineno-73-11"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-73-12"><a id="__codelineno-73-12" name="__codelineno-73-12"></a><span class="w">    </span><span class="n">outBuffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-73-13"><a id="__codelineno-73-13" name="__codelineno-73-13"></a><span class="w">      </span><span class="n">inBuffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">inBuffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-73-14"><a id="__codelineno-73-14" name="__codelineno-73-14"></a><span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-73-15"><a id="__codelineno-73-15" name="__codelineno-73-15"></a><span class="w">    </span><span class="n">outBuffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inBuffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-73-16"><a id="__codelineno-73-16" name="__codelineno-73-16"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-73-17"><a id="__codelineno-73-17" name="__codelineno-73-17"></a>
</span><span id="__span-73-18"><a id="__codelineno-73-18" name="__codelineno-73-18"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-73-19"><a id="__codelineno-73-19" name="__codelineno-73-19"></a>
</span><span id="__span-73-20"><a id="__codelineno-73-20" name="__codelineno-73-20"></a><span class="w">  </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inBuffer_s</span><span class="p">;</span>
</span><span id="__span-73-21"><a id="__codelineno-73-21" name="__codelineno-73-21"></a><span class="w">  </span><span class="n">inBuffer_s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outBuffer_s</span><span class="p">;</span>
</span><span id="__span-73-22"><a id="__codelineno-73-22" name="__codelineno-73-22"></a><span class="w">  </span><span class="n">outBuffer_s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp</span><span class="p">;</span>
</span><span id="__span-73-23"><a id="__codelineno-73-23" name="__codelineno-73-23"></a><span class="p">}</span>
</span><span id="__span-73-24"><a id="__codelineno-73-24" name="__codelineno-73-24"></a><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inBuffer_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
</span></code></pre></div></td></tr></table></div>
<p><img src="./assets/image-20251017200057992.png" alt="image-20251017200057992" style="zoom:50%;" /></p>
<h4 id="code-for-scan-with-warp-level-primitives">Code for Scan with Warp-level Primitives<a class="headerlink" href="#code-for-scan-with-warp-level-primitives" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-74-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-74-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-74-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-74-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-74-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-74-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-74-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-74-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-74-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-74-10">10</a></span>
<span class="normal"><a href="#__codelineno-74-11">11</a></span>
<span class="normal"><a href="#__codelineno-74-12">12</a></span>
<span class="normal"><a href="#__codelineno-74-13">13</a></span>
<span class="normal"><a href="#__codelineno-74-14">14</a></span>
<span class="normal"><a href="#__codelineno-74-15">15</a></span>
<span class="normal"><a href="#__codelineno-74-16">16</a></span>
<span class="normal"><a href="#__codelineno-74-17">17</a></span>
<span class="normal"><a href="#__codelineno-74-18">18</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-74-1"><a id="__codelineno-74-1" name="__codelineno-74-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">scan_kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-74-2"><a id="__codelineno-74-2" name="__codelineno-74-2"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-74-3"><a id="__codelineno-74-3" name="__codelineno-74-3"></a><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-74-4"><a id="__codelineno-74-4" name="__codelineno-74-4"></a><span class="w">  </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockScan</span><span class="p">(</span><span class="n">val</span><span class="p">);</span>
</span><span id="__span-74-5"><a id="__codelineno-74-5" name="__codelineno-74-5"></a><span class="w">  </span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
</span><span id="__span-74-6"><a id="__codelineno-74-6" name="__codelineno-74-6"></a><span class="p">}</span>
</span><span id="__span-74-7"><a id="__codelineno-74-7" name="__codelineno-74-7"></a><span class="n">__device__</span><span class="w"> </span><span class="kr">inline</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">laneIdx</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
</span><span id="__span-74-8"><a id="__codelineno-74-8" name="__codelineno-74-8"></a><span class="n">__device__</span><span class="w"> </span><span class="kr">inline</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">warpIdx</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
</span><span id="__span-74-9"><a id="__codelineno-74-9" name="__codelineno-74-9"></a><span class="n">__device__</span><span class="w"> </span><span class="kr">inline</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">warpScan</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-74-10"><a id="__codelineno-74-10" name="__codelineno-74-10"></a><span class="w">  </span><span class="cp">#pragma unroll</span>
</span><span id="__span-74-11"><a id="__codelineno-74-11" name="__codelineno-74-11"></a><span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">WARP_SIZE</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-74-12"><a id="__codelineno-74-12" name="__codelineno-74-12"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">leftVal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__shfl_up_sync</span><span class="p">(</span><span class="mh">0xffffffff</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">);</span>
</span><span id="__span-74-13"><a id="__codelineno-74-13" name="__codelineno-74-13"></a><span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">laneIdx</span><span class="p">()</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-74-14"><a id="__codelineno-74-14" name="__codelineno-74-14"></a><span class="w">      </span><span class="n">val</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">leftVal</span><span class="p">;</span>
</span><span id="__span-74-15"><a id="__codelineno-74-15" name="__codelineno-74-15"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-74-16"><a id="__codelineno-74-16" name="__codelineno-74-16"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-74-17"><a id="__codelineno-74-17" name="__codelineno-74-17"></a><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
</span><span id="__span-74-18"><a id="__codelineno-74-18" name="__codelineno-74-18"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="work-efficiency">Work Efficiency<a class="headerlink" href="#work-efficiency" title="Permanent link">&para;</a></h4>
<p>A parallel algorithm is <strong>work-efficient</strong> if it performs the same amount of work as the corresponding sequential algorithm</p>
<p>Work efficiency of parallel scan</p>
<ul>
<li>Sequential scan performs <em>N</em> additions</li>
<li><strong>Kogge-Stone parallel scan</strong> performs:<ul>
<li>Latency: <span class="arithmatex">\(\log(N)\)</span> steps, <span class="arithmatex">\(N - 2^{step}\)</span>  operations per step ÈÄüÂ∫¶Âø´</li>
<li><strong>Total</strong>: <span class="arithmatex">\((N-1) + (N-2) + (N-4) + ‚Ä¶ + (N-N/2)\\ = N*\log(N) - (N-1) = O(N*\log(N))\)</span> operations</li>
<li>Algorithm is not work efficient<ul>
<li>A factor of <span class="arithmatex">\(\log(n)\)</span> hurts: 20x for 1,000,000 elements!</li>
<li>Typically used within each block, where n ‚â§ 1,024</li>
<li>Áº∫ÁÇπÔºöÂ∑•‰ΩúÈáèÂ§ßÔºåËµÑÊ∫ê‰ΩøÁî®ÁéáÈ´ò High Resource Usage (Because "every thread is active" in every step)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="improve-efficiency">Improve Efficiency<a class="headerlink" href="#improve-efficiency" title="Permanent link">&para;</a></h4>
<p>A common parallel algorithm pattern: <em>Balanced Trees</em></p>
<p>Build a balanced binary tree on the input data and sweep it to and from the root</p>
<p>Tree is not an actual data structure, but a conceptual pattern</p>
<p>For scan:</p>
<ul>
<li>Traverse down from leaves to root building partial sums at internal nodes in the tree<ul>
<li>Root holds sum of all leaves</li>
</ul>
</li>
<li>Traverse back up the tree building the scan from the partial sums</li>
</ul>
<h3 id="brent-kung-parallel-scan-step">Brent-Kung Parallel Scan Step<a class="headerlink" href="#brent-kung-parallel-scan-step" title="Permanent link">&para;</a></h3>
<p><strong>Parallel (Inclusive) Scan</strong></p>
<p><img src="./assets/image-20251017201641645.png" alt="image-20251017201641645" style="zoom:50%;" /></p>
<p>Inclusive Post-Scan Step ÂåÖÂê´ÂêéÊâ´ÊèèÊ≠•È™§</p>
<p><img src="./assets/9364c46126bbbbae463fcccbeb3a6cb2.jpg" alt="9364c46126bbbbae463fcccbeb3a6cb2" style="zoom: 25%;" /></p>
<p><strong>Reduction Step Kernel Code</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-75-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-75-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-75-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-75-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-75-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-75-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-75-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-75-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-75-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-75-10">10</a></span>
<span class="normal"><a href="#__codelineno-75-11">11</a></span>
<span class="normal"><a href="#__codelineno-75-12">12</a></span>
<span class="normal"><a href="#__codelineno-75-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-75-1"><a id="__codelineno-75-1" name="__codelineno-75-1"></a><span class="c1">// float T[2*BLOCK_SIZE] is in shared memory</span>
</span><span id="__span-75-2"><a id="__codelineno-75-2" name="__codelineno-75-2"></a><span class="c1">// for previous slide, BLOCK_SIZE is 8</span>
</span><span id="__span-75-3"><a id="__codelineno-75-3" name="__codelineno-75-3"></a><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
</span><span id="__span-75-4"><a id="__codelineno-75-4" name="__codelineno-75-4"></a><span class="k">while</span><span class="p">(</span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">BLOCK_SIZE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-75-5"><a id="__codelineno-75-5" name="__codelineno-75-5"></a><span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-75-6"><a id="__codelineno-75-6" name="__codelineno-75-6"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stride</span><span class="o">*</span><span class="mi">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
</span><span id="__span-75-7"><a id="__codelineno-75-7" name="__codelineno-75-7"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">index</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">BLOCK_SIZE</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">index</span><span class="o">-</span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-75-8"><a id="__codelineno-75-8" name="__codelineno-75-8"></a><span class="w">    </span><span class="n">T</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">T</span><span class="p">[</span><span class="n">index</span><span class="o">-</span><span class="n">stride</span><span class="p">];</span>
</span><span id="__span-75-9"><a id="__codelineno-75-9" name="__codelineno-75-9"></a><span class="w">  </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stride</span><span class="o">*</span><span class="mi">2</span><span class="p">;</span>
</span><span id="__span-75-10"><a id="__codelineno-75-10" name="__codelineno-75-10"></a><span class="p">}</span>
</span><span id="__span-75-11"><a id="__codelineno-75-11" name="__codelineno-75-11"></a><span class="c1">// In our example,</span>
</span><span id="__span-75-12"><a id="__codelineno-75-12" name="__codelineno-75-12"></a><span class="c1">// threadIdx.x+1 = 1, 2, 3, 4, 5, 6, 7, 8</span>
</span><span id="__span-75-13"><a id="__codelineno-75-13" name="__codelineno-75-13"></a><span class="c1">// stride = 1, index = 1, 3, 5, 7, 9, 11, 13, 15</span>
</span></code></pre></div></td></tr></table></div>
<p><strong>Post Scan Step (Distribution Tree)</strong></p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-76-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-76-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-76-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-76-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-76-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-76-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-76-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-76-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-76-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-76-10">10</a></span>
<span class="normal"><a href="#__codelineno-76-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-76-1"><a id="__codelineno-76-1" name="__codelineno-76-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span>
</span><span id="__span-76-2"><a id="__codelineno-76-2" name="__codelineno-76-2"></a><span class="w">  </span><span class="k">while</span><span class="p">(</span><span class="n">stride</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-76-3"><a id="__codelineno-76-3" name="__codelineno-76-3"></a><span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-76-4"><a id="__codelineno-76-4" name="__codelineno-76-4"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stride</span><span class="o">*</span><span class="mi">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
</span><span id="__span-76-5"><a id="__codelineno-76-5" name="__codelineno-76-5"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="n">index</span><span class="o">+</span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">BLOCK_SIZE</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-76-6"><a id="__codelineno-76-6" name="__codelineno-76-6"></a><span class="w">      </span><span class="n">T</span><span class="p">[</span><span class="n">index</span><span class="o">+</span><span class="n">stride</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">T</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span><span id="__span-76-7"><a id="__codelineno-76-7" name="__codelineno-76-7"></a><span class="w">    </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span>
</span><span id="__span-76-8"><a id="__codelineno-76-8" name="__codelineno-76-8"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-76-9"><a id="__codelineno-76-9" name="__codelineno-76-9"></a><span class="c1">// In our example, </span>
</span><span id="__span-76-10"><a id="__codelineno-76-10" name="__codelineno-76-10"></a><span class="c1">// BLOCK_SIZE=8 stride=4, 2, 1</span>
</span><span id="__span-76-11"><a id="__codelineno-76-11" name="__codelineno-76-11"></a><span class="c1">// for first iteration, active thread = 0 index = 7, stride = 11</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="work-analysis">Work Analysis<a class="headerlink" href="#work-analysis" title="Permanent link">&para;</a></h4>
<p>The parallel Scan executes <em><span class="arithmatex">\(2\times\log(n)\)</span> parallel iterations</em></p>
<ul>
<li>
<p><span class="arithmatex">\(\log(n)\)</span> in reduction and <span class="arithmatex">\(\log(n)\)</span> in post scan</p>
</li>
<li>
<p><strong>Latency:</strong> <span class="arithmatex">\(2 \log_2(N) - 1\)</span> ==&gt; It takes twice as many steps as Kogge-Stone.</p>
</li>
<li>
<p>The iterations do <span class="arithmatex">\(n/2, n/4,..1, (2-1), ‚Ä¶., (n/4-1), (n/2-1)\)</span> useful adds</p>
</li>
<li>In our example, n = 16, the number of useful adds is <span class="arithmatex">\(16/2 + 16/4 + 16/8 + 16/16 + (16/8-1) + (16/4-1) + (16/2-1)\)</span></li>
<li><strong>Total adds:</strong> <span class="arithmatex">\((n-1) + (n-2) ‚Äì (log(n) -1) = 2*(n-1) ‚Äì log(n)\)</span> ‚û°Ô∏è  <span class="arithmatex">\(O(n)\)</span> work</li>
</ul>
<p>The total number of adds is <em>no more than twice</em> of that done in the efficient sequential algorithm</p>
<p>The benefit of parallelism can easily overcome the 2√ó work when there is sufficient hardware</p>
<h3 id="kogge-stone-vs-brent-kung">Kogge-Stone vs. Brent-Kung<a class="headerlink" href="#kogge-stone-vs-brent-kung" title="Permanent link">&para;</a></h3>
<p>Brent-Kung uses <em>half</em> the number of <em>threads</em> compared to Kogge-Stone</p>
<ul>
<li>Each thread should load two elements into the shared memory</li>
<li>Brent-Kung is more worok-efficient()</li>
</ul>
<p>Brent-Kung takes <em>twice</em> the number of <em>steps</em> compared to Kogge-Stone</p>
<ul>
<li>Kogge-Stone is <strong>more popular</strong> for parallel scan with blocks in GPUs</li>
</ul>
<h3 id="overall-flow-of-complete-scan">Overall Flow of Complete Scan<a class="headerlink" href="#overall-flow-of-complete-scan" title="Permanent link">&para;</a></h3>
<p><img alt="image-20251017211601502" src="assets/image-20251017211601502.png" /></p>
<p>A complete herarchical scan</p>
<h4 id="scan-of-arbitrary-length-input">Scan of Arbitrary Length Input<a class="headerlink" href="#scan-of-arbitrary-length-input" title="Permanent link">&para;</a></h4>
<ol>
<li>Build on the scan kernel that handles up to <code>2*blockDim.x</code> elements from Brent-Kung.(For Kogge-Stone, have each section of <code>blockDim.x</code> elements assigned to a blockÔºâ</li>
<li>Have each block write the sum of its section into a Sum array using its <code>blockIdx.x</code> as index</li>
<li>Run parallel scan on the Sum array</li>
<li>May need to break down Sum into multiple sections if it is too big for a block</li>
<li>Add the scanned Sum array values to the elements of corresponding sections</li>
</ol>
<p>Âü∫‰∫é Brent-Kung ÁÆóÊ≥ïÊûÑÂª∫ÁöÑÊâ´ÊèèÂÜÖÊ†∏ÔºåÊúÄÂ§öÂèØÂ§ÑÁêÜ 2*blockDim.x ‰∏™ÂÖÉÁ¥†„ÄÇ</p>
<p>ÔºàÂØπ‰∫é Kogge-Stone ÁÆóÊ≥ïÔºåÂ∞Ü blockDim.x ‰∏™ÂÖÉÁ¥†ÁöÑÊØè‰∏™ÈÉ®ÂàÜÂàÜÈÖçÁªô‰∏Ä‰∏™Âùó„ÄÇ</p>
<p>ËÆ©ÊØè‰∏™Âùó‰ΩøÁî®ÂÖ∂ blockIdx.x ‰Ωú‰∏∫Á¥¢ÂºïÔºåÂ∞ÜÂÖ∂ÈÉ®ÂàÜÁöÑÊÄªÂíåÂÜôÂÖ• Sum Êï∞ÁªÑ„ÄÇ</p>
<p>ÂØπ Sum Êï∞ÁªÑËøõË°åÂπ∂Ë°åÊâ´Êèè„ÄÇ</p>
<p>Â¶ÇÊûú Sum Êï∞ÁªÑÂØπ‰∫é‰∏Ä‰∏™ÂùóÊù•ËØ¥Â§™Â§ßÔºåÂèØËÉΩÈúÄË¶ÅÂ∞ÜÂÖ∂ÊãÜÂàÜÊàêÂ§ö‰∏™ÈÉ®ÂàÜ„ÄÇ</p>
<p>Â∞ÜÊâ´ÊèèÂà∞ÁöÑ Sum Êï∞ÁªÑÂÄºÊ∑ªÂä†Âà∞Áõ∏Â∫îÈÉ®ÂàÜÁöÑÂÖÉÁ¥†‰∏≠„ÄÇ</p>
<h4 id="memory-bandwidth-considerations">Memory Bandwidth Considerations<a class="headerlink" href="#memory-bandwidth-considerations" title="Permanent link">&para;</a></h4>
<p>Scan is <strong>memory bound</strong></p>
<ul>
<li>
<p>Let‚Äôs analyze the number of memory accesses for scanning an array of <em>N</em> values</p>
</li>
<li>
<p>Ignore accesses to partial sums array which are much fewer for a large block size and coarsening factor</p>
</li>
</ul>
<p><img alt="image-20251017212423607" src="assets/image-20251017212423607.png" /></p>
<h4 id="single-kernel-scan">Single-Kernel Scan<a class="headerlink" href="#single-kernel-scan" title="Permanent link">&para;</a></h4>
<p>How can we perform the inter-block scan inside the same kernel as the segmented scan?</p>
<blockquote>
<p>One approach is to use <strong>grid-wide barrier synchronizations</strong>ÁΩëÊ†ºËåÉÂõ¥Â±èÈöúÂêåÊ≠• with cooperative groups and scan the partial sums with a single thread block</p>
<p>Limits the number of thread blocks that can execute, thereby the size of the array that can be scanned</p>
<p>Another approach is to use <strong>unidirectional synchronization</strong>ÂçïÈ°πÂêåÊ≠• to pass the partial sums from earlier thread blocks to later thread blocks</p>
</blockquote>
<h3 id="problem-solving_5">Problem solving<a class="headerlink" href="#problem-solving_5" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251017212724221.png" alt="image-20251017212724221" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251017213030064.png" alt="image-20251017213030064" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251017214158400.png" alt="image-20251017214158400" style="zoom:50%;" /></p>
<blockquote>
<p>The key is to understand that the Brent-Kung parallel scan algorithm operates in two main phases within each block. The question asks for the total number of additions across both phases.</p>
<p>The number of elements processed per block is <strong>n = 2048</strong>.</p>
<p><strong>1. Phase 1: Reduction (or Up-Sweep)</strong></p>
<ul>
<li><strong>Goal:</strong> To calculate the sum of all <code>n</code> elements within the block.</li>
<li><strong>Process:</strong> This phase works like a tournament. In each step, pairs of elements are added together, reducing the number of active elements by half until only a single element‚Äîthe total sum of the block‚Äîremains.</li>
<li><strong>Calculation:</strong> To sum <code>n</code> numbers, you need to perform exactly <strong>n - 1</strong> addition operations.</li>
<li><strong>Approximation:</strong> For <code>n = 2048</code>, this is <code>2048 - 1 = 2047</code> additions. This is well approximated as <strong>2048</strong> operations.</li>
</ul>
<p><strong>2. Phase 2: Post-Scan (or Down-Sweep)</strong></p>
<ul>
<li><strong>Goal:</strong> To use the block's total sum and the intermediate values calculated during the reduction phase to compute the final scan value for each element.</li>
<li><strong>Process:</strong> This phase starts with the block sum and works its way "down the tree" that was conceptually built during the up-sweep. It distributes the partial sums to calculate the correct prefix sum for every element in the block.</li>
<li><strong>Calculation:</strong> This phase also requires approximately <strong>n - 1</strong> addition operations in most efficient parallel implementations.</li>
<li><strong>Approximation:</strong> For <code>n = 2048</code>, this is also approximated as <strong>2048</strong> operations.</li>
</ul>
<p>The total number of floating-point add operations is the sum of the operations from both phases.</p>
<ul>
<li><strong>Total Operations</strong> = (Additions in Reduction) + (Additions in Post-Scan)</li>
<li><strong>Total Operations</strong> ‚âà <span class="arithmatex">\(n + n = 2n\)</span></li>
<li><strong>Total Operations</strong> ‚âà <span class="arithmatex">\(2048 + 2048 = \textbf{2048 x 2}\)</span></li>
</ul>
<p><strong>Note:</strong> The other information in the prompt, such as the total input size (<span class="arithmatex">\(2^{42}\)</span>), threads per block (1024), and grid size (2048), is context for the overall hierarchical algorithm but is <strong>not needed</strong> to calculate the number of operations <em>within a single block</em>.</p>
</blockquote>
<h2 id="16-advanced-optimizations-for-projects">16 Advanced Optimizations for Projects<a class="headerlink" href="#16-advanced-optimizations-for-projects" title="Permanent link">&para;</a></h2>
<p>General (dense) matrix multiplication is both compute and memory intensive</p>
<h3 id="where-we-left-off-basic-shared-memory-tiling">Where We Left Off: Basic Shared Memory Tiling<a class="headerlink" href="#where-we-left-off-basic-shared-memory-tiling" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251021142759620.png" alt="image-20251021142759620" style="zoom:50%;" /></p>
<h4 id="parameter-tuning-in-basic-shared-memory-tiling">Parameter Tuning in Basic Shared Memory Tiling<a class="headerlink" href="#parameter-tuning-in-basic-shared-memory-tiling" title="Permanent link">&para;</a></h4>
<p>Thread block (output tile) can be <strong>non-square</strong></p>
<p><code>S</code> (input tile shared dimension) can be flexible</p>
<p>But why?</p>
<ul>
<li>Larger <strong>T</strong> and <strong>U</strong> allows for more reuse <em>(recall they each represent reuse in M and N)</em></li>
<li>Larger <strong>S</strong> allows for less <code>__syncthreads()</code></li>
</ul>
<h4 id="basic-shared-memory-tiling-efficiency">Basic Shared Memory Tiling Efficiency<a class="headerlink" href="#basic-shared-memory-tiling-efficiency" title="Permanent link">&para;</a></h4>
<p>Your block size <code>(UxT)</code> is <strong>limited</strong>, can‚Äôt increase much (32 x 32 = 1024). </p>
<p>For the GPUs we use in delta (NVIDIA A40), biggest thread block is <strong>32 x 32</strong></p>
<p>Each input loaded is used 32 times in shared memory</p>
<p>A40‚Äôs peak FP32 compute throughput is <em>37.4 TFLOPs</em> (<em>37400 GFLOPs</em>), but peak memory throughput is only <em>696 GB/s</em>, so <em>32x</em> reuse means <em>5568</em> GFLOPs, far less than the peak obtainable compute throughput. </p>
<p>Basic shared memory tiling matmul <strong>performs poorly</strong> on modern GPUs without further optimizations</p>
<h4 id="better-than-shared-memory">Better Than Shared Memory<a class="headerlink" href="#better-than-shared-memory" title="Permanent link">&para;</a></h4>
<p><strong>Registers</strong> have low access latency and high throughput</p>
<p>ÂØÑÂ≠òÂô®ÊØîÂÖ±‰∫´ÂÜÖÂ≠òËøòË¶ÅÂø´</p>
<p>Basic shared memory tiling makes little use of the register hardware</p>
<p>However, registers are also <strong>local to each thread</strong>, meaning they cannot be reused between different threads.</p>
<p>Thread Coarsening Comes to the Rescue</p>
<h3 id="joint-register-and-shared-memory-tiling">Joint Register and Shared Memory Tiling<a class="headerlink" href="#joint-register-and-shared-memory-tiling" title="Permanent link">&para;</a></h3>
<p>Either one of the 2 input tiles can be placed into registers.</p>
<p>Let‚Äôs just pick <code>M</code> (for no good reason*).</p>
<p>Each row of an <code>M</code> tile is loaded into a <strong>single thread‚Äôs registers</strong></p>
<p>That thread then uses the registered values to compute an entire row of <strong>U</strong> output values. </p>
<p><em>Don‚Äôt make U too big, you don‚Äôt have an unlimited number of registers</em></p>
<ul>
<li><strong>U = 16</strong> is a reasonable size.</li>
</ul>
<p>The output tile height <code>T</code> is now the <strong>number of threads in the block</strong>, and you‚Äôll probably want more than 4.</p>
<p>Remember <strong>the dimension of the output tile decides how much reuse you get</strong>.</p>
<p>However, don‚Äôt make it too big that you start to run out of registers; it's good to do some parameter sweeping.</p>
<p>We also need to load the input tile from <code>N</code> into shared memory.</p>
<p>Do this the old-fashioned way, each thread in a block loads <strong>1</strong> value of N into a shared memory tile.</p>
<blockquote>
<p><em>Pop Quiz</em>: Given <strong>U</strong> and <strong>T</strong>, what should <strong>S</strong> be then?</p>
<p>Since we have <strong>T</strong> threads, and there are <strong>S</strong>x<strong>U</strong> elements in an <code>N</code> tile, each thread loading <strong>1</strong> value would mean <strong>S</strong> x <strong>U</strong> = <strong>T</strong></p>
<ul>
<li><strong>S = T / U</strong></li>
<li><em>You can also choose to load more than 1 input per thread, but it‚Äôs more complicated.</em></li>
</ul>
</blockquote>
<p>After a tile of <code>M</code> and a tile of <code>N</code> is loaded, the actual computation is simple. </p>
<p>Each thread uses the <strong>row of <code>M</code> in its registers</strong> and the <strong>entire tile of <code>N</code> in shared memory</strong> to multiply and accumulate to <code>U</code> different output values.</p>
<p>Then start over again, load the next tile of <code>M</code> and <code>N</code>, compute, add to the <code>U</code> different output values</p>
<p>You should probably have <strong>registers for the output values</strong> of each thread.</p>
<p><img src="./assets/image-20251021153149076.png" alt="image-20251021153149076" style="zoom:50%;" /></p>
<ul>
<li>One of the tile is completely utilized by other threads</li>
</ul>
<hr />
<p><img src="./assets/image-20251021153606662.png" alt="image-20251021153606662" style="zoom:50%;" /></p>
<blockquote>
<p>[!CAUTION]</p>
<p>Does this algorithm have <strong>coalesced loads</strong> for <code>M</code> and <code>N</code>?</p>
<p>For loading <code>N</code> into <strong>shared memory</strong>, it‚Äôs easy to make sure loads are coalesced. </p>
<p>But what about <code>M</code>?</p>
<p>Each thread loads a row of consecutive values from M‚Ä¶(At least 2 ways to make it coalesced.)</p>
<p>Consecutive threads load from other rows‚Ä¶</p>
<hr />
<p><strong>Solving the Uncoalesced Load for M</strong></p>
<ul>
<li><strong>The Problem:</strong> Loading M directly into registers causes <strong>uncoalesced</strong> memory access. Since each thread needs a different row, their memory requests are "strided" (far apart) in Global Memory, wasting bandwidth.</li>
<li><strong>The Solution (Staging in Shared Memory):</strong><ol>
<li><strong>Collaborative Load:</strong> Have all threads in the block work together to load the tile of <code>M</code> into <strong>Shared Memory</strong> first. Because they load it together, they can read consecutive addresses (Coalesced).</li>
<li><strong>Local Load:</strong> Once the data is in Shared Memory, each thread reads its specific row from Shared Memory into its <strong>Registers</strong>.</li>
<li><strong>Trade-off:</strong> This uses more Shared Memory space, but it maximizes Global Memory bandwidth efficiency.</li>
</ol>
</li>
</ul>
</blockquote>
<h3 id="tensor-corestf32">Tensor cores‚Äî‚ÄîTF32<a class="headerlink" href="#tensor-corestf32" title="Permanent link">&para;</a></h3>
<p>Tensor Cores are specialized matrix-matrix hardware compute units introduced in NVIDIA GPUs after their <strong>Volta</strong> generation.</p>
<p>This <strong>hardware</strong> addition significantly increases Matrix Multiplication efficiency</p>
<p><strong>TF32</strong> is a special <strong>floating-point format</strong> used in NVIDIA Tensor Cores</p>
<p>TF32 stands for Tensor Float [<em>Not Quite</em>] 32-bit format</p>
<p>Less precision than FP32, but good enough for Deep Learning</p>
<p><img src="./assets/image-20251021155352122.png" alt="image-20251021155352122" style="zoom:50%;" /></p>
<p><strong>TF32</strong> shares the same exponent format ÊåáÊï∞Ê†ºÂºè as FP32, and the mantissa format is simply a less precise version of FP32‚Äôs mantissa bits Â∞æÊï∞Ê†ºÂºè, so any TF32 value can also be stored in a float variable.</p>
<p>The CUDA intrinsic <code>__float_to_tf32</code> can be used to cast a float down to TF32.</p>
<h3 id="wmma-api">WMMA API<a class="headerlink" href="#wmma-api" title="Permanent link">&para;</a></h3>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-77-1">1</a></span>
<span class="normal"><a href="#__codelineno-77-2">2</a></span>
<span class="normal"><a href="#__codelineno-77-3">3</a></span>
<span class="normal"><a href="#__codelineno-77-4">4</a></span>
<span class="normal"><a href="#__codelineno-77-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-77-1"><a id="__codelineno-77-1" name="__codelineno-77-1"></a><span class="n">fragment</span><span class="o">&lt;&gt;</span><span class="p">;</span>
</span><span id="__span-77-2"><a id="__codelineno-77-2" name="__codelineno-77-2"></a>
</span><span id="__span-77-3"><a id="__codelineno-77-3" name="__codelineno-77-3"></a><span class="kt">void</span><span class="w"> </span><span class="nf">load_matrix_sync</span><span class="p">();</span>
</span><span id="__span-77-4"><a id="__codelineno-77-4" name="__codelineno-77-4"></a><span class="kt">void</span><span class="w"> </span><span class="nf">mma_sync</span><span class="p">();</span>
</span><span id="__span-77-5"><a id="__codelineno-77-5" name="__codelineno-77-5"></a><span class="kt">void</span><span class="w"> </span><span class="nf">store_matrix_sync</span><span class="p">();</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="spilt-k">Spilt-K<a class="headerlink" href="#spilt-k" title="Permanent link">&para;</a></h4>
<p>The Split-K algorithm for matrix multiplications parallelizes along the K dimension (shared dimension between two input matrices)</p>
<p>Instead of one thread block computing the <em>final</em> value for a tile of <span class="arithmatex">\(C\)</span> by iterating through the entire <span class="arithmatex">\(K\)</span> dimension, we split <span class="arithmatex">\(K\)</span> into chunks (splits).</p>
<ol>
<li><strong>Divide and Conquer:</strong> We break the <span class="arithmatex">\(K\)</span> dimension into smaller segments. For example, if we split <span class="arithmatex">\(K\)</span> into 2 parts:</li>
</ol>
<ul>
<li><strong>Block 1</strong> calculates the partial product for the first half of <span class="arithmatex">\(K\)</span>.</li>
<li><strong>Block 2</strong> calculates the partial product for the second half of <span class="arithmatex">\(K\)</span>.</li>
</ul>
<ol start="2">
<li><strong>More Blocks:</strong> Now, instead of 1 block per output tile, we have 2 (or more). If we split <span class="arithmatex">\(K\)</span> into 100 parts, we generate 100x more blocks, allowing us to fill up those empty SMs on the GPU </li>
</ol>
<p>Since multiple blocks are now calculating parts of the <em>same</em> output tile, they can't just overwrite the value in global memory. They each hold a <strong>partial sum</strong>.</p>
<p>After independently loading part of the input and computing partial results, thread blocks <strong>atomically</strong> ÂéüÂ≠êÁõ∏Âä† add to the output, forming the final output values.</p>
<p>When many threads fight for the same address (high contention), performance drops significantly.</p>
<p>If you split K among many blocks, consider using <strong>a reduction kernel</strong> to sum all the partial results.</p>
<h4 id="pointer-aliasing">Pointer Aliasing<a class="headerlink" href="#pointer-aliasing" title="Permanent link">&para;</a></h4>
<p>ÊåáÈíàÂà´Âêç</p>
<p>an alternative approach to avoid this atomic bottleneck </p>
<h4 id="compiler-optimizations-the-restrict-keyword">Compiler Optimizations ‚Äì The Restrict Keyword<a class="headerlink" href="#compiler-optimizations-the-restrict-keyword" title="Permanent link">&para;</a></h4>
<p>The ‚Äú<em><strong>restrict</strong></em>‚Äù keyword promises the compiler that any data <strong>written</strong> through that pointer is <strong>not read</strong> by any other pointer that <u>also has the restrict property</u>.</p>
<h2 id="17-profiling-on-nvidia-gpu-profiling">17 <strong>Profiling on</strong> Nvidia GPU Profiling<a class="headerlink" href="#17-profiling-on-nvidia-gpu-profiling" title="Permanent link">&para;</a></h2>
<h3 id="gpu-hardware">GPU hardware<a class="headerlink" href="#gpu-hardware" title="Permanent link">&para;</a></h3>
<p><strong>GPU (The whole chip):</strong> This contains everything, including the L2 Cache and Memory Controllers.</p>
<p><strong>GPC (Graphics Processing Cluster):</strong> The GPU is split into several clusters.</p>
<p><strong>TPC (Texture Processing Cluster):</strong> Inside the clusters, there are smaller groups called TPCs.</p>
<p><strong>SM (Streaming Multiprocessor):</strong> This is the most critical unit for CUDA programming. An SM contains:</p>
<ul>
<li><strong>Cores:</strong> CUDA Cores (for standard math), Tensor Cores (for matrix math), and RT Cores.</li>
<li><strong>Memory:</strong> Its own Register File (fastest memory) and L1/Shared Memory (for communication).</li>
<li><strong>Schedulers:</strong> Hardware units that decide which instructions to run next.</li>
</ul>
<p><strong>SMSP (SM Sub-Partition):</strong> The SM is further divided into 4 partitions to handle groups of threads.</p>
<p><strong>The Connection:</strong> In CUDA software, we group threads into <strong>Grids</strong>, <strong>Blocks</strong>, and <strong>Warps</strong>. The hardware maps these software concepts directly to the physical units to execute them .
Âú® CUDA ËΩØ‰ª∂‰∏≠ÔºåÊàë‰ª¨Â∞ÜÁ∫øÁ®ãÂàÜÁªÑ‰∏∫ÁΩëÊ†ºÔºàGridÔºâ„ÄÅÂùóÔºàBlockÔºâÂíåÁ∫øÁ®ãÊùüÔºàWarpÔºâ„ÄÇÁ°¨‰ª∂Â∞ÜËøô‰∫õËΩØ‰ª∂Ê¶ÇÂøµÁõ¥Êé•Êò†Â∞ÑÂà∞Áâ©ÁêÜÂçïÂÖÉ‰ª•ÊâßË°åÂÆÉ‰ª¨„ÄÇ</p>
<p>A <strong>Grid</strong> (the whole kernel) runs on the whole <strong>GPU</strong>.</p>
<p>A <strong>Warp</strong> (32 threads) runs on an <strong>SMSP</strong> (Sub-Partition).</p>
<p>A <strong>Thread Block</strong> is always scheduled on a single <strong>Streaming Multiprocessor (SM)</strong>.</p>
<h3 id="computation">Computation<a class="headerlink" href="#computation" title="Permanent link">&para;</a></h3>
<p>A Grid/kernel is scheduled on an available GPU</p>
<p>A block is scheduled on an available Stream Multiprocessor</p>
<p>A group of 32 threads is scheduled on an available warp</p>
<h3 id="cache_1">Cache<a class="headerlink" href="#cache_1" title="Permanent link">&para;</a></h3>
<p>cache is</p>
<p><strong>Nsight Systems (<code>nsys</code>)</strong>: The "Big Picture" tool. It visualizes a timeline of the entire system (CPU and GPU). You use this to see if your GPU is sitting idle waiting for the CPU, or to check overlaps between memory transfers and computation .
ÂÆÉ‰ª•Êó∂Èó¥ËΩ¥ÁöÑÂΩ¢ÂºèÂèØËßÜÂåñÊï¥‰∏™Á≥ªÁªüÔºàCPU Âíå GPUÔºâÁöÑËøêË°åÊÉÖÂÜµ„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®Ê≠§Â∑•ÂÖ∑Êü•Áúã GPU ÊòØÂê¶Â§Ñ‰∫éÁ©∫Èó≤Áä∂ÊÄÅÁ≠âÂæÖ CPUÔºåÊàñÊ£ÄÊü•ÂÜÖÂ≠ò‰º†ËæìÂíåËÆ°ÁÆó‰πãÈó¥ÁöÑÈáçÂè†ÊÉÖÂÜµ„ÄÇ</p>
<p><strong>Nsight Compute (<code>ncu</code>)</strong>: The "Microscope". It dives deep into a <em>specific</em> kernel launch. It tells you about cache hit rates, register pressure, and exactly which lines of code are causing stalls .
ÂÆÉÊ∑±ÂÖ•ÂàÜÊûêÁâπÂÆöÁöÑÂÜÖÊ†∏ÂêØÂä®ËøáÁ®ãÔºåÂëäËØâ‰Ω†ÁºìÂ≠òÂëΩ‰∏≠Áéá„ÄÅÂØÑÂ≠òÂô®ÂéãÂäõ‰ª•ÂèäÂØºËá¥Á®ãÂ∫èÂÅúÈ°øÁöÑÂÖ∑‰Ωì‰ª£Á†ÅË°å„ÄÇ</p>
<h2 id="18-gpu-systems-architecture">18 GPU Systems Architecture<a class="headerlink" href="#18-gpu-systems-architecture" title="Permanent link">&para;</a></h2>
<h3 id="cuda-structurte">CUDA structurte<a class="headerlink" href="#cuda-structurte" title="Permanent link">&para;</a></h3>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-78-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-78-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-78-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-78-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-78-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-78-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-78-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-78-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-78-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-78-10">10</a></span>
<span class="normal"><a href="#__codelineno-78-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-78-1"><a id="__codelineno-78-1" name="__codelineno-78-1"></a><span class="n">Global</span><span class="w"> </span><span class="n">variables</span><span class="w"> </span><span class="n">declaration</span>
</span><span id="__span-78-2"><a id="__codelineno-78-2" name="__codelineno-78-2"></a><span class="o">-</span><span class="w"> </span><span class="n">Kernel</span><span class="w"> </span><span class="n">functions</span>
</span><span id="__span-78-3"><a id="__codelineno-78-3" name="__codelineno-78-3"></a><span class="o">-</span><span class="w"> </span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">kernelOne</span><span class="p">(</span><span class="err">‚Ä¶</span><span class="p">)</span>
</span><span id="__span-78-4"><a id="__codelineno-78-4" name="__codelineno-78-4"></a><span class="n">main</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="c1">// host code</span>
</span><span id="__span-78-5"><a id="__codelineno-78-5" name="__codelineno-78-5"></a><span class="o">-</span><span class="w"> </span><span class="n">allocate</span><span class="w"> </span><span class="n">memory</span><span class="w"> </span><span class="n">space</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_GlblVarPtr</span><span class="p">,</span><span class="w"> </span><span class="n">bytes</span><span class="w"> </span><span class="p">)</span>
</span><span id="__span-78-6"><a id="__codelineno-78-6" name="__codelineno-78-6"></a><span class="o">-</span><span class="w"> </span><span class="n">transfer</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">host</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_GlblVarPtr</span><span class="p">,</span><span class="w"> </span><span class="n">h_Gl</span><span class="err">‚Ä¶</span><span class="p">)</span>
</span><span id="__span-78-7"><a id="__codelineno-78-7" name="__codelineno-78-7"></a><span class="o">-</span><span class="w"> </span><span class="n">execution</span><span class="w"> </span><span class="n">configuration</span><span class="w"> </span><span class="n">setup</span>
</span><span id="__span-78-8"><a id="__codelineno-78-8" name="__codelineno-78-8"></a><span class="o">-</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">call</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="n">kernelOne</span><span class="o">&lt;&lt;&lt;</span><span class="n">execution</span><span class="w"> </span><span class="n">configuration</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="w"> </span><span class="n">args</span><span class="err">‚Ä¶</span><span class="w"> </span><span class="p">);</span>
</span><span id="__span-78-9"><a id="__codelineno-78-9" name="__codelineno-78-9"></a><span class="o">-</span><span class="w"> </span><span class="n">transfer</span><span class="w"> </span><span class="n">results</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">host</span><span class="w"> </span><span class="err">‚Äì</span><span class="w"> </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">h_GlblVarPtr</span><span class="p">,</span><span class="err">‚Ä¶</span><span class="p">)</span>
</span><span id="__span-78-10"><a id="__codelineno-78-10" name="__codelineno-78-10"></a>
</span><span id="__span-78-11"><a id="__codelineno-78-11" name="__codelineno-78-11"></a><span class="o">-</span><span class="w"> </span><span class="n">optional</span><span class="o">:</span><span class="w"> </span><span class="n">compare</span><span class="w"> </span><span class="n">against</span><span class="w"> </span><span class="n">golden</span><span class="w"> </span><span class="p">(</span><span class="n">host</span><span class="w"> </span><span class="n">computed</span><span class="p">)</span><span class="w"> </span><span class="n">solution</span>
</span></code></pre></div></td></tr></table></div>
<p>Classic (Historical) PC Architecture</p>
<p>(Original) PCI Bus Specification</p>
<h3 id="peripheral-component-interconnect-pci">Peripheral Component Interconnect (PCI)<a class="headerlink" href="#peripheral-component-interconnect-pci" title="Permanent link">&para;</a></h3>
<h4 id="pci">PCI<a class="headerlink" href="#pci" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251207162342363.png" alt="image-20251207162342363" style="zoom:50%;" /></p>
<ul>
<li>
<p>high latency protocol</p>
</li>
<li>
<p>PCI device registers are mapped into the CPU‚Äôs physical address space</p>
<p>Accessed through loads/stores (kernel mode)</p>
<p>Addresses are assigned to the PCI devices at boot time</p>
<p>All devices listen for their addresses</p>
</li>
</ul>
<h4 id="pcie">PCIe<a class="headerlink" href="#pcie" title="Permanent link">&para;</a></h4>
<p>PCI Express (PCIe)</p>
<ul>
<li>switched, point-to-point connection</li>
<li>each card has dedicated ‚Äúlink‚Äù to the central switch, with no arbitration‰ª≤Ë£Å</li>
<li>packet switches: messages form virtual channel</li>
<li>prioritized packets for QoS (such as for real-time video streaming)</li>
</ul>
<p>PCIe Generations</p>
<ul>
<li>Within a generation, number of lanes in a link can be scaled using distinct physical channels (more bits / wider transfers) √ó1, √ó2, √ó4, √ó8, √ó16, √ó32, ‚Ä¶</li>
<li>PCIe original was 2GT/s, but now the latest PCIe 6.0 is 64GT/s</li>
</ul>
<p>PCIe Gen 3 Links and Lanes</p>
<ul>
<li>
<p>Each link consists of one or more lanes</p>
</li>
<li>
<p>Each lane is 1-bit wide (4 wires, each 2-wire pair can transmit 8Gb/s in one direction)</p>
</li>
<li>
<p>Each byte data is <strong>128b/130b</strong> encoded into 130 bits with equal number of 1‚Äôs and 0‚Äôs </p>
<p>Thus, the net data rates are 985 MB/s (x1), 1.97 GB/s (x2), 3.94 GB/s (x4), 7.9 GB/s (x8), 15.8 GB/s (x16), each way</p>
</li>
</ul>
<p>Foundation: 8/10 bit encoding</p>
<p>Current: 128/130 bit encoding</p>
<p>SLI connector helps to syncronize GPUs sothat they render in the same speed.</p>
<h3 id="pcie-data-transfer-using-dma">PCIe Data Transfer using DMA<a class="headerlink" href="#pcie-data-transfer-using-dma" title="Permanent link">&para;</a></h3>
<p><strong>DMA (Direct Memory Access)</strong> is used to fully utilize the bandwidth of an I/O bus</p>
<p>DMA uses physical address for source and destination</p>
<p>Transfers a number of bytes requested by OS</p>
<p>Needs pinned memory Âõ∫ÂÆöÂÜÖÂ≠ò</p>
<h3 id="pinned-memory">Pinned Memory<a class="headerlink" href="#pinned-memory" title="Permanent link">&para;</a></h3>
<p>DMA uses physical addresses</p>
<p>The OS could accidentally page out the data that is being read or written by a DMA and page in another virtual page into the same location</p>
<p>Pinned memory cannot be paged out</p>
<p>If a source or destination of a cudaMemcpy in the host memory is not pinned, it needs to be first copied to a pinned memory ‚Äì extra overhead</p>
<p><code>cudaMemcpy</code> is much <em>faster</em> with pinned host memory source or destination</p>
<p>Allocate/Free Pinned Memory</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-79-1">1</a></span>
<span class="normal"><a href="#__codelineno-79-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-79-1"><a id="__codelineno-79-1" name="__codelineno-79-1"></a><span class="n">cudaHostAlloc</span><span class="p">();</span>
</span><span id="__span-79-2"><a id="__codelineno-79-2" name="__codelineno-79-2"></a><span class="n">cudaFreeHost</span><span class="p">();</span>
</span></code></pre></div></td></tr></table></div>
<p>NVIDIA Ampere GPUs: AI Accelerators</p>
<p><strong>NVlink</strong> makes any GPU talk to other GPUs. </p>
<ul>
<li>high-speed interconnect(hundreds of GB/s)</li>
</ul>
<p>CPUs are interconnected.</p>
<p><img src="./assets/image-20251030213459693.png" alt="image-20251030213459693" style="zoom:50%;" /></p>
<p>IBM Power9 System</p>
<p>NO PCIe interconnect</p>
<h4 id="deltas-nvidia-a40-gpus">Delta‚Äôs NVIDIA A40 GPUs<a class="headerlink" href="#deltas-nvidia-a40-gpus" title="Permanent link">&para;</a></h4>
<p>When profiling, make sure the CPU is not overloaded, have access to all GPUs(don't want other jobs on the host/system)</p>
<h3 id="problem-solving_6">Problem Solving<a class="headerlink" href="#problem-solving_6" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251030221800183.png" alt="image-20251030221800183" style="zoom: 33%;" /></p>
<blockquote>
<p>The goal is to find which kernel configuration (K1, K2, K3, or K4) achieves the maximum <strong>occupancy</strong>, which is defined as the ratio of active warps per SM to the maximum allowed warps per SM .</p>
<p>For a <strong>Compute Capability (CC) 1.3</strong> device, the key hardware limits per SM are :</p>
<ul>
<li><strong>Max Warps per SM:</strong> 32</li>
<li><strong>Max Blocks per SM:</strong> 8</li>
<li><strong>Shared Memory per SM:</strong> 16K</li>
<li><strong>Registers per SM:</strong> 16K</li>
</ul>
<p>We also use the standard CUDA definition of <strong>1 warp = 32 threads</strong>.</p>
<p>üß† The Logic</p>
<p>To find the actual number of active warps, we first must find out how many <strong>blocks</strong> can run on a single SM at the same time. The number of concurrent blocks is limited by <em>all</em> of the SM's resources. A block can only be scheduled if it does not exceed <em>any</em> of the limits.</p>
<p>For each kernel, we must find the <strong>limiting factor</strong> by calculating the maximum number of blocks that can fit based on each resource limit.</p>
<ol>
<li><strong>Warps per Block:</strong> First, we calculate how many warps are in each block(<code>blockDim</code>).<ul>
<li><code>Warps per Block = ceil(Threads per Block / 32)</code></li>
</ul>
</li>
<li><strong>Find the Limiting Resource:</strong> We find the maximum number of blocks allowed by each of the four SM limits.<ul>
<li><strong>Limit 1 (Max Blocks):</strong> <code>8</code> (this is a fixed limit)</li>
<li><strong>Limit 2 (Shared Memory):</strong> <code>floor(Shared Memory per SM / Shared Memory per Block)</code></li>
<li><strong>Limit 3 (Registers):</strong> <code>floor(Registers per SM / Registers per Block)</code></li>
<li><strong>Limit 4 (Warps):</strong> <code>floor(Max Warps per SM / Warps per Block)</code></li>
</ul>
</li>
<li><strong>Actual Blocks per SM:</strong> The <em>actual</em> number of blocks that can run concurrently is the <strong>minimum</strong> of these four limits.<ul>
<li><code>Actual Blocks = min(Limit 1, Limit 2, Limit 3, Limit 4)</code></li>
</ul>
</li>
<li><strong>Actual Warps per SM:</strong> Once we know the actual number of blocks, we can find the total active warps.<ul>
<li><code>Actual Warps = Actual Blocks * Warps per Block</code></li>
</ul>
</li>
<li><strong>Find the Max:</strong> The kernel with the highest "Actual Warps per SM" has the maximum occupancy.</li>
</ol>
<p>üßÆ The Calculation</p>
<p>Let's apply this logic to each kernel using the data from the tables .</p>
<table>
<thead>
<tr>
<th><strong>Kernel</strong></th>
<th><strong>Warps per Blockceil(Threads / 32)</strong></th>
<th><strong>Max Blocks(SM Limit)</strong></th>
<th><strong>Max Blocks(SMem Limit)</strong></th>
<th><strong>Max Blocks(Regs Limit)</strong></th>
<th><strong>Max Blocks(Warps Limit)</strong></th>
<th><strong>Actual Blocks per SM(Minimum of limits)</strong></th>
<th><strong>Actual Warps per SM(Actual Blocks * Warps/Block)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>K1</strong></td>
<td><code>ceil(160/32) = 5</code></td>
<td>8</td>
<td><code>floor(16K/7K) = 2</code></td>
<td><code>floor(16K/1K) = 16</code></td>
<td><code>floor(32/5) = 6</code></td>
<td><code>min(8, 2, 16, 6) = 2</code></td>
<td><code>2 * 5 = 10</code></td>
</tr>
<tr>
<td><strong>K2</strong></td>
<td><code>ceil(224/32) = 7</code></td>
<td>8</td>
<td><code>floor(16K/8K) = 2</code></td>
<td><code>floor(16K/6K) = 2</code></td>
<td><code>floor(32/7) = 4</code></td>
<td><code>min(8, 2, 2, 4) = 2</code></td>
<td><code>2 * 7 = 14</code></td>
</tr>
<tr>
<td><strong>K3</strong></td>
<td><code>ceil(288/32) = 9</code></td>
<td>8</td>
<td><code>floor(16K/10K) = 1</code></td>
<td><code>floor(16K/9K) = 1</code></td>
<td><code>floor(32/9) = 3</code></td>
<td><code>min(8, 1, 1, 3) = 1</code></td>
<td><code>1 * 9 = 9</code></td>
</tr>
<tr>
<td><strong>K4</strong></td>
<td><code>ceil(96/32) = 3</code></td>
<td>8</td>
<td><code>floor(16K/4K) = 4</code></td>
<td><code>floor(16K/2K) = 8</code></td>
<td><code>floor(32/3) = 10</code></td>
<td><code>min(8, 4, 8, 10) = 4</code></td>
<td><code>4 * 3 = 12</code></td>
</tr>
</tbody>
</table>
<p>‚úÖ Conclusion</p>
<p>By comparing the "Actual Warps per SM" for each kernel:</p>
<ul>
<li>K1: 10 warps</li>
<li><strong>K2: 14 warps</strong></li>
<li>K3: 9 warps</li>
<li>K4: 12 warps</li>
</ul>
<p><strong>K2</strong> achieves the highest number of active warps (14), giving it the maximum occupancy (14/32 = 43.75%). This matches the provided answer .</p>
</blockquote>
<h2 id="19-acclerating-matrix-operations">19 Acclerating Matrix Operations<a class="headerlink" href="#19-acclerating-matrix-operations" title="Permanent link">&para;</a></h2>
<h3 id="tensor-cores">Tensor Cores<a class="headerlink" href="#tensor-cores" title="Permanent link">&para;</a></h3>
<h4 id="1-the-motivation-deep-learning-scale"><strong>1. The Motivation: Deep Learning Scale</strong><a class="headerlink" href="#1-the-motivation-deep-learning-scale" title="Permanent link">&para;</a></h4>
<p>Modern AI models are enormous. LLaMA 3.1 has <strong>70 billion parameters</strong>.</p>
<ul>
<li>A single matrix multiplication for the "Query" (Q) projection involves matrices of size <strong>8192 <span class="arithmatex">\(\times\)</span> 8192</strong>.</li>
<li>That is roughly <strong><span class="arithmatex">\(11 \times 10^{11}\)</span> operations</strong> just for that one step1.</li>
<li>Standard <code>float</code> (FP32) math on standard CUDA cores is simply too slow. We need specialized hardware.</li>
</ul>
<h4 id="2-the-hardware-tensor-cores"><strong>2. The Hardware: Tensor Cores</strong><a class="headerlink" href="#2-the-hardware-tensor-cores" title="Permanent link">&para;</a></h4>
<p>Standard CUDA cores add two numbers. Tensor Cores perform a whole matrix calculation in one hardware cycle: $<span class="arithmatex">\(D = A \times B + C\)</span>$</p>
<ul>
<li><strong>Inputs (<span class="arithmatex">\(A, B\)</span>):</strong> Usually lower precision (FP16 or BF16) to save bandwidth and space.</li>
<li><strong>Accumulator (<span class="arithmatex">\(C, D\)</span>):</strong> Higher precision (FP32) to preserve accuracy during the sum.</li>
</ul>
<h4 id="3-the-software-wmma-api"><strong>3. The Software: WMMA API</strong><a class="headerlink" href="#3-the-software-wmma-api" title="Permanent link">&para;</a></h4>
<p>To use Tensor Cores, CUDA provides the <strong>WMMA (Warp Matrix Multiply Accumulate)</strong> API. It works at the <strong>Warp level</strong>, not the Thread level.</p>
<p><strong>The Workflow:</strong></p>
<ol>
<li><strong>Declare Fragments:</strong> You don't access registers directly. You declare <code>wmma::fragment</code> variables. These are "opaque" structures that hold a piece of the matrix tile distributed across the threads in the warp.</li>
<li><strong>Load:</strong> <code>wmma::load_matrix_sync</code>. The warp collaboratively loads data from memory (Global or Shared) into the fragments.</li>
<li><strong>Compute:</strong> <code>wmma::mma_sync</code>. The hardware performs the matrix multiply (<span class="arithmatex">\(D = A \times B + C\)</span>)</li>
<li><strong>Store:</strong> <code>wmma::store_matrix_sync</code>. The result is written back to memory.</li>
</ol>
<blockquote>
<p>[!NOTE]</p>
<p>All WMMA functions end in <code>_sync</code> (e.g., <code>load_matrix_sync</code>, <code>mma_sync</code>).</p>
<p>==&gt; All threads in the Warp must execute this function simultaneously (converged) to perform the cooperative operation.</p>
</blockquote>
<h4 id="4-tiling-constraints"><strong>4. Tiling Constraints</strong><a class="headerlink" href="#4-tiling-constraints" title="Permanent link">&para;</a></h4>
<p>You can't just throw any matrix size at a Tensor Core. It operates on fixed-size tiles (e.g., <span class="arithmatex">\(16 \times 16 \times 16\)</span>).</p>
<ul>
<li>If your matrix is huge, you must break it down into these <span class="arithmatex">\(16 \times 16\)</span> chunks.</li>
<li>If your matrix is small or irregular, you might have to pad it with zeros to fit.</li>
</ul>
<h2 id="20-data-transfer-and-cuda-streams-task-parallelism">20 Data Transfer and CUDA Streams (Task Parallelism)<a class="headerlink" href="#20-data-transfer-and-cuda-streams-task-parallelism" title="Permanent link">&para;</a></h2>
<h3 id="serialized-data-transfer">Serialized Data Transfer<a class="headerlink" href="#serialized-data-transfer" title="Permanent link">&para;</a></h3>
<p>So far, the way we use cudaMemcpy serializes data transfer and GPU computation</p>
<p><strong>Timeline:</strong> <code>Copy H2D</code> <span class="arithmatex">\(\rightarrow\)</span> <code>Kernel</code> <span class="arithmatex">\(\rightarrow\)</span> <code>Copy D2H</code></p>
<p><img src="./assets/image-20251105203244248.png" alt="image-20251105203244248" style="zoom: 33%;" /></p>
<h3 id="device-overlap">Device Overlap<a class="headerlink" href="#device-overlap" title="Permanent link">&para;</a></h3>
<p>Most CUDA devices support <em>device overlap</em> ËÆæÂ§áÈáçÂè†</p>
<ul>
<li>Simultaneously execute a kernel while performing a copy between device and host memory</li>
</ul>
<p>When GPU is computing here, the interconnect is idle; when the interconnect is busy by transferring data one way, the GPU is idle.</p>
<p>-&gt; Q: Can it be done differently?</p>
<blockquote>
<p>Yes. Device Overlap, we can transfer data at the sme time in both directions</p>
</blockquote>
<p>Checking if this is supported</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-80-1">1</a></span>
<span class="normal"><a href="#__codelineno-80-2">2</a></span>
<span class="normal"><a href="#__codelineno-80-3">3</a></span>
<span class="normal"><a href="#__codelineno-80-4">4</a></span>
<span class="normal"><a href="#__codelineno-80-5">5</a></span>
<span class="normal"><a href="#__codelineno-80-6">6</a></span>
<span class="normal"><a href="#__codelineno-80-7">7</a></span>
<span class="normal"><a href="#__codelineno-80-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-80-1"><a id="__codelineno-80-1" name="__codelineno-80-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">cudaDeviceProp</span><span class="p">;</span>
</span><span id="__span-80-2"><a id="__codelineno-80-2" name="__codelineno-80-2"></a><span class="n">dev_count</span><span class="w"> </span><span class="n">prop</span><span class="p">;</span>
</span><span id="__span-80-3"><a id="__codelineno-80-3" name="__codelineno-80-3"></a><span class="n">cudaGetDeviceCount</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">dev_count</span><span class="p">);</span>
</span><span id="__span-80-4"><a id="__codelineno-80-4" name="__codelineno-80-4"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">dev_count</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-80-5"><a id="__codelineno-80-5" name="__codelineno-80-5"></a><span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">prop</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">);</span>
</span><span id="__span-80-6"><a id="__codelineno-80-6" name="__codelineno-80-6"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">prop</span><span class="p">.</span><span class="n">deviceOverlap</span><span class="p">){</span>
</span><span id="__span-80-7"><a id="__codelineno-80-7" name="__codelineno-80-7"></a><span class="w">    </span><span class="p">...</span>
</span><span id="__span-80-8"><a id="__codelineno-80-8" name="__codelineno-80-8"></a><span class="w">  </span><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="cuda-streams">CUDA Streams<a class="headerlink" href="#cuda-streams" title="Permanent link">&para;</a></h3>
<p>CUDA supports parallel execution of kernels and <code>cudaMemcpy</code> with <strong>streams</strong></p>
<p>Each stream <strong>is a queue of operations</strong> (kernel launches and cudaMemcpy‚Äôs)</p>
<p><strong>Across streams:</strong> Operations can execute <strong>concurrently</strong> (in parallel) .</p>
<p><strong><code>cudaMemcpyAsync</code>:</strong> Returns control to the host immediately. This allows the host to queue up the next task (kernel or copy) in a different stream while the hardware handles the transfer in the background. Á´ãÂç≥Â∞ÜÊéßÂà∂ÊùÉËøîÂõûÁªô‰∏ªÊú∫„ÄÇËøôÊ†∑Ôºå‰∏ªÊú∫Â∞±ÂèØ‰ª•Â∞Ü‰∏ã‰∏Ä‰∏™‰ªªÂä°ÔºàÂÜÖÊ†∏ÊàñÂ§çÂà∂ÔºâÊîæÂÖ•‰∏çÂêåÁöÑÊµÅ‰∏≠ÊéíÈòüÔºåËÄåÁ°¨‰ª∂ÂàôÂú®ÂêéÂè∞Â§ÑÁêÜ‰º†Ëæì„ÄÇ</p>
<p><code>cudaMemcpy</code> is blocking (synchronous) and halts the host thread.</p>
<p><strong>Good (Breadth-First):</strong> Loop over "stages". Queue <code>H2D</code> for <em>all</em> streams. Then queue <code>Kernel</code> for <em>all</em> streams. Then <code>D2H</code> for <em>all</em> streams.</p>
<p>To fully overlap <strong>Host-to-Device</strong> transfer, <strong>Kernel</strong> execution, and <strong>Device-to-Host</strong> transfer simultaneously (3-way concurrency), how many distinct hardware engines does the GPU need?</p>
<ul>
<li>3 (Copy Engine Up + Copy Engine Down + Kernel Engine)</li>
</ul>
<h2 id="21-parallel-sparse-methods">21 Parallel Sparse Methods<a class="headerlink" href="#21-parallel-sparse-methods" title="Permanent link">&para;</a></h2>
<blockquote>
<p>[!NOTE]</p>
<p>To learn the key techniques for compacting input data in parallel sparse methods for reduced consumption of memory bandwidth</p>
<ul>
<li>Better utilization of on-chip memory</li>
<li>Fewer bytes transferred to on-chip memory</li>
<li>Better utilization of global memory</li>
<li>Challenge: retaining regularity</li>
</ul>
</blockquote>
<p>A <strong>sparse matrix</strong> is one where many elements are <strong>zero</strong></p>
<p><strong>The Goal:</strong> We want to compress the data to save memory bandwidth (the biggest bottleneck on GPUs) without making the computation too messy or slow.</p>
<h3 id="sparse-matrix-storage-formats">Sparse Matrix Storage Formats<a class="headerlink" href="#sparse-matrix-storage-formats" title="Permanent link">&para;</a></h3>
<h4 id="coordinate-format-coo">Coordinate Format (COO)<a class="headerlink" href="#coordinate-format-coo" title="Permanent link">&para;</a></h4>
<p>Store every nonzero along with its row index and column index<img src="./assets/image-20251203143451093.png" alt="image-20251203143451093" style="zoom:25%;" /></p>
<p>For every non-zero value, we just store three things: <code>(row, column, value)</code>.</p>
<ul>
<li><strong>Example:</strong> If we have a value <code>7</code> at row 0, column 1:<ul>
<li><code>row_index</code>: 0</li>
<li><code>col_index</code>: 1</li>
<li><code>value</code>: 7</li>
</ul>
</li>
</ul>
<p>Problem: When multiple threads try to add to the same spot in the output vector at the same time, they create a <strong>race condition</strong>. One thread might overwrite the work of another, leading to incorrect results.</p>
<p><strong>COO Tradeoffs</strong></p>
<p>Advantages:</p>
<ul>
<li>
<p>Modifiability: easy to add new elements to the matrix, nonzeros can be stored in any order</p>
</li>
<li>
<p>Accessibility: given nonzero, easy to find row and column</p>
</li>
<li>SpMV/COO memory accesses to the input matrix are <em>coalesced</em></li>
<li>SpMV/COO has <em>no control divergence</em></li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>Accessibility: given a row or column, hard to find all nonzeros (need to search)</li>
<li>SpMV/COO memory accesses to the output vector require <em>atomic operations</em></li>
</ul>
<p>To fix this in COO, we have to use <strong>Atomic Operations</strong> (like <code>atomicAdd</code>), which forces threads to wait their turn. While this ensures correctness, it slows down performance because threads are stuck waiting in line.</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-81-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-81-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-81-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-81-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-81-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-81-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-81-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-81-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-81-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-81-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-81-1"><a id="__codelineno-81-1" name="__codelineno-81-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">spmv_coo_kernel</span><span class="p">(</span><span class="n">COOMatrix</span><span class="w"> </span><span class="n">cooMatrix</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-81-2"><a id="__codelineno-81-2" name="__codelineno-81-2"></a><span class="w">                                </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">inVector</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">outVector</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-81-3"><a id="__codelineno-81-3" name="__codelineno-81-3"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-81-4"><a id="__codelineno-81-4" name="__codelineno-81-4"></a><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">cooMatrix</span><span class="p">.</span><span class="n">numNonzeros</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-81-5"><a id="__codelineno-81-5" name="__codelineno-81-5"></a><span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cooMatrix</span><span class="p">.</span><span class="n">rowIdxs</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-81-6"><a id="__codelineno-81-6" name="__codelineno-81-6"></a><span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cooMatrix</span><span class="p">.</span><span class="n">colIdxs</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-81-7"><a id="__codelineno-81-7" name="__codelineno-81-7"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cooMatrix</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-81-8"><a id="__codelineno-81-8" name="__codelineno-81-8"></a><span class="w">    </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">outVector</span><span class="p">[</span><span class="n">row</span><span class="p">],</span><span class="w"> </span><span class="n">inVector</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">*</span><span class="n">value</span><span class="p">);</span>
</span><span id="__span-81-9"><a id="__codelineno-81-9" name="__codelineno-81-9"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-81-10"><a id="__codelineno-81-10" name="__codelineno-81-10"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="compressed-sparse-row-csr">Compressed Sparse Row (CSR)<a class="headerlink" href="#compressed-sparse-row-csr" title="Permanent link">&para;</a></h4>
<p>Store nonzeros of the same <strong>row</strong> adjacently and an index to the first element of each row. <img src="./assets/image-20251203143537881.png" alt="image-20251203143537881" style="zoom:25%;" /></p>
<p>To avoid storing every single row index repeatedly (like COO does), we use <strong>CSR</strong>. This is the most common format in scientific computing.</p>
<ul>
<li><strong>CSR</strong> stores: <code>Value</code> and <code>Col</code> (size <span class="arithmatex">\(NNZ\)</span>), but it replaces the <code>Row</code> array with a much smaller array called <code>RowPtr</code>.</li>
</ul>
<p><strong>CSR Tradeoffs (versus COO)</strong></p>
<p>Advantages:
- Space efficiency: row pointers smaller than row indexes
- Accessibility: given a row, easy to find all nonzeros
- SpMV/CSR memory accesses to the output vector are coalesced and do not require atomics</p>
<p>Disadvantage:</p>
<ul>
<li>Modifiability: hard to add new elements to the matrix</li>
<li>Accessibility: given nonzero, hard to find row; given a column, hard to find all nonzeros</li>
<li>SpMV/CSR memory accesses to the input matrix are <em>not coalesced</em></li>
<li>SpMV/CSR has <em>control divergence</em></li>
</ul>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-82-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-82-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-82-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-82-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-82-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-82-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-82-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-82-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-82-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-82-10">10</a></span>
<span class="normal"><a href="#__codelineno-82-11">11</a></span>
<span class="normal"><a href="#__codelineno-82-12">12</a></span>
<span class="normal"><a href="#__codelineno-82-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-82-1"><a id="__codelineno-82-1" name="__codelineno-82-1"></a><span class="n">_global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">SpMV_CSR</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">num_rows</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">col_index</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">row_ptr</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">data</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-82-2"><a id="__codelineno-82-2" name="__codelineno-82-2"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-82-3"><a id="__codelineno-82-3" name="__codelineno-82-3"></a><span class="p">{</span>
</span><span id="__span-82-4"><a id="__codelineno-82-4" name="__codelineno-82-4"></a><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-82-5"><a id="__codelineno-82-5" name="__codelineno-82-5"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_rows</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-82-6"><a id="__codelineno-82-6" name="__codelineno-82-6"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">dot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-82-7"><a id="__codelineno-82-7" name="__codelineno-82-7"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row_start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">row_ptr</span><span class="p">[</span><span class="n">row</span><span class="p">];</span>
</span><span id="__span-82-8"><a id="__codelineno-82-8" name="__codelineno-82-8"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row_end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">row_ptr</span><span class="p">[</span><span class="n">row</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>
</span><span id="__span-82-9"><a id="__codelineno-82-9" name="__codelineno-82-9"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">elem</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">row_start</span><span class="p">;</span><span class="w"> </span><span class="n">elem</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">row_end</span><span class="p">;</span><span class="w"> </span><span class="n">elem</span><span class="o">++</span><span class="p">)</span>
</span><span id="__span-82-10"><a id="__codelineno-82-10" name="__codelineno-82-10"></a><span class="w">      </span><span class="n">dot</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">data</span><span class="p">[</span><span class="n">elem</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">col_index</span><span class="p">[</span><span class="n">elem</span><span class="p">]];</span>
</span><span id="__span-82-11"><a id="__codelineno-82-11" name="__codelineno-82-11"></a><span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">row</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dot</span><span class="p">;</span>
</span><span id="__span-82-12"><a id="__codelineno-82-12" name="__codelineno-82-12"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-82-13"><a id="__codelineno-82-13" name="__codelineno-82-13"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="compressed-sparse-column-csc">Compressed Sparse Column (CSC)<a class="headerlink" href="#compressed-sparse-column-csc" title="Permanent link">&para;</a></h4>
<blockquote>
<p>[!CAUTION]</p>
<p>CSC is typically not used for SpMV</p>
<ul>
<li>Useful for computations where the vector is very sparse: if an input vector value is zero, we can avoid accessing and entire matrix column</li>
</ul>
</blockquote>
<p>Store nonzeros of the same <strong>column</strong> adjacently and an index to the first element of each column</p>
<p><img src="./assets/image-20251203144519642.png" alt="image-20251203144519642" style="zoom:25%;" /></p>
<p>CSC Tradeoffs (versus CSR)</p>
<p>Advantages:</p>
<ul>
<li>
<p>Space efficiency: same as CSR</p>
</li>
<li>
<p>Accessibility: given a column, easy to find all nonzeros</p>
</li>
<li>
<p>SpMV/CSC achieves memory accesses to the input vector are coalesced</p>
</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>
<p>Modifiability: hard to add new elements to the matrix</p>
</li>
<li>
<p>Accessibility: given nonzero, hard to find row; given a row, hard to find all nonzeros</p>
</li>
<li>
<p>SpMV/CSC memory accesses to the input matrix are not coalesced</p>
</li>
<li>
<p>SpMV/CSC memory accesses to the output vector require <em>atomic operations</em></p>
</li>
<li>
<p>SpMV/CSC has control divergence</p>
</li>
</ul>
<h4 id="ellpack-format-ell">ELLPACK Format (ELL)<a class="headerlink" href="#ellpack-format-ell" title="Permanent link">&para;</a></h4>
<p>Column-Major Order</p>
<p>We store the <strong>1<sup>st</sup> element</strong> of Row 0, then the <strong>1<sup>st</sup> element</strong> of Row 1, then the <strong>1<sup>st</sup> element</strong> of Row 2...</p>
<p>Then we store the <strong>2<sup>nd</sup> element</strong> of Row 0, the <strong>2<sup>nd</sup> element</strong> of Row 1...</p>
<p>We typically use two arrays to store the matrix:</p>
<ol>
<li><strong><code>data</code></strong>: Stores the actual values (including padded zeros).</li>
<li><strong><code>col_index</code></strong>: Stores the column index for each value. (For padded zeros, we usually store a dummy index like <code>-1</code> or just reuse a valid column index since the value is 0 anyway).</li>
</ol>
<p><img src="./assets/image-20251203155340069.png" alt="image-20251203155340069" style="zoom:25%;" /><img src="./assets/image-20251203155354420.png" alt="image-20251203155354420" style="zoom:25%;" /></p>
<p>Advantages:</p>
<ul>
<li>
<p>Modifiability: can add new elements as long as row not full</p>
</li>
<li>
<p>Accessibility: given a row, easy to find all nonzeros; given nonzero, easy to find row and column</p>
</li>
<li>
<p>SpMV/ELL memory accesses are <em>coalesced</em></p>
</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>
<p>Space efficiency: <em>overhead</em> due to padding</p>
</li>
<li>
<p>Accessibility: given a column, hard to find all nonzeros</p>
</li>
<li>
<p>SpMV/ELL has <em>control divergence</em></p>
</li>
</ul>
<h4 id="jagged-diagonal-storage-jds">Jagged Diagonal Storage (JDS)<a class="headerlink" href="#jagged-diagonal-storage-jds" title="Permanent link">&para;</a></h4>
<p><img src="./assets/image-20251203201003861.png" alt="image-20251203201003861" style="zoom:25%;" /><img src="./assets/image-20251203201018689.png" alt="image-20251203201018689" style="zoom:25%;" /></p>
<p>JDS tries to fix ELL's padding problem <strong>without</strong> needing a secondary COO list.</p>
<p>Keep track of the <strong>original row numbers</strong>(<code>jds_row_perm</code>) so that the output vector can be generated correctly.</p>
<p><strong>JDS Tradeoffs</strong></p>
<p>Advantages:</p>
<ul>
<li>
<p>Space efficiency: no padding</p>
</li>
<li>
<p>Accessibility: given a row, easy to find all nonzeros</p>
</li>
<li>
<p>SpMV/JDS memory accesses are coalesced</p>
</li>
<li>
<p>SpMV/JDS minimizes control divergence</p>
</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>
<p>Modifiability: hard to add new elements to the matrix </p>
</li>
<li>
<p>Accessibility: given nonzero, hard to find row; given a column, hard to find all nonzeros</p>
</li>
</ul>
<h3 id="what-format-should-we-use">What format should we use?<a class="headerlink" href="#what-format-should-we-use" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Condition</th>
<th>Method</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>Roughly Random</td>
<td>Probably best with <strong>ELL</strong></td>
<td>Padding will be uniformly distributed; Sparse representation will be uniform</td>
</tr>
<tr>
<td>High variance in rows</td>
<td>Probably best with <strong>ELL/COO</strong></td>
<td>Benefit of ELL for most cases; Outliers are captured with COO</td>
</tr>
<tr>
<td>Very sparse</td>
<td>Probably best with <strong>COO</strong></td>
<td>Not a lot of data, compute is sparse</td>
</tr>
<tr>
<td>Roughly triangular</td>
<td>Probably best with <strong>JDS</strong></td>
<td>Takes advantage of sparsity structure</td>
</tr>
<tr>
<td>Banded Matrix</td>
<td>Probably best with <strong>ELL</strong></td>
<td>Small amount of variance in rows</td>
</tr>
</tbody>
</table>
<h2 id="22-other-acceleration-apisalternatives-to-cuda">22 Other Acceleration APIs(Alternatives to CUDA)<a class="headerlink" href="#22-other-acceleration-apisalternatives-to-cuda" title="Permanent link">&para;</a></h2>
<p>CUDA is just one way to accelerate code</p>
<ol>
<li><strong>OpenCL üåê:</strong> An open standard that runs on almost anything‚ÄîCPUs, GPUs, FPGAs‚Äînot just NVIDIA hardware. ‰∏Ä‰∏™ÂºÄÊîæÊ†áÂáÜÔºåÂá†‰πéÂèØ‰ª•Âú®‰ªª‰ΩïËÆæÂ§á‰∏äËøêË°å‚Äî‚ÄîCPU„ÄÅGPU„ÄÅFPGA‚Äî‚ÄîËÄå‰∏ç‰ªÖ‰ªÖÊòØ NVIDIA Á°¨‰ª∂„ÄÇ</li>
<li><strong>HIP ‚ÜîÔ∏è:</strong> A C++ dialect designed for portability, allowing code to run on both AMD and NVIDIA GPUs. ‰∏ÄÁßç‰∏∫ÂèØÁßªÊ§çÊÄßËÄåËÆæËÆ°ÁöÑ C++ ÊñπË®ÄÔºåÂÖÅËÆ∏‰ª£Á†ÅÂú® AMD Âíå NVIDIA GPU ‰∏äËøêË°å„ÄÇ</li>
<li><strong>OpenACC üìù:</strong> A "low-code" approach using compiler directives (pragmas) to tell the compiler what to parallelize, rather than writing explicit kernels. ‰∏ÄÁßç‚Äú‰Ωé‰ª£Á†Å‚ÄùÊñπÊ≥ïÔºå‰ΩøÁî®ÁºñËØëÂô®Êåá‰ª§ÔºàÁºñËØëÊåáÁ§∫ÔºâÂëäËØâÁºñËØëÂô®Ë¶ÅÂπ∂Ë°åÂåñ‰ªÄ‰πàÔºåËÄå‰∏çÊòØÁºñÂÜôÊòæÂºèÂÜÖÊ†∏„ÄÇ</li>
<li><strong>MPI üñ•Ô∏è:</strong> The standard for large-scale, multi-node parallel computing, often used in supercomputers to coordinate thousands of GPUs. Â§ßËßÑÊ®°Â§öËäÇÁÇπÂπ∂Ë°åËÆ°ÁÆóÁöÑÊ†áÂáÜÔºåÂ∏∏Áî®‰∫éË∂ÖÁ∫ßËÆ°ÁÆóÊú∫‰∏≠ÂçèË∞ÉÊï∞ÂçÉ‰∏™ GPU„ÄÇ</li>
</ol>
<p>Here are the key traits they all share with CUDA:</p>
<h3 id="hardware-traits">‚öôÔ∏è Hardware Traits<a class="headerlink" href="#hardware-traits" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Lightweight Cores:</strong> They rely on a hierarchy of many simple, lightweight cores rather than a few complex ones (like a CPU).
    <strong>ËΩªÈáèÁ∫ßÊ†∏ÂøÉÔºö</strong> ÂÆÉ‰ª¨‰æùÈù†ËÆ∏Â§öÁÆÄÂçï„ÄÅËΩªÈáèÁ∫ßÁöÑÊ†∏ÂøÉÁªÑÊàêÁöÑÂ±ÇÊ¨°ÁªìÊûÑÔºåËÄå‰∏çÊòØÂ∞ëÊï∞Â§çÊùÇÁöÑÊ†∏ÂøÉÔºàÂ¶Ç CPUÔºâ„ÄÇ</li>
<li><strong>Scratchpad Memory:</strong> They all utilize fast, local "scratchpad" memories that are close to the compute units.
    <strong>ÊöÇÂ≠òÂ≠òÂÇ®Âô®Ôºö</strong> ÂÆÉ‰ª¨ÈÉΩÂà©Áî®Èù†ËøëËÆ°ÁÆóÂçïÂÖÉÁöÑÂø´ÈÄüÊú¨Âú∞‚ÄúÊöÇÂ≠ò‚ÄùÂ≠òÂÇ®Âô®„ÄÇ</li>
<li><strong>No Hardware Coherence:</strong> Unlike CPUs, the hardware does not automatically keep caches in sync; you often have to manage data consistency manually.
    <strong>Ê≤°ÊúâÁ°¨‰ª∂‰∏ÄËá¥ÊÄßÔºö</strong> ‰∏é CPU ‰∏çÂêåÔºåÁ°¨‰ª∂‰∏ç‰ºöËá™Âä®‰øùÊåÅÁºìÂ≠òÂêåÊ≠•ÔºõÊÇ®ÈÄöÂ∏∏ÈúÄË¶ÅÊâãÂä®ÁÆ°ÁêÜÊï∞ÊçÆ‰∏ÄËá¥ÊÄß„ÄÇ</li>
<li><strong>Threading:</strong> They rely heavily on massive threading to hide latency.
    <strong>Â§öÁ∫øÁ®ãÔºö</strong> ÂÆÉ‰ª¨Â§ßÈáè‰æùËµñÂ§öÁ∫øÁ®ãÊù•ÈöêËóèÂª∂Ëøü„ÄÇ</li>
</ul>
<h3 id="software-traits">üíª Software Traits<a class="headerlink" href="#software-traits" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Kernels:</strong> You write code in "kernels"‚Äîfunctions designed to run on the device.
    <strong>ÂÜÖÊ†∏Ôºö</strong> ÊÇ®Âú®‚ÄúÂÜÖÊ†∏‚Äù‰∏≠ÁºñÂÜô‰ª£Á†Å‚Äî‚ÄîÂÜÖÊ†∏ÊòØËÆæËÆ°Áî®‰∫éÂú®ËÆæÂ§á‰∏äËøêË°åÁöÑÂáΩÊï∞„ÄÇ</li>
<li><strong>Separate Memory Spaces:</strong> There is a distinct split between <strong>Host Memory</strong> (CPU) and <strong>Device Memory</strong> (GPU).
    <strong>Áã¨Á´ãÁöÑÂÜÖÂ≠òÁ©∫Èó¥Ôºö</strong> <strong>‰∏ªÊú∫ÂÜÖÂ≠ò</strong> ÔºàCPUÔºâÂíå<strong>ËÆæÂ§áÂÜÖÂ≠ò</strong> ÔºàGPUÔºâ‰πãÈó¥Â≠òÂú®ÊòéÊòæÁöÑÂàíÂàÜ„ÄÇ</li>
<li><strong>Software-Managed Memory:</strong> You (the programmer) are responsible for moving data between these spaces (e.g., <code>cudaMemcpy</code>).
    <strong>ËΩØ‰ª∂ÁÆ°ÁêÜÂÜÖÂ≠òÔºö</strong> ÊÇ®ÔºàÁ®ãÂ∫èÂëòÔºâË¥üË¥£Âú®Ëøô‰∫õÁ©∫Èó¥‰πãÈó¥ÁßªÂä®Êï∞ÊçÆÔºà‰æãÂ¶ÇÔºå <code>cudaMemcpy</code> Ôºâ„ÄÇ</li>
<li><strong>Execution Hierarchy:</strong> Work is divided into a hierarchy of <strong>Grids</strong>, <strong>Blocks</strong>, and <strong>Threads</strong>.
    <strong>ÊâßË°åÂ±ÇÊ¨°ÁªìÊûÑÔºö</strong> Â∑•‰ΩúË¢´ÂàíÂàÜ‰∏∫<strong>ÁΩëÊ†º</strong> „ÄÅ <strong>Âùó</strong>Âíå<strong>Á∫øÁ®ã</strong>ÁöÑÂ±ÇÊ¨°ÁªìÊûÑ„ÄÇ</li>
<li><strong>Bulk Synchronous Parallelism:</strong> The general flow is: Launch work <span class="arithmatex">\(\rightarrow\)</span> Wait for everyone to finish <span class="arithmatex">\(\rightarrow\)</span> Synchronize <span class="arithmatex">\(\rightarrow\)</span> Move data.
    <strong>ÊâπÈáèÂêåÊ≠•Âπ∂Ë°åÔºö</strong> ‰∏ÄËà¨ÊµÅÁ®ãÊòØÔºöÂêØÂä®Â∑•‰Ωú <span class="arithmatex">\(\rightarrow\)</span> Á≠âÂæÖÊâÄÊúâ‰∫∫ÂÆåÊàê <span class="arithmatex">\(\rightarrow\)</span> ÂêåÊ≠• <span class="arithmatex">\(\rightarrow\)</span> ÁßªÂä®Êï∞ÊçÆ„ÄÇ</li>
</ul>
<h2 id="23-cuda-dynamic-parallelism">23 CUDA Dynamic Parallelism<a class="headerlink" href="#23-cuda-dynamic-parallelism" title="Permanent link">&para;</a></h2>
<p>Traditionally, the CPU (Host) acts as the "commander," telling the GPU exactly what to do and when. <strong>Dynamic Parallelism</strong> changes this by giving the GPU the ability to launch its own kernels without needing the CPU to intervene.
‰º†Áªü‰∏äÔºåCPUÔºà‰∏ªÊú∫ÔºâÊâÆÊºîÁùÄ‚ÄúÊåáÊå•ÂÆò‚ÄùÁöÑËßíËâ≤ÔºåÁ≤æÁ°ÆÂú∞ÂëäËØâ GPU ËØ•ÂÅö‰ªÄ‰πà‰ª•Âèä‰ΩïÊó∂ÂÅö„ÄÇÂä®ÊÄÅÂπ∂Ë°åÊîπÂèò‰∫ÜËøôÁßçÂ±ÄÈù¢ÔºåÂÆÉËµã‰∫à GPU Âú®Êó†ÈúÄ CPU Âπ≤È¢ÑÁöÑÊÉÖÂÜµ‰∏ãÂêØÂä®Ëá™Ë∫´ÂÜÖÊ†∏ÁöÑËÉΩÂäõ„ÄÇ</p>
<ol>
<li><strong>The Concept:</strong> Moving work generation from the Host to the Device to handle data-dependent workloads.
    Ê¶ÇÂøµÔºöÂ∞ÜÂ∑•‰ΩúÁîüÊàê‰ªé‰∏ªÊú∫ËΩ¨ÁßªÂà∞ËÆæÂ§áÔºå‰ª•Â§ÑÁêÜÊï∞ÊçÆÁõ∏ÂÖ≥ÁöÑÂ∑•‰ΩúË¥üËΩΩ„ÄÇ</li>
<li><strong>Use Cases: ‰ΩøÁî®Ê°à‰æãÔºö</strong><ul>
<li><strong>Dynamic Grids:</strong> Allocating resolution only where needed (e.g., turbulence simulations), rather than a wasteful fixed grid.
    Âä®ÊÄÅÁΩëÊ†ºÔºö‰ªÖÂú®ÈúÄË¶ÅÁöÑÂú∞ÊñπÔºà‰æãÂ¶ÇÊπçÊµÅÊ®°ÊãüÔºâÂàÜÈÖçÂàÜËæ®ÁéáÔºåËÄå‰∏çÊòØÊµ™Ë¥πËµÑÊ∫êÁöÑÂõ∫ÂÆöÁΩëÊ†º„ÄÇ</li>
<li><strong>Recursion:</strong> Algorithms like <strong>Quadtrees</strong> where a thread needs to subdivide itself into more threads based on data density.
    ÈÄíÂΩíÔºöÂÉèÂõõÂèâÊ†ëËøôÊ†∑ÁöÑÁÆóÊ≥ïÔºåÂÖ∂‰∏≠Á∫øÁ®ãÈúÄË¶ÅÊ†πÊçÆÊï∞ÊçÆÂØÜÂ∫¶Â∞ÜËá™Ë∫´ÁªÜÂàÜ‰∏∫Êõ¥Â§öÁ∫øÁ®ã„ÄÇ</li>
<li><strong>Library Calls:</strong> Allowing kernels to call libraries (like cuBLAS) directly.
    Â∫ìË∞ÉÁî®ÔºöÂÖÅËÆ∏ÂÜÖÊ†∏Áõ¥Êé•Ë∞ÉÁî®Â∫ìÔºàÂ¶Ç cuBLASÔºâ</li>
</ul>
</li>
<li><strong>Mechanics:</strong> How "Parent" grids launch "Child" grids and how they synchronize.
    Êú∫Âà∂ÔºöÁà∂ÁΩëÊ†ºÂ¶Ç‰ΩïÂêØÂä®Â≠êÁΩëÊ†º‰ª•ÂèäÂÆÉ‰ª¨Â¶Ç‰ΩïÂêåÊ≠•„ÄÇ</li>
</ol>
<h4 id="important-exam-concepts">Important Exam Concepts ÈáçË¶ÅËÄÉËØïÊ¶ÇÂøµ<a class="headerlink" href="#important-exam-concepts" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Parent-Child Synchronization:
    Áà∂Â≠êÂêåÊ≠•Ôºö</strong><ul>
<li>The Parent grid launches a Child grid. The Parent does <em>not</em> automatically wait for the Child to finish. You must explicitly use <code>cudaDeviceSynchronize()</code> inside the kernel if the Parent needs to read the Child's results. Áà∂ÁΩëÊ†ºÂêØÂä®Â≠êÁΩëÊ†º„ÄÇÁà∂ÁΩëÊ†º‰∏ç‰ºöËá™Âä®Á≠âÂæÖÂ≠êÁΩëÊ†ºÂÆåÊàê„ÄÇÂ¶ÇÊûúÁà∂ÁΩëÊ†ºÈúÄË¶ÅËØªÂèñÂ≠êÁΩëÊ†ºÁöÑÁªìÊûúÔºåÂàôÂøÖÈ°ªÂú®ÂÜÖÊ†∏‰∏≠ÊòæÂºè‰ΩøÁî® <code>cudaDeviceSynchronize()</code> Âê¶Âàô‰ºöËØªÂèñÈîôËØØ„ÄÇ</li>
<li><strong>Memory Consistency:</strong> The Parent is only guaranteed to see the memory writes of the Child <em>after</em> synchronization.
    ÂÜÖÂ≠ò‰∏ÄËá¥ÊÄßÔºöÂè™ÊúâÂú®ÂêåÊ≠•‰πãÂêéÔºåÊâçËÉΩ‰øùËØÅÁà∂ËøõÁ®ãÁúãÂà∞Â≠êËøõÁ®ãÁöÑÂÜÖÂ≠òÂÜôÂÖ•„ÄÇ</li>
</ul>
</li>
<li><strong>Syntax: Âè•Ê≥ïÔºö</strong><ul>
<li>The syntax inside a kernel is almost identical to the host: <code>kernel_name&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;(args)</code>.
    ÂÜÖÊ†∏ÂÜÖÈÉ®ÁöÑËØ≠Ê≥ï‰∏é‰∏ªÊú∫Âá†‰πéÁõ∏ÂêåÔºö <code>kernel_name&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;(args)</code> „ÄÇ</li>
</ul>
</li>
<li><strong>Streams in Dynamic Parallelism:
    Âä®ÊÄÅÂπ∂Ë°å‰∏≠ÁöÑÊµÅÔºö</strong><ul>
<li>By default, child kernels launched by a single thread launch sequentially. To run them in parallel (e.g., processing 4 quadrants of a Quadtree at once), you must use <strong>CUDA Streams</strong> created within the kernel.
    ÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåÁî±Âçï‰∏™Á∫øÁ®ãÂêØÂä®ÁöÑÂ≠êÂÜÖÊ†∏ÊåâÈ°∫Â∫èËøêË°å„ÄÇË¶ÅÂπ∂Ë°åËøêË°åÂÆÉ‰ª¨Ôºà‰æãÂ¶ÇÔºåÂêåÊó∂Â§ÑÁêÜÂõõÂèâÊ†ëÁöÑ 4 ‰∏™Ë±°ÈôêÔºâÔºåÂøÖÈ°ª‰ΩøÁî®ÂÜÖÊ†∏ÂÜÖÂàõÂª∫ÁöÑ CUDA ÊµÅ„ÄÇ</li>
</ul>
</li>
<li><strong>Performance Pitfalls (The "What is NOT" section):
    Áª©ÊïàÈô∑Èò±Ôºà‚Äú‰∏çÊòØ‰ªÄ‰πà‚ÄùÈÉ®ÂàÜÔºâÔºö</strong><ul>
<li>Launching very small grids (e.g., 1 block with 1 thread) is inefficient. It is better to have "thick tree nodes" or aggregate work before launching a child kernel.
    ÂêØÂä®ÈùûÂ∏∏Â∞èÁöÑÁΩëÊ†ºÔºà‰æãÂ¶ÇÔºå1 ‰∏™Á∫øÁ®ãÂ§ÑÁêÜ 1 ‰∏™ÂùóÔºâÊïàÁéá‰Ωé‰∏ã„ÄÇÊúÄÂ•ΩÂÖàÊûÑÂª∫‚ÄúÂéöÊ†ëËäÇÁÇπ‚ÄùÊàñÂú®ÂêØÂä®Â≠êÂÜÖÊ†∏‰πãÂâçËÅöÂêàÂ∑•‰Ωú„ÄÇ</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>Q:</strong> If a Parent thread launches a Child kernel and immediately tries to read the data the Child produced <em>without</em> calling <code>cudaDeviceSynchronize()</code> first, what do you think happens?</p>
<p><strong>A:</strong> It will essentially get <strong>old or invalid data</strong> (garbage) instead of the new results it wants. This happens because the Parent kernel continues executing immediately after launching the Child, without waiting. Unless you use <code>cudaDeviceSynchronize()</code>, the Parent might try to read the memory before the Child has finished writing to it .</p>
<p><strong>Q:</strong> If a single Parent thread launches multiple Child kernels (K0, K1, K2) using the <strong>default stream</strong>, do those children run at the same time (in parallel) or one after another (sequentially) ?</p>
<p><strong>A:</strong> When a parent thread launches multiple child grids into the <strong>default stream</strong> (NULL stream), they execute <strong>sequentially</strong> . Even if the hardware has space, the second child kernel won't start until the first one finishes. This is shown on the left side of Slide 20, where K0 through K7 run one after another.</p>
</blockquote>
<h2 id="24">24<a class="headerlink" href="#24" title="Permanent link">&para;</a></h2>
<p>Guest lecture by <strong>Katrina Riehl</strong>, <em>Principal Technical Product Manager,</em> NVIDIA: The CUDA Python Developer‚Äôs Toolbox</p>
<p><img alt="image-20251207164331515" src="assets/image-20251207164331515.png" /></p>
<h2 id="25-advanced-optimizations-improving-attention">25 Advanced Optimizations-Improving Attention<a class="headerlink" href="#25-advanced-optimizations-improving-attention" title="Permanent link">&para;</a></h2>
<h3 id="attention">Attention<a class="headerlink" href="#attention" title="Permanent link">&para;</a></h3>
<p><img alt="image-20251129201034173" src="assets/image-20251129201034173.png" /></p>
<h3 id="overview-why-optimize-attention"><strong>Overview: Why Optimize Attention?</strong><a class="headerlink" href="#overview-why-optimize-attention" title="Permanent link">&para;</a></h3>
<p>The lecture focuses on the "Attention" mechanism, which is the bottleneck in Large Language Model (LLM) inference. Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁì∂È¢à
* <strong>The Bottleneck:</strong> Attention scales quadratically <span class="arithmatex">\(O(T^2)\)</span> with sequence length.
* <strong>The Hardware Reality:</strong> For large sequences (<span class="arithmatex">\(100k+\)</span> tokens), creating and moving a <span class="arithmatex">\(T \times T\)</span> matrix between Global Memory (HBM) and On-Chip Memory (SRAM) is too slow.</p>
<h3 id="1-flash-attention-kernel-fusion-tiling">1. Flash Attention (Kernel Fusion &amp; Tiling)<a class="headerlink" href="#1-flash-attention-kernel-fusion-tiling" title="Permanent link">&para;</a></h3>
<p>ÂÜÖÊ†∏ËûçÂêà‰∏éÂàÜÂùó</p>
<p>This is the most critical algorithmic optimization covered. It addresses the <strong>memory bandwidth bottleneck</strong>. ÂÜÖÂ≠òÂ∏¶ÂÆΩÁì∂È¢à</p>
<ul>
<li><strong>The Problem:</strong> Naive implementation uses three separate kernels:<ol>
<li>Compute <span class="arithmatex">\(S = QK^T\)</span> (writes <span class="arithmatex">\(N \times N\)</span> to global memory).</li>
<li>Compute <span class="arithmatex">\(P = \text{Softmax}(S)\)</span> (reads/writes <span class="arithmatex">\(N \times N\)</span> to global memory).</li>
<li>Compute <span class="arithmatex">\(O = PV\)</span> (reads <span class="arithmatex">\(N \times N\)</span> from global memory).</li>
</ol>
</li>
<li><strong>The Solution:</strong> <strong>Kernel Fusion</strong> ÂÜÖÊ†∏ËûçÂêà: Fuse all three steps into one kernel to avoid writing the massive <span class="arithmatex">\(N \times N\)</span> matrix to global memory.</li>
<li><strong>The Challenge:</strong> You cannot simply tile Softmax because Softmax requires the sum/max of the <em>entire</em> row before you can normalize values.</li>
<li><strong>The Enabler:</strong> <strong>Online Softmax</strong>. This algorithm allows calculating Softmax iteratively by keeping a running max and normalization term. This eliminates the need to compute the global max upfront.</li>
<li><strong>Implementation:</strong> Flash Attention loads tiles of <span class="arithmatex">\(Q, K, V\)</span> into SRAM (Shared Memory). It computes partial results, applies Online Softmax, and accumulates the output without ever writing the full attention matrix to global memory.<ul>
<li><strong>Result:</strong> <span class="arithmatex">\(3x-10x\)</span> speedup by reducing HBM accesses.</li>
</ul>
</li>
</ul>
<h3 id="2-algorithmic-simplification-windowed-attention">2. Algorithmic Simplification: Windowed Attention<a class="headerlink" href="#2-algorithmic-simplification-windowed-attention" title="Permanent link">&para;</a></h3>
<p>Á™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂</p>
<p>If <span class="arithmatex">\(O(T^2)\)</span> is too expensive, we change the algorithm.</p>
<ul>
<li><strong>Method:</strong> Only attend to a fixed window of <strong>nearest neighbors</strong> (e.g., the last <span class="arithmatex">\(W\)</span> tokens)</li>
<li><strong>Complexity:</strong> Drops to <span class="arithmatex">\(O(T \times W)\)</span></li>
<li><strong>Trade-off:</strong> The model loses "long-range context" (e.g., a chatbot forgetting your name mentioned 100 turns ago) </li>
</ul>
<h3 id="3-inference-optimization-kv-cache">3. Inference Optimization: KV Cache<a class="headerlink" href="#3-inference-optimization-kv-cache" title="Permanent link">&para;</a></h3>
<p>Êé®ÁêÜ‰ºòÂåñÔºöKV cache</p>
<p>This is standard practice for "Next Token Generation" (like ChatGPT typing out an answer).
* <strong>The Redundancy:</strong> When generating token #51, the Key (K) and Value (V) vectors for tokens #1 through #50 are exactly the same as they were in the previous step[cite: 651].
* <strong>The Fix:</strong> <strong>KV Cache</strong>. Store the K and V vectors in global memory. Only compute the K and V for the <em>newest</em> token and append it to the cache[cite: 660, 663].
* <strong>Performance Shift:</strong> This reduces work from <span class="arithmatex">\(O(n^2)\)</span> to <span class="arithmatex">\(O(n)\)</span>, but shifts the bottleneck from <strong>Compute</strong> to <strong>Memory Capacity</strong> (storing the cache) Áì∂È¢à‰ªéËÆ°ÁÆóËΩ¨ÁßªÂà∞ÂÜÖÂ≠òÂÆπÈáèÔºàÂ≠òÂÇ®ÁºìÂ≠òÔºâ.</p>
<h3 id="4-memory-management-pagedattention">4. Memory Management: PagedAttention<a class="headerlink" href="#4-memory-management-pagedattention" title="Permanent link">&para;</a></h3>
<p>ÂÜÖÂ≠òÁÆ°ÁêÜÔºöÂàÜÈ°µÊ≥®ÊÑèÂäõ</p>
<p>As the KV Cache grows, it creates memory fragmentation (gaps in memory), similar to how old OS memory management struggled.
* <strong>The Solution:</strong> Inspired by OS <strong>Virtual Memory Paging</strong>. ËôöÊãüÂÜÖÂ≠òÂàÜÈ°µ
* <strong>How it works:</strong> Break the KV cache into fixed-size "pages" (blocks). These pages do not need to be contiguous in physical memory. A "page table" maps the logical token sequence to physical memory blocks.
* <strong>Benefit:</strong> Zero external fragmentation and flexible memory allocation.</p>
<h3 id="5-precision-quantization">5. Precision: Quantization ÈáèÂåñ<a class="headerlink" href="#5-precision-quantization" title="Permanent link">&para;</a></h3>
<p>To fit larger models on GPUs with limited VRAM (e.g., 40GB/80GB), we reduce numerical precision.
* <strong>Technique:</strong> Convert FP32 (32-bit) weights/KV Cache to FP16, INT8, or even FP8[cite: 930, 954].
* <strong>Risk:</strong> "Cheating" precision helps speed and memory but hurts accuracy[cite: 988].
* <strong>Metric:</strong> We measure the impact using <strong>Perplexity Âõ∞ÊÉëÂ∫¶ (PPL)</strong>. A lower PPL score means the model is less "surprised" by the next token (i.e., it is more accurate). PPL ÂÄºË∂ä‰ΩéÔºåÊÑèÂë≥ÁùÄÊ®°ÂûãÂØπ‰∏ã‰∏Ä‰∏™ËØçÂÖÉÁöÑ‚ÄúÊÉäËÆ∂‚ÄùÁ®ãÂ∫¶Ë∂ä‰ΩéÔºàÂç≥ÔºåÂáÜÁ°ÆÁéáË∂äÈ´òÔºâ</p>
<hr />
<h3 id="important-knowledge-points">Important Knowledge Points<a class="headerlink" href="#important-knowledge-points" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Memory IO is the Enemy:</strong> In Attention, moving data between HBM and SRAM is the bottleneck. Optimizations (Flash Attention) focus on IO-awareness, not just FLOPs.</li>
<li><strong>Online Softmax is Key:</strong> You cannot tile Attention without Online Softmax, because standard Softmax requires global row knowledge.</li>
<li><strong>Inference vs. Training:</strong><ul>
<li><strong>Flash Attention</strong> helps both but is famous for training speedups.</li>
<li><strong>KV Cache</strong> is specific to <strong>Inference</strong> (generation) to prevent re-calculating history.</li>
</ul>
</li>
<li><strong>SRAM Constraints:</strong> Flash Attention works because it tiles computations to fit into the small SRAM (Shared Mem), similar to the matrix multiplication tiling you likely implemented in earlier labs.</li>
<li><strong>Perplexity:</strong> The standard metric to validate if your optimizations (like quantization) broke the model.</li>
</ol>
<h2 id="26">26<a class="headerlink" href="#26" title="Permanent link">&para;</a></h2>
<p>Guest lecture by <strong>Vikram Mailthody</strong>, <em>Sr. Research Scientist</em>, NVIDIA; Training and Inference at Scale</p>
<p><img src="./assets/image-20251207162814001.png" alt="image-20251207162814001" style="zoom:50%;" /></p>
<h2 id="cnn-project">CNN Project<a class="headerlink" href="#cnn-project" title="Permanent link">&para;</a></h2>
<p><img src="./assets/image-20251207161001204.png" alt="image-20251207161001204" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207160937281.png" alt="image-20251207160937281" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207161454641.png" alt="image-20251207161454641" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207162023747.png" alt="image-20251207162023747" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207163252548.png" alt="image-20251207163252548" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207163418472.png" alt="image-20251207163418472" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207163534036.png" alt="image-20251207163534036" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207163706728.png" alt="image-20251207163706728" style="zoom:50%;" /></p>
<h2 id="quiz">Quiz<a class="headerlink" href="#quiz" title="Permanent link">&para;</a></h2>
<h3 id="mt1">MT1<a class="headerlink" href="#mt1" title="Permanent link">&para;</a></h3>
<p><img alt="image-20250904152707085" src="assets/image-20250904152707085.png" /></p>
<blockquote>
<p>A is correct
</p>
</blockquote>
<p><img alt="image-20250916180541729" src="assets/image-20250916180541729.png" /></p>
<blockquote>
<p><strong>A</strong></p>
<p>The kernel reads from matrix <code>A</code> and matrix <code>B</code> to compute the output. For each element in the output matrix <code>C</code>, the kernel performs a dot product. This involves reading a full row from <code>A</code> and a full row from <code>B</code> (conceptually, though access patterns might differ).</p>
<ol>
<li><strong>Elements in C:</strong> The output matrix <code>C</code> has <code>numCRows</code> √ó <code>numCColumns</code> elements.<ul>
<li><code>40 * 33 = 1,320</code> elements.</li>
</ul>
</li>
<li><strong>Reads per C element:</strong> To calculate one element of <code>C</code>, a dot product of length <code>numAColumns</code> is performed. This requires reading <code>numAColumns</code> floats from <code>A</code> and <code>numAColumns</code> floats from <code>B</code>.<ul>
<li>Reads per element = <code>31 (from A) + 31 (from B) = 62</code> floats.</li>
</ul>
</li>
<li><strong>Total floats read:</strong><ul>
<li><code>1,320 elements * 62 floats/element = 81,840</code> floats.</li>
</ul>
</li>
<li><strong>Total bytes read:</strong> Since each float is 4 bytes:<ul>
<li><code>81,840 floats * 4 bytes/float = 327,360</code> bytes.</li>
</ul>
</li>
</ol>
</blockquote>
<p><img alt="image-20250916175752303" src="assets/image-20250916175752303.png" /></p>
<blockquote>
<p>The goal is to choose a block size that allows the Streaming Multiprocessor (SM) to simultaneously reach its maximum thread count <strong>and</strong> its maximum block count.</p>
<ol>
<li><strong>Find the Ideal Threads per Block:</strong> To saturate both limits, divide the total number of threads an SM can handle by the total number of blocks it can handle.
   -   1536 total threads/16 total blocks=96 threads per block</li>
<li><strong>Convert Threads to Warps:</strong> A warp in an NVIDIA GPU always consists of 32 threads. Convert the ideal thread count into warps.<ul>
<li>96 threads per block/32 threads per warp = 3 warps per block</li>
</ul>
</li>
</ol>
</blockquote>
<p>Which of the following CUDA kernels could possibly have control divergence?</p>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-83-1">1</a></span>
<span class="normal"><a href="#__codelineno-83-2">2</a></span>
<span class="normal"><a href="#__codelineno-83-3">3</a></span>
<span class="normal"><a href="#__codelineno-83-4">4</a></span>
<span class="normal"><a href="#__codelineno-83-5">5</a></span>
<span class="normal"><a href="#__codelineno-83-6">6</a></span>
<span class="normal"><a href="#__codelineno-83-7">7</a></span>
<span class="normal"><a href="#__codelineno-83-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-83-1"><a id="__codelineno-83-1" name="__codelineno-83-1"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">E</span><span class="p">(</span><span class="kt">int</span><span class="p">[]</span><span class="w"> </span><span class="n">io</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">control</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-83-2"><a id="__codelineno-83-2" name="__codelineno-83-2"></a><span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-83-3"><a id="__codelineno-83-3" name="__codelineno-83-3"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">control</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">control</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
</span><span id="__span-83-4"><a id="__codelineno-83-4" name="__codelineno-83-4"></a><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">control</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-83-5"><a id="__codelineno-83-5" name="__codelineno-83-5"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">io</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">io</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">control</span><span class="p">;</span>
</span><span id="__span-83-6"><a id="__codelineno-83-6" name="__codelineno-83-6"></a><span class="w">  </span><span class="p">}</span>
</span><span id="__span-83-7"><a id="__codelineno-83-7" name="__codelineno-83-7"></a><span class="w">  </span><span class="n">io</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">control</span><span class="p">;</span>
</span><span id="__span-83-8"><a id="__codelineno-83-8" name="__codelineno-83-8"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<blockquote>
<p>The number can't be negative for <code>control * threadIdx.x</code>, so no control divergence.</p>
</blockquote>
<p><img alt="image-20250916180502830" src="assets/image-20250916180502830.png" /></p>
<blockquote>
<p><strong>How many warps will be generated?</strong></p>
<ol>
<li><strong>Calculate Grid Dimensions:</strong><ul>
<li>The image has 176 rows and 174 columns.</li>
<li>Each block has 16 threads in the y-direction (height) and 16 threads in the x-direction (width).</li>
<li>Number of blocks in y-dimension: ceil(176/16)=ceil(11)=11 blocks.</li>
<li>Number of blocks in x-dimension: ceil(174/16)=ceil(10.875)=11 blocks.</li>
<li>This gives a grid of <strong>11x11 = 121 blocks</strong>.</li>
</ul>
</li>
<li><strong>Calculate Threads and Warps:</strong><ul>
<li>Each block has <strong>16x16 = 256 threads</strong>.</li>
<li>A <strong>warp</strong> consists of 32 threads.</li>
<li>Warps per block: 256 threads/32 threads/warp=8 warps.</li>
</ul>
</li>
<li><strong>Calculate Total Warps:</strong><ul>
<li>Total Warps = (Total Blocks) √ó (Warps per Block)</li>
<li>Total Warps = 121√ó8=968.</li>
</ul>
</li>
</ol>
<p><strong>Answer: <code>968</code></strong></p>
<p><strong>How many warps will have control divergence?</strong></p>
<p>The answer is 168 because control divergence in this kernel originates from <strong>two distinct sources</strong>, and your original calculation of 88 only accounted for one of them. <mark>warp‰∏≠Êó¢Êúârow &gt; colÂèàÊúârow‚â§colÁöÑ‰ºö‰∫ßÁîücontrol divergence</mark> </p>
<ol>
<li>The explicit <code>if (row &gt; col)</code> check.</li>
<li>The implicit boundary check <code>if (... &amp;&amp; (col &lt; numCols))</code>.</li>
</ol>
<p><strong>The <code>if (row &gt; col)</code> Condition</strong></p>
<p>This is the most obvious source of divergence. A warp will diverge if some of its threads satisfy <code>row &gt; col</code> while others don't. This happens in thread blocks that lie on the main diagonal of the image.</p>
<ul>
<li>The grid of blocks is 11x11.</li>
<li>The blocks on the diagonal are those where <code>blockIdx.x == blockIdx.y</code>. There are <strong>11</strong> such blocks (from <code>(0,0)</code> to <code>(10,10)</code>).</li>
<li>Inside these blocks, every single one of the 8 warps will contain a mix of threads that are above and below the local diagonal (<code>threadIdx.y &gt; threadIdx.x</code>), causing them all to diverge.</li>
<li><strong>Divergent Warps from this source:</strong> 11 blocks√ó8 warps/block=88 warps.</li>
</ul>
<p><strong>The Outer Boundary Check</strong></p>
<p>This is the subtle part you missed. The kernel launches a grid of threads that is slightly larger than the image itself.</p>
<ul>
<li><strong>Grid Width:</strong> The grid has 11 blocks of 16 threads each, for a total width of 11√ó16=176 threads.</li>
<li><strong>Image Width:</strong> The image's <code>numCols</code> is only <strong>174</strong>.</li>
</ul>
<p>Because of this mismatch, the outer <code>if</code> statement <code>if ((row &lt; numRows) &amp;&amp; (col &lt; numCols))</code> will cause divergence for threads in the <strong>last column of blocks</strong> (where <code>blockIdx.x = 10</code>).</p>
<ul>
<li>In these blocks, threads with a global column index <code>col &lt; 174</code> will pass the check, while threads with <code>col &gt;= 174</code> will fail it.</li>
<li>This boundary occurs within the warps of these blocks, causing all warps in that last column to diverge.</li>
<li>There are <strong>11 blocks</strong> in this last column (<code>blockIdx.x = 10</code>, while <code>blockIdx.y</code> ranges from 0 to 10).</li>
<li><strong>Divergent Warps from this source:</strong> 11 blocks√ó8 warps/block=88 warps.</li>
</ul>
<p>To get the total number of divergent warps, we add the warps from both sources and subtract the overlap (since the block at <code>(10,10)</code> is in both sets).</p>
<ul>
<li><strong>Total = (Diagonal Warps ÂØπËßíÁ∫ø) + (Boundary Warps Âè≥ËæπÂ§öÂá∫Êù•ÁöÑ) - (Overlap Warps)</strong></li>
<li>The overlap is the single block <code>(10,10)</code>, which contains 8 warps.</li>
<li>Total = 88+88‚àí8=168</li>
</ul>
<p>So, there are 80 unique warps on the diagonal, 80 unique warps on the boundary, and 8 warps that are on both, leading to the final correct answer.</p>
</blockquote>
<p><img alt="image-20250916180656441" src="assets/image-20250916180656441.png" /></p>
<blockquote>
<p>Control divergence is not "wait for the longest path"; it's even worse. It's basically going through all the paths sequentially. Suppose you have Path A and Path B that take 10ms/2ms to execute. Control divergence is basically saying you need to <strong>sequentially execute</strong> both path and the total execution time is 10+2=12ms. It has nothing to do with which path is longer since they're not parallel anymore.</p>
<p>'All threads must wait until the longest path is completed. '</p>
<p>This description usually fits <em>barrier synchronization</em> (we will talk about this concept soon), where multiple threads are running concurrently/in parallel and they synchronize at some point in the future. The threads that arrive first will wait for other threads. All threads won't continue until all threads have reached this synchronization point.</p>
</blockquote>
<p><img alt="image-20250916212024053" src="assets/image-20250916212024053.png" /></p>
<blockquote>
<p><strong>A: Operations by Threads for C Elements</strong></p>
<p>This question asks for the number of floating-point operations (flops) required to calculate the final <code>C</code> matrix, ignoring any work done by threads outside the matrix's bounds.</p>
<ol>
<li><strong>Flops per Element:</strong> To calculate a single element of the output matrix <code>C</code>, a dot product is performed. This involves iterating <code>numAColumns</code> (or <code>141</code>) times. Each iteration performs <strong>one multiplication</strong> and <strong>one addition</strong>.<ul>
<li>Operations per element = 141√ó2=282 flops.</li>
</ul>
</li>
<li><strong>Total Elements in C:</strong> The output matrix <code>C</code> has <code>numCRows</code> x <code>numCColumns</code> elements.<ul>
<li>Total elements = 100√ó92=9,200 elements.</li>
</ul>
</li>
<li><strong>Total Operations:</strong><ul>
<li>Total flops = (Total elements) √ó (Operations per element)</li>
<li>Total flops = 9,200√ó282=2,594,400.</li>
</ul>
</li>
</ol>
<p><strong>A: <code>2594400</code></strong></p>
<hr />
<p><strong>B: Operations by All Launched Threads</strong></p>
<ol>
<li>
<p>Determine the Grid and Block Configuration</p>
<p>First, we determine how many threads are launched in total. This is based on covering the output matrix <code>C</code> (100x92) with 32x32 tiles, where each tile corresponds to a thread block.</p>
<ul>
<li><strong>Grid Height:</strong> ceil(numCRows/32)=ceil(100/32)=4 blocks</li>
<li><strong>Grid Width:</strong> ceil(numCColumns/32)=ceil(92/32)=3 blocks</li>
<li><strong>Total Blocks:</strong> 4√ó3=12 blocks</li>
<li><strong>Threads per Block:</strong> 32√ó32=1,024 threads</li>
</ul>
</li>
<li>
<p>Determine the Number of Tile Iterations</p>
<p>For each thread block to compute its 32x32 output tile, it must loop over the tiles of the input matrices (<code>A</code> and <code>B</code>) along their common dimension, which is <code>numAColumns = 141</code>.</p>
<ul>
<li><strong>Tile Loop Iterations:</strong> ceil(numAColumns/32)=ceil(141/32)=5 iterations.</li>
</ul>
</li>
<li>
<p>Determine Operations per Iteration</p>
<p>In each of the 5 iterations, every thread in the block performs a series of multiplications and additions using the 32x32 tiles loaded into shared memory. Each thread performs <strong>32 multiplications</strong> and <strong>32 additions</strong> to contribute to its final output value.</p>
<ul>
<li><strong>Flops per Thread per Iteration:</strong> 32 multiplications+32 additions=64 floating-point operations.</li>
</ul>
</li>
<li>
<p>Calculate Total Floating-Point Operations</p>
<p>Finally, we combine these numbers to find the total work done by all threads across all loop iterations.</p>
<ul>
<li><strong>Total Flops = (Total Blocks) √ó (Threads per Block) √ó (Tile Iterations) √ó (Flops per Iteration)</strong></li>
<li>Total Flops = 12√ó1,024√ó5√ó64  = 12,288√ó320 = <strong>3,932,160</strong></li>
</ul>
</li>
</ol>
<p>B: <code>3932160</code></p>
</blockquote>
<p><img alt="image-20250916211845709" src="assets/image-20250916211845709.png" /></p>
<blockquote>
<p>Standard way: in the tiled multiplication, the number of blocks that will read a given element <code>A[i][k]</code> is equal to the number of blocks in the x-direction of the grid (which is <code>ceil(numCColumns/tile_width)</code>) because for fixed row i, it is used in all columns j of C.</p>
<p>Similarly, an element <code>B[k][j]</code> is read by all blocks in the y-direction of the grid <code>ceil(numCRows/tile_height)</code>.</p>
<p>So:</p>
<ul>
<li>Each element of A is read by (number of blocks in x-direction) = ceil(69/16)=5 times.</li>
<li>Each element of B is read by (number of blocks in y-direction) = ceil(80/16)=5 times.</li>
</ul>
<p>Therefore:</p>
<p>Total elements read from A = (number of elements in A) * (number of blocks in x-dir) = (80<em>41) * 5 = 3280 * 5 = 16400.
  Total elements read from B = (number of elements in B) * (number of blocks in y-dir) = (41</em>69) * 5 = 2829 * 5 = 14145.</p>
<p>So total elements read = 16400 + 14145 = 30545.
  Then total bytes read = 30545 * 4 bytes = <strong>122180</strong> bytes.</p>
</blockquote>
<p><img alt="image-20250930140436726" src="assets/image-20250930140436726.png" /></p>
<blockquote>
<p>If <code>MASK_WIDTH=3</code>, then you basically have 2 halo cells per block. In strategy 3, each of them are only read once. So basically it means that strategy 3 has the same number of global memory reads as strategy 1 and 2.</p>
<p>An increased number of global memory accesses is the primary reason why we don't want strategy 3 and want to reuse data. And now this downside is invalid for <code>MASK_WIDTH = 3</code>. </p>
<p>Strategy 3 now enjoys 1G for each halo:</p>
<ol>
<li>Smaller shared memory &amp; less number of threads per block =&gt; more blocks in an SM.</li>
<li>No redundant read from shared memory (halo cells are directly read from global memory)</li>
</ol>
<p>But Strategy 2 is 1G+1S for each halo</p>
</blockquote>
<p><img alt="image-20250930140551040" src="assets/image-20250930140551040.png" /></p>
<blockquote>
<ol>
<li>
<p>Block width = 16+9-1=24, then 24^2 threads per block</p>
<p>2048/24^2=3.556 </p>
<p><strong>3</strong> block/SM</p>
</li>
<li>
<p>3 block/SM * 24^2 threads/block * 4 bytes/float = 6912</p>
<p><strong>6912</strong> bytes</p>
</li>
<li>
<p>Average uses per value (internal tile):
        Total uses = outputs √ó mask_area = 16√ó16 √ó 9√ó9 = 256 √ó 81 = 20736.
        Values loaded = 24√ó24 = 576.
        Average = 20736 / 576 = <strong>36.00</strong> (4 significant figures).</p>
</li>
<li>Now each thread loads 4 values (so loaded values per block = 576√ó4 = 2304).
        With the same mask, choose the input tile such that loaded values = 2304 ‚áí input side = ‚àö2304 = 48.
        Outputs = (input side ‚àí (mask‚àí1))^2 = (48 ‚àí 8)^2 = 40√ó40 = 1600 outputs.
        Total uses = 1600 √ó 81 = 129600. Average per loaded value = 129600 / 2304 = <strong>56.25</strong> (4 s.f.).</li>
</ol>
</blockquote>
<p><img alt="image-20250930150135653" src="assets/image-20250930150135653.png" /></p>
<p><img src="./assets/image-20250930150209775.png" alt="image-20250930150209775" style="zoom:25%;" /></p>
<p><img alt="image-20250930150232023" src="assets/image-20250930150232023.png" /></p>
<blockquote>
<p>Strategy 2, no load control divergence but 22 in the calculation</p>
</blockquote>
<hr />
<h3 id="mt2">MT2<a class="headerlink" href="#mt2" title="Permanent link">&para;</a></h3>
<p><img src="./assets/image-20251205164851723.png" alt="image-20251205164851723" style="zoom: 33%;" /></p>
<blockquote>
<p>C is correct. Operator has to be associative and commutative</p>
</blockquote>
<p><img alt="image-20251205234106733" src="assets/image-20251205234106733.png" /></p>
<p><img src="./assets/image-20251206230323583.png" alt="image-20251206230323583" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207144852878.png" alt="image-20251207144852878" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207144911854.png" alt="image-20251207144911854" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207150525457.png" alt="image-20251207150525457" style="zoom:50%;" /></p>
<p><img src="./assets/image-20251207150630623.png" alt="image-20251207150630623" style="zoom: 33%;" /></p>
<p><img src="./assets/image-20251207153209829.png" alt="image-20251207153209829" style="zoom: 50%;" /></p>
<p><img src="./assets/image-20251207153256576.png" alt="image-20251207153256576" style="zoom:33%;" /></p>
<h2 id="midterm">Midterm<a class="headerlink" href="#midterm" title="Permanent link">&para;</a></h2>
<h3 id="cuda-code-for-2d-convolution-tiled-matrix-operation">Cuda code for 2D convolution tiled matrix operation<a class="headerlink" href="#cuda-code-for-2d-convolution-tiled-matrix-operation" title="Permanent link">&para;</a></h3>
<p>A kernel computes <code>output = A * B + C</code> using a tiled approach with shared memory.</p>
<h4 id="host-code">Host code<a class="headerlink" href="#host-code" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-84-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-84-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-84-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-84-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-84-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-84-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-84-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-84-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-84-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-84-10">10</a></span>
<span class="normal"><a href="#__codelineno-84-11">11</a></span>
<span class="normal"><a href="#__codelineno-84-12">12</a></span>
<span class="normal"><a href="#__codelineno-84-13">13</a></span>
<span class="normal"><a href="#__codelineno-84-14">14</a></span>
<span class="normal"><a href="#__codelineno-84-15">15</a></span>
<span class="normal"><a href="#__codelineno-84-16">16</a></span>
<span class="normal"><a href="#__codelineno-84-17">17</a></span>
<span class="normal"><a href="#__codelineno-84-18">18</a></span>
<span class="normal"><a href="#__codelineno-84-19">19</a></span>
<span class="normal"><a href="#__codelineno-84-20">20</a></span>
<span class="normal"><a href="#__codelineno-84-21">21</a></span>
<span class="normal"><a href="#__codelineno-84-22">22</a></span>
<span class="normal"><a href="#__codelineno-84-23">23</a></span>
<span class="normal"><a href="#__codelineno-84-24">24</a></span>
<span class="normal"><a href="#__codelineno-84-25">25</a></span>
<span class="normal"><a href="#__codelineno-84-26">26</a></span>
<span class="normal"><a href="#__codelineno-84-27">27</a></span>
<span class="normal"><a href="#__codelineno-84-28">28</a></span>
<span class="normal"><a href="#__codelineno-84-29">29</a></span>
<span class="normal"><a href="#__codelineno-84-30">30</a></span>
<span class="normal"><a href="#__codelineno-84-31">31</a></span>
<span class="normal"><a href="#__codelineno-84-32">32</a></span>
<span class="normal"><a href="#__codelineno-84-33">33</a></span>
<span class="normal"><a href="#__codelineno-84-34">34</a></span>
<span class="normal"><a href="#__codelineno-84-35">35</a></span>
<span class="normal"><a href="#__codelineno-84-36">36</a></span>
<span class="normal"><a href="#__codelineno-84-37">37</a></span>
<span class="normal"><a href="#__codelineno-84-38">38</a></span>
<span class="normal"><a href="#__codelineno-84-39">39</a></span>
<span class="normal"><a href="#__codelineno-84-40">40</a></span>
<span class="normal"><a href="#__codelineno-84-41">41</a></span>
<span class="normal"><a href="#__codelineno-84-42">42</a></span>
<span class="normal"><a href="#__codelineno-84-43">43</a></span>
<span class="normal"><a href="#__codelineno-84-44">44</a></span>
<span class="normal"><a href="#__codelineno-84-45">45</a></span>
<span class="normal"><a href="#__codelineno-84-46">46</a></span>
<span class="normal"><a href="#__codelineno-84-47">47</a></span>
<span class="normal"><a href="#__codelineno-84-48">48</a></span>
<span class="normal"><a href="#__codelineno-84-49">49</a></span>
<span class="normal"><a href="#__codelineno-84-50">50</a></span>
<span class="normal"><a href="#__codelineno-84-51">51</a></span>
<span class="normal"><a href="#__codelineno-84-52">52</a></span>
<span class="normal"><a href="#__codelineno-84-53">53</a></span>
<span class="normal"><a href="#__codelineno-84-54">54</a></span>
<span class="normal"><a href="#__codelineno-84-55">55</a></span>
<span class="normal"><a href="#__codelineno-84-56">56</a></span>
<span class="normal"><a href="#__codelineno-84-57">57</a></span>
<span class="normal"><a href="#__codelineno-84-58">58</a></span>
<span class="normal"><a href="#__codelineno-84-59">59</a></span>
<span class="normal"><a href="#__codelineno-84-60">60</a></span>
<span class="normal"><a href="#__codelineno-84-61">61</a></span>
<span class="normal"><a href="#__codelineno-84-62">62</a></span>
<span class="normal"><a href="#__codelineno-84-63">63</a></span>
<span class="normal"><a href="#__codelineno-84-64">64</a></span>
<span class="normal"><a href="#__codelineno-84-65">65</a></span>
<span class="normal"><a href="#__codelineno-84-66">66</a></span>
<span class="normal"><a href="#__codelineno-84-67">67</a></span>
<span class="normal"><a href="#__codelineno-84-68">68</a></span>
<span class="normal"><a href="#__codelineno-84-69">69</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-84-1"><a id="__codelineno-84-1" name="__codelineno-84-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
</span><span id="__span-84-2"><a id="__codelineno-84-2" name="__codelineno-84-2"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
</span><span id="__span-84-3"><a id="__codelineno-84-3" name="__codelineno-84-3"></a>
</span><span id="__span-84-4"><a id="__codelineno-84-4" name="__codelineno-84-4"></a><span class="c1">// Tile width for shared memory implementation</span>
</span><span id="__span-84-5"><a id="__codelineno-84-5" name="__codelineno-84-5"></a><span class="cp">#define TILE_WIDTH 32</span>
</span><span id="__span-84-6"><a id="__codelineno-84-6" name="__codelineno-84-6"></a>
</span><span id="__span-84-7"><a id="__codelineno-84-7" name="__codelineno-84-7"></a><span class="c1">// Forward declaration of a helper function to initialize matrices</span>
</span><span id="__span-84-8"><a id="__codelineno-84-8" name="__codelineno-84-8"></a><span class="kt">void</span><span class="w"> </span><span class="nf">getData</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</span><span id="__span-84-9"><a id="__codelineno-84-9" name="__codelineno-84-9"></a>
</span><span id="__span-84-10"><a id="__codelineno-84-10" name="__codelineno-84-10"></a><span class="c1">// The provided host code starts here</span>
</span><span id="__span-84-11"><a id="__codelineno-84-11" name="__codelineno-84-11"></a><span class="cp">#define n 128 </span><span class="c1">// as an example</span>
</span><span id="__span-84-12"><a id="__codelineno-84-12" name="__codelineno-84-12"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-84-13"><a id="__codelineno-84-13" name="__codelineno-84-13"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="p">;</span>
</span><span id="__span-84-14"><a id="__codelineno-84-14" name="__codelineno-84-14"></a><span class="w">    </span><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</span><span id="__span-84-15"><a id="__codelineno-84-15" name="__codelineno-84-15"></a><span class="w">    </span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</span><span id="__span-84-16"><a id="__codelineno-84-16" name="__codelineno-84-16"></a><span class="w">    </span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</span><span id="__span-84-17"><a id="__codelineno-84-17" name="__codelineno-84-17"></a><span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
</span><span id="__span-84-18"><a id="__codelineno-84-18" name="__codelineno-84-18"></a><span class="w">    </span><span class="n">getData</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="c1">// this function fills in data for matrices A, B, and C</span>
</span><span id="__span-84-19"><a id="__codelineno-84-19" name="__codelineno-84-19"></a>
</span><span id="__span-84-20"><a id="__codelineno-84-20" name="__codelineno-84-20"></a><span class="w">    </span><span class="c1">// 1. Declare and allocate GPU memory</span>
</span><span id="__span-84-21"><a id="__codelineno-84-21" name="__codelineno-84-21"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_output</span><span class="p">;</span>
</span><span id="__span-84-22"><a id="__codelineno-84-22" name="__codelineno-84-22"></a><span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">matrix_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
</span><span id="__span-84-23"><a id="__codelineno-84-23" name="__codelineno-84-23"></a>
</span><span id="__span-84-24"><a id="__codelineno-84-24" name="__codelineno-84-24"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">);</span>
</span><span id="__span-84-25"><a id="__codelineno-84-25" name="__codelineno-84-25"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">);</span>
</span><span id="__span-84-26"><a id="__codelineno-84-26" name="__codelineno-84-26"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">);</span>
</span><span id="__span-84-27"><a id="__codelineno-84-27" name="__codelineno-84-27"></a><span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_output</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">);</span>
</span><span id="__span-84-28"><a id="__codelineno-84-28" name="__codelineno-84-28"></a>
</span><span id="__span-84-29"><a id="__codelineno-84-29" name="__codelineno-84-29"></a><span class="w">    </span><span class="c1">// 2. Copy input matrices from host to device</span>
</span><span id="__span-84-30"><a id="__codelineno-84-30" name="__codelineno-84-30"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-84-31"><a id="__codelineno-84-31" name="__codelineno-84-31"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-84-32"><a id="__codelineno-84-32" name="__codelineno-84-32"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span><span id="__span-84-33"><a id="__codelineno-84-33" name="__codelineno-84-33"></a>
</span><span id="__span-84-34"><a id="__codelineno-84-34" name="__codelineno-84-34"></a><span class="w">    </span><span class="c1">// 3. Configure kernel launch parameters</span>
</span><span id="__span-84-35"><a id="__codelineno-84-35" name="__codelineno-84-35"></a><span class="w">    </span><span class="c1">// Block dimensions are fixed as required</span>
</span><span id="__span-84-36"><a id="__codelineno-84-36" name="__codelineno-84-36"></a><span class="w">    </span><span class="n">dim3</span><span class="w"> </span><span class="n">dimBlock</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-84-37"><a id="__codelineno-84-37" name="__codelineno-84-37"></a>
</span><span id="__span-84-38"><a id="__codelineno-84-38" name="__codelineno-84-38"></a><span class="w">    </span><span class="c1">// Grid dimensions are calculated to cover the entire output matrix with tiles</span>
</span><span id="__span-84-39"><a id="__codelineno-84-39" name="__codelineno-84-39"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">grid_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">;</span>
</span><span id="__span-84-40"><a id="__codelineno-84-40" name="__codelineno-84-40"></a><span class="w">    </span><span class="n">dim3</span><span class="w"> </span><span class="n">dimGrid</span><span class="p">(</span><span class="n">grid_dim</span><span class="p">,</span><span class="w"> </span><span class="n">grid_dim</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-84-41"><a id="__codelineno-84-41" name="__codelineno-84-41"></a>
</span><span id="__span-84-42"><a id="__codelineno-84-42" name="__codelineno-84-42"></a><span class="w">    </span><span class="c1">// 4. Launch the kernel on the device</span>
</span><span id="__span-84-43"><a id="__codelineno-84-43" name="__codelineno-84-43"></a><span class="w">    </span><span class="n">MAC</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="w"> </span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">d_output</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</span><span id="__span-84-44"><a id="__codelineno-84-44" name="__codelineno-84-44"></a>
</span><span id="__span-84-45"><a id="__codelineno-84-45" name="__codelineno-84-45"></a><span class="w">    </span><span class="c1">// 5. Copy the result matrix from device back to host</span>
</span><span id="__span-84-46"><a id="__codelineno-84-46" name="__codelineno-84-46"></a><span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">d_output</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
</span><span id="__span-84-47"><a id="__codelineno-84-47" name="__codelineno-84-47"></a>
</span><span id="__span-84-48"><a id="__codelineno-84-48" name="__codelineno-84-48"></a><span class="w">    </span><span class="c1">// 6. Free all allocated memory</span>
</span><span id="__span-84-49"><a id="__codelineno-84-49" name="__codelineno-84-49"></a><span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_A</span><span class="p">);</span>
</span><span id="__span-84-50"><a id="__codelineno-84-50" name="__codelineno-84-50"></a><span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_B</span><span class="p">);</span>
</span><span id="__span-84-51"><a id="__codelineno-84-51" name="__codelineno-84-51"></a><span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_C</span><span class="p">);</span>
</span><span id="__span-84-52"><a id="__codelineno-84-52" name="__codelineno-84-52"></a><span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_output</span><span class="p">);</span>
</span><span id="__span-84-53"><a id="__codelineno-84-53" name="__codelineno-84-53"></a>
</span><span id="__span-84-54"><a id="__codelineno-84-54" name="__codelineno-84-54"></a><span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>
</span><span id="__span-84-55"><a id="__codelineno-84-55" name="__codelineno-84-55"></a><span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">B</span><span class="p">);</span>
</span><span id="__span-84-56"><a id="__codelineno-84-56" name="__codelineno-84-56"></a><span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">C</span><span class="p">);</span>
</span><span id="__span-84-57"><a id="__codelineno-84-57" name="__codelineno-84-57"></a><span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">output</span><span class="p">);</span>
</span><span id="__span-84-58"><a id="__codelineno-84-58" name="__codelineno-84-58"></a>
</span><span id="__span-84-59"><a id="__codelineno-84-59" name="__codelineno-84-59"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-84-60"><a id="__codelineno-84-60" name="__codelineno-84-60"></a><span class="p">}</span>
</span><span id="__span-84-61"><a id="__codelineno-84-61" name="__codelineno-84-61"></a>
</span><span id="__span-84-62"><a id="__codelineno-84-62" name="__codelineno-84-62"></a><span class="c1">// Dummy implementation for getData to make the code runnable</span>
</span><span id="__span-84-63"><a id="__codelineno-84-63" name="__codelineno-84-63"></a><span class="kt">void</span><span class="w"> </span><span class="nf">getData</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-84-64"><a id="__codelineno-84-64" name="__codelineno-84-64"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-84-65"><a id="__codelineno-84-65" name="__codelineno-84-65"></a><span class="w">        </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">;</span>
</span><span id="__span-84-66"><a id="__codelineno-84-66" name="__codelineno-84-66"></a><span class="w">        </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">;</span>
</span><span id="__span-84-67"><a id="__codelineno-84-67" name="__codelineno-84-67"></a><span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5f</span><span class="p">;</span>
</span><span id="__span-84-68"><a id="__codelineno-84-68" name="__codelineno-84-68"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-84-69"><a id="__codelineno-84-69" name="__codelineno-84-69"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="cuda-kernel-code">Cuda kernel code<a class="headerlink" href="#cuda-kernel-code" title="Permanent link">&para;</a></h4>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-85-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-85-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-85-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-85-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-85-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-85-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-85-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-85-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-85-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-85-10">10</a></span>
<span class="normal"><a href="#__codelineno-85-11">11</a></span>
<span class="normal"><a href="#__codelineno-85-12">12</a></span>
<span class="normal"><a href="#__codelineno-85-13">13</a></span>
<span class="normal"><a href="#__codelineno-85-14">14</a></span>
<span class="normal"><a href="#__codelineno-85-15">15</a></span>
<span class="normal"><a href="#__codelineno-85-16">16</a></span>
<span class="normal"><a href="#__codelineno-85-17">17</a></span>
<span class="normal"><a href="#__codelineno-85-18">18</a></span>
<span class="normal"><a href="#__codelineno-85-19">19</a></span>
<span class="normal"><a href="#__codelineno-85-20">20</a></span>
<span class="normal"><a href="#__codelineno-85-21">21</a></span>
<span class="normal"><a href="#__codelineno-85-22">22</a></span>
<span class="normal"><a href="#__codelineno-85-23">23</a></span>
<span class="normal"><a href="#__codelineno-85-24">24</a></span>
<span class="normal"><a href="#__codelineno-85-25">25</a></span>
<span class="normal"><a href="#__codelineno-85-26">26</a></span>
<span class="normal"><a href="#__codelineno-85-27">27</a></span>
<span class="normal"><a href="#__codelineno-85-28">28</a></span>
<span class="normal"><a href="#__codelineno-85-29">29</a></span>
<span class="normal"><a href="#__codelineno-85-30">30</a></span>
<span class="normal"><a href="#__codelineno-85-31">31</a></span>
<span class="normal"><a href="#__codelineno-85-32">32</a></span>
<span class="normal"><a href="#__codelineno-85-33">33</a></span>
<span class="normal"><a href="#__codelineno-85-34">34</a></span>
<span class="normal"><a href="#__codelineno-85-35">35</a></span>
<span class="normal"><a href="#__codelineno-85-36">36</a></span>
<span class="normal"><a href="#__codelineno-85-37">37</a></span>
<span class="normal"><a href="#__codelineno-85-38">38</a></span>
<span class="normal"><a href="#__codelineno-85-39">39</a></span>
<span class="normal"><a href="#__codelineno-85-40">40</a></span>
<span class="normal"><a href="#__codelineno-85-41">41</a></span>
<span class="normal"><a href="#__codelineno-85-42">42</a></span>
<span class="normal"><a href="#__codelineno-85-43">43</a></span>
<span class="normal"><a href="#__codelineno-85-44">44</a></span>
<span class="normal"><a href="#__codelineno-85-45">45</a></span>
<span class="normal"><a href="#__codelineno-85-46">46</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-85-1"><a id="__codelineno-85-1" name="__codelineno-85-1"></a><span class="cp">#define TILE_WIDTH 32</span>
</span><span id="__span-85-2"><a id="__codelineno-85-2" name="__codelineno-85-2"></a>
</span><span id="__span-85-3"><a id="__codelineno-85-3" name="__codelineno-85-3"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">MAC</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span>
</span><span id="__span-85-4"><a id="__codelineno-85-4" name="__codelineno-85-4"></a><span class="p">{</span>
</span><span id="__span-85-5"><a id="__codelineno-85-5" name="__codelineno-85-5"></a><span class="w">    </span><span class="c1">// Shared memory to store tiles from A and B</span>
</span><span id="__span-85-6"><a id="__codelineno-85-6" name="__codelineno-85-6"></a><span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>
</span><span id="__span-85-7"><a id="__codelineno-85-7" name="__codelineno-85-7"></a><span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">B_s</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>
</span><span id="__span-85-8"><a id="__codelineno-85-8" name="__codelineno-85-8"></a>
</span><span id="__span-85-9"><a id="__codelineno-85-9" name="__codelineno-85-9"></a><span class="w">    </span><span class="c1">// Thread indices within the block (tx: 0-31, ty: 0-31)</span>
</span><span id="__span-85-10"><a id="__codelineno-85-10" name="__codelineno-85-10"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span id="__span-85-11"><a id="__codelineno-85-11" name="__codelineno-85-11"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span><span id="__span-85-12"><a id="__codelineno-85-12" name="__codelineno-85-12"></a>
</span><span id="__span-85-13"><a id="__codelineno-85-13" name="__codelineno-85-13"></a><span class="w">    </span><span class="c1">// Calculate the global row and column for the single output element this thread computes</span>
</span><span id="__span-85-14"><a id="__codelineno-85-14" name="__codelineno-85-14"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ty</span><span class="p">;</span>
</span><span id="__span-85-15"><a id="__codelineno-85-15" name="__codelineno-85-15"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tx</span><span class="p">;</span>
</span><span id="__span-85-16"><a id="__codelineno-85-16" name="__codelineno-85-16"></a>
</span><span id="__span-85-17"><a id="__codelineno-85-17" name="__codelineno-85-17"></a><span class="w">    </span><span class="c1">// Accumulator register for the single output element</span>
</span><span id="__span-85-18"><a id="__codelineno-85-18" name="__codelineno-85-18"></a><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-85-19"><a id="__codelineno-85-19" name="__codelineno-85-19"></a>
</span><span id="__span-85-20"><a id="__codelineno-85-20" name="__codelineno-85-20"></a><span class="w">    </span><span class="c1">// Loop over all tiles needed to compute the dot product</span>
</span><span id="__span-85-21"><a id="__codelineno-85-21" name="__codelineno-85-21"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-85-22"><a id="__codelineno-85-22" name="__codelineno-85-22"></a><span class="w">        </span><span class="c1">// Load one element from global matrix A into shared memory A_s</span>
</span><span id="__span-85-23"><a id="__codelineno-85-23" name="__codelineno-85-23"></a><span class="w">        </span><span class="n">A_s</span><span class="p">[</span><span class="n">ty</span><span class="p">][</span><span class="n">tx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tx</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tx</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-85-24"><a id="__codelineno-85-24" name="__codelineno-85-24"></a>
</span><span id="__span-85-25"><a id="__codelineno-85-25" name="__codelineno-85-25"></a><span class="w">        </span><span class="c1">// Load one element from global matrix B into shared memory B_s</span>
</span><span id="__span-85-26"><a id="__codelineno-85-26" name="__codelineno-85-26"></a><span class="w">        </span><span class="n">B_s</span><span class="p">[</span><span class="n">ty</span><span class="p">][</span><span class="n">tx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ty</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">B</span><span class="p">[(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ty</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-85-27"><a id="__codelineno-85-27" name="__codelineno-85-27"></a>
</span><span id="__span-85-28"><a id="__codelineno-85-28" name="__codelineno-85-28"></a><span class="w">        </span><span class="c1">// Synchronize to ensure all data is loaded into shared memory before proceeding</span>
</span><span id="__span-85-29"><a id="__codelineno-85-29" name="__codelineno-85-29"></a><span class="w">        </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-85-30"><a id="__codelineno-85-30" name="__codelineno-85-30"></a>
</span><span id="__span-85-31"><a id="__codelineno-85-31" name="__codelineno-85-31"></a><span class="w">        </span><span class="c1">// Perform matrix multiplication for the current tiles from shared memory</span>
</span><span id="__span-85-32"><a id="__codelineno-85-32" name="__codelineno-85-32"></a><span class="w">        </span><span class="c1">// Each thread calculates one partial dot product</span>
</span><span id="__span-85-33"><a id="__codelineno-85-33" name="__codelineno-85-33"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_WIDTH</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-85-34"><a id="__codelineno-85-34" name="__codelineno-85-34"></a><span class="w">            </span><span class="n">acc</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A_s</span><span class="p">[</span><span class="n">ty</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B_s</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">tx</span><span class="p">];</span>
</span><span id="__span-85-35"><a id="__codelineno-85-35" name="__codelineno-85-35"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-85-36"><a id="__codelineno-85-36" name="__codelineno-85-36"></a>
</span><span id="__span-85-37"><a id="__codelineno-85-37" name="__codelineno-85-37"></a><span class="w">        </span><span class="c1">// Synchronize to ensure all calculations are done before loading the next tile</span>
</span><span id="__span-85-38"><a id="__codelineno-85-38" name="__codelineno-85-38"></a><span class="w">        </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-85-39"><a id="__codelineno-85-39" name="__codelineno-85-39"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-85-40"><a id="__codelineno-85-40" name="__codelineno-85-40"></a>
</span><span id="__span-85-41"><a id="__codelineno-85-41" name="__codelineno-85-41"></a><span class="w">    </span><span class="c1">// After the loops, add the element from C and write the final result</span>
</span><span id="__span-85-42"><a id="__codelineno-85-42" name="__codelineno-85-42"></a><span class="w">    </span><span class="c1">// to the output matrix, guarded by a boundary check.</span>
</span><span id="__span-85-43"><a id="__codelineno-85-43" name="__codelineno-85-43"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-85-44"><a id="__codelineno-85-44" name="__codelineno-85-44"></a><span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span>
</span><span id="__span-85-45"><a id="__codelineno-85-45" name="__codelineno-85-45"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-85-46"><a id="__codelineno-85-46" name="__codelineno-85-46"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="3d-tiled-matrix-operation-convolution">3D tiled matrix operation Convolution<a class="headerlink" href="#3d-tiled-matrix-operation-convolution" title="Permanent link">&para;</a></h3>
<div class="language-c highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-86-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-86-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-86-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-86-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-86-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-86-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-86-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-86-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-86-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-86-10">10</a></span>
<span class="normal"><a href="#__codelineno-86-11">11</a></span>
<span class="normal"><a href="#__codelineno-86-12">12</a></span>
<span class="normal"><a href="#__codelineno-86-13">13</a></span>
<span class="normal"><a href="#__codelineno-86-14">14</a></span>
<span class="normal"><a href="#__codelineno-86-15">15</a></span>
<span class="normal"><a href="#__codelineno-86-16">16</a></span>
<span class="normal"><a href="#__codelineno-86-17">17</a></span>
<span class="normal"><a href="#__codelineno-86-18">18</a></span>
<span class="normal"><a href="#__codelineno-86-19">19</a></span>
<span class="normal"><a href="#__codelineno-86-20">20</a></span>
<span class="normal"><a href="#__codelineno-86-21">21</a></span>
<span class="normal"><a href="#__codelineno-86-22">22</a></span>
<span class="normal"><a href="#__codelineno-86-23">23</a></span>
<span class="normal"><a href="#__codelineno-86-24">24</a></span>
<span class="normal"><a href="#__codelineno-86-25">25</a></span>
<span class="normal"><a href="#__codelineno-86-26">26</a></span>
<span class="normal"><a href="#__codelineno-86-27">27</a></span>
<span class="normal"><a href="#__codelineno-86-28">28</a></span>
<span class="normal"><a href="#__codelineno-86-29">29</a></span>
<span class="normal"><a href="#__codelineno-86-30">30</a></span>
<span class="normal"><a href="#__codelineno-86-31">31</a></span>
<span class="normal"><a href="#__codelineno-86-32">32</a></span>
<span class="normal"><a href="#__codelineno-86-33">33</a></span>
<span class="normal"><a href="#__codelineno-86-34">34</a></span>
<span class="normal"><a href="#__codelineno-86-35">35</a></span>
<span class="normal"><a href="#__codelineno-86-36">36</a></span>
<span class="normal"><a href="#__codelineno-86-37">37</a></span>
<span class="normal"><a href="#__codelineno-86-38">38</a></span>
<span class="normal"><a href="#__codelineno-86-39">39</a></span>
<span class="normal"><a href="#__codelineno-86-40">40</a></span>
<span class="normal"><a href="#__codelineno-86-41">41</a></span>
<span class="normal"><a href="#__codelineno-86-42">42</a></span>
<span class="normal"><a href="#__codelineno-86-43">43</a></span>
<span class="normal"><a href="#__codelineno-86-44">44</a></span>
<span class="normal"><a href="#__codelineno-86-45">45</a></span>
<span class="normal"><a href="#__codelineno-86-46">46</a></span>
<span class="normal"><a href="#__codelineno-86-47">47</a></span>
<span class="normal"><a href="#__codelineno-86-48">48</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-86-1"><a id="__codelineno-86-1" name="__codelineno-86-1"></a><span class="cp">#define IN_TILE_DIM 32</span>
</span><span id="__span-86-2"><a id="__codelineno-86-2" name="__codelineno-86-2"></a><span class="cp">#define OUT_TILE_DIM ((IN_TILE_DIM) - 2*(FILTER_RADIUS))</span>
</span><span id="__span-86-3"><a id="__codelineno-86-3" name="__codelineno-86-3"></a>
</span><span id="__span-86-4"><a id="__codelineno-86-4" name="__codelineno-86-4"></a><span class="n">__constant__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">F_c</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">FILTER_RADIUS</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="o">*</span><span class="n">FILTER_RADIUS</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="o">*</span><span class="n">FILTER_RADIUS</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>
</span><span id="__span-86-5"><a id="__codelineno-86-5" name="__codelineno-86-5"></a>
</span><span id="__span-86-6"><a id="__codelineno-86-6" name="__codelineno-86-6"></a><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">convolution_tiled_3D_const_mem_kernel</span><span class="p">(</span>
</span><span id="__span-86-7"><a id="__codelineno-86-7" name="__codelineno-86-7"></a><span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">P</span><span class="p">,</span>
</span><span id="__span-86-8"><a id="__codelineno-86-8" name="__codelineno-86-8"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">depth</span><span class="p">)</span>
</span><span id="__span-86-9"><a id="__codelineno-86-9" name="__codelineno-86-9"></a><span class="p">{</span>
</span><span id="__span-86-10"><a id="__codelineno-86-10" name="__codelineno-86-10"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-86-11"><a id="__codelineno-86-11" name="__codelineno-86-11"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-86-12"><a id="__codelineno-86-12" name="__codelineno-86-12"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-86-13"><a id="__codelineno-86-13" name="__codelineno-86-13"></a>
</span><span id="__span-86-14"><a id="__codelineno-86-14" name="__codelineno-86-14"></a><span class="w">    </span><span class="c1">// Allocate 3D shared memory tile</span>
</span><span id="__span-86-15"><a id="__codelineno-86-15" name="__codelineno-86-15"></a><span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">N_s</span><span class="p">[</span><span class="n">IN_TILE_DIM</span><span class="p">][</span><span class="n">IN_TILE_DIM</span><span class="p">][</span><span class="n">IN_TILE_DIM</span><span class="p">];</span>
</span><span id="__span-86-16"><a id="__codelineno-86-16" name="__codelineno-86-16"></a>
</span><span id="__span-86-17"><a id="__codelineno-86-17" name="__codelineno-86-17"></a><span class="w">    </span><span class="c1">// Load input tile (including halo)</span>
</span><span id="__span-86-18"><a id="__codelineno-86-18" name="__codelineno-86-18"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">depth</span><span class="p">)</span>
</span><span id="__span-86-19"><a id="__codelineno-86-19" name="__codelineno-86-19"></a><span class="w">        </span><span class="n">N_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-86-20"><a id="__codelineno-86-20" name="__codelineno-86-20"></a><span class="w">            </span><span class="n">N</span><span class="p">[</span><span class="n">z</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">];</span>
</span><span id="__span-86-21"><a id="__codelineno-86-21" name="__codelineno-86-21"></a><span class="w">    </span><span class="k">else</span>
</span><span id="__span-86-22"><a id="__codelineno-86-22" name="__codelineno-86-22"></a><span class="w">        </span><span class="n">N_s</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-86-23"><a id="__codelineno-86-23" name="__codelineno-86-23"></a>
</span><span id="__span-86-24"><a id="__codelineno-86-24" name="__codelineno-86-24"></a><span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>
</span><span id="__span-86-25"><a id="__codelineno-86-25" name="__codelineno-86-25"></a>
</span><span id="__span-86-26"><a id="__codelineno-86-26" name="__codelineno-86-26"></a><span class="w">    </span><span class="c1">// Compute output tile indices</span>
</span><span id="__span-86-27"><a id="__codelineno-86-27" name="__codelineno-86-27"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tileX</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-86-28"><a id="__codelineno-86-28" name="__codelineno-86-28"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tileY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-86-29"><a id="__codelineno-86-29" name="__codelineno-86-29"></a><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tileZ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="p">;</span>
</span><span id="__span-86-30"><a id="__codelineno-86-30" name="__codelineno-86-30"></a>
</span><span id="__span-86-31"><a id="__codelineno-86-31" name="__codelineno-86-31"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">depth</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-86-32"><a id="__codelineno-86-32" name="__codelineno-86-32"></a><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tileX</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tileX</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">&amp;&amp;</span>
</span><span id="__span-86-33"><a id="__codelineno-86-33" name="__codelineno-86-33"></a><span class="w">            </span><span class="n">tileY</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tileY</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="w"> </span><span class="o">&amp;&amp;</span>
</span><span id="__span-86-34"><a id="__codelineno-86-34" name="__codelineno-86-34"></a><span class="w">            </span><span class="n">tileZ</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">tileZ</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">OUT_TILE_DIM</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-86-35"><a id="__codelineno-86-35" name="__codelineno-86-35"></a>
</span><span id="__span-86-36"><a id="__codelineno-86-36" name="__codelineno-86-36"></a><span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
</span><span id="__span-86-37"><a id="__codelineno-86-37" name="__codelineno-86-37"></a><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fz</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">fz</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">fz</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-86-38"><a id="__codelineno-86-38" name="__codelineno-86-38"></a><span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">fy</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">fy</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-86-39"><a id="__codelineno-86-39" name="__codelineno-86-39"></a><span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">fx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">fx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">FILTER_RADIUS</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">fx</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-86-40"><a id="__codelineno-86-40" name="__codelineno-86-40"></a><span class="w">                        </span><span class="n">Pvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">F_c</span><span class="p">[</span><span class="n">fz</span><span class="p">][</span><span class="n">fy</span><span class="p">][</span><span class="n">fx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span>
</span><span id="__span-86-41"><a id="__codelineno-86-41" name="__codelineno-86-41"></a><span class="w">                                  </span><span class="n">N_s</span><span class="p">[</span><span class="n">tileZ</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fz</span><span class="p">][</span><span class="n">tileY</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fy</span><span class="p">][</span><span class="n">tileX</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fx</span><span class="p">];</span>
</span><span id="__span-86-42"><a id="__codelineno-86-42" name="__codelineno-86-42"></a><span class="w">                    </span><span class="p">}</span>
</span><span id="__span-86-43"><a id="__codelineno-86-43" name="__codelineno-86-43"></a><span class="w">                </span><span class="p">}</span>
</span><span id="__span-86-44"><a id="__codelineno-86-44" name="__codelineno-86-44"></a><span class="w">            </span><span class="p">}</span>
</span><span id="__span-86-45"><a id="__codelineno-86-45" name="__codelineno-86-45"></a><span class="w">            </span><span class="n">P</span><span class="p">[</span><span class="n">z</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Pvalue</span><span class="p">;</span>
</span><span id="__span-86-46"><a id="__codelineno-86-46" name="__codelineno-86-46"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-86-47"><a id="__codelineno-86-47" name="__codelineno-86-47"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-86-48"><a id="__codelineno-86-48" name="__codelineno-86-48"></a><span class="p">}</span>
</span></code></pre></div></td></tr></table></div>
<p><img alt="image-20251006214521808" src="assets/image-20251006214521808.png" /></p>
<blockquote>
<p>For Strategy 3</p>
<p><strong>Output Tile Size</strong>: 16√ó16=256 pixels loaded into the shared memory tile</p>
<p><strong>Mask Size</strong>: 9√ó5=45 elements</p>
<p><strong>Total Computational Reads</strong>: 256√ó45=11,520</p>
<p>11,520(Total Reads)‚àí9,176(Shared Reads)=2,344 halo loads.</p>
<p><strong>9176 / 256</strong> represents the <strong>average reuse of data within the shared memory tile</strong></p>
<p><strong>11520/2600</strong> is the average reuse of <strong>total computational reads to total global memory loads</strong>.</p>
<hr />
<p>How to get 9176:</p>
<ol>
<li>Height Dimension Calculation (Filter Height = 9)</li>
</ol>
<p>We analyze how many times each of the <strong>16</strong> input rows in shared memory is accessed by the <strong>9-element</strong> tall filter. We can break the 16 rows into three regions.</p>
<ul>
<li><strong>Top Edge (Rows 0-3):</strong> These rows are too close to the edge to be used by the full height of the filter.<ul>
<li>Row 0 is used <strong>5</strong> times.</li>
<li>Row 1 is used <strong>6</strong> times.</li>
<li>Row 2 is used <strong>7</strong> times.</li>
<li>Row 3 is used <strong>8</strong> times.</li>
<li><em>Subtotal: 26</em></li>
</ul>
</li>
<li><strong>Middle (Rows 4-11):</strong> These 8 rows are far from the edges, so each one is fully used by the filter <strong>9</strong> times.<ul>
<li>8 rows√ó9 uses/row=72</li>
<li><em>Subtotal: 72</em></li>
</ul>
</li>
<li><strong>Bottom Edge (Rows 12-15):</strong> This is a mirror image of the top edge.<ul>
<li><em>Subtotal: 26</em></li>
</ul>
</li>
</ul>
<p>The total number of vertical accesses is 26+72+26=124.</p>
<ol start="2">
<li>Width Dimension Calculation (Filter Width = 5)</li>
</ol>
<p>Next, we do the same for the width. We analyze how many times each of the <strong>16</strong> input columns in shared memory is accessed by the <strong>5-element</strong> wide filter.</p>
<ul>
<li><strong>Left Edge (Columns 0-1):</strong><ul>
<li>Column 0 is used <strong>3</strong> times.</li>
<li>Column 1 is used <strong>4</strong> times.</li>
<li><em>Subtotal: 7</em></li>
</ul>
</li>
<li><strong>Middle (Columns 2-13):</strong> These 12 columns are each fully used by the filter <strong>5</strong> times.<ul>
<li>12 columns√ó5 uses/column=60</li>
<li><em>Subtotal: 60</em></li>
</ul>
</li>
<li><strong>Right Edge (Columns 14-15):</strong> This is a mirror image of the left edge.<ul>
<li><em>Subtotal: 7</em></li>
</ul>
</li>
</ul>
<p>The total number of horizontal accesses is 7+60+7=74.</p>
<p>Combining the Dimensions: To get the total number of reads from the 2D shared memory tile, we multiply the totals from the height and width calculations.</p>
<p>Total Shared Reads=(Total Vertical Accesses)√ó(Total Horizontal Accesses)</p>
<p>Total Shared Reads=124√ó74=9,176</p>
</blockquote>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="ÊúÄÂêéÊõ¥Êñ∞">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2026Âπ¥2Êúà20Êó• 01:15:29 CST">2026Âπ¥2Êúà20Êó• 01:15:29</span>
  </span>

    
    
    
    
  </aside>




<div id="__comments">
  
    <h2 ><!-- ËØÑËÆ∫ -->ËØÑËÆ∫Âå∫~</h2>
    
    ÊúâÁî®ÁöÑËØùËØ∑ÁªôÊàë‰∏™ËµûÂíå star => <a href="https://cindyzhou2003.github.io/mymkdocs/">
        <img alt="GitHub stars" src="https://img.shields.io/github/stars/CindyZhou2003/mymkdocs.svg?style=plastic&amp;label=Stars"></a>
    
    
    </div>
    <script src="https://giscus.app/client.js"
        data-repo="CindyZhou2003/mymkdocs"
        data-repo-id="R_kgDOJHRt5g"
        data-category="General"
        data-category-id="DIC_kwDOJHRt5s4Cge0r"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>

        updateScheme();

    </script>
    
    
    <!-- Synchronize Giscus theme with palette -->
    <script>
    var giscus = document.querySelector("script[src*=giscus]")
    
    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "dark" : "light"
        giscus.setAttribute("data-theme", theme) 
    }
    
    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function() {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
            var theme = palette.color.scheme === "slate" ? "dark" : "light"
            localStorage.setItem("data-md-color-scheme", palette.color.scheme === "slate" ? "slate" : "default");
            /* Instruct Giscus to change theme */
            var frame = document.querySelector(".giscus-frame")
            frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
            )
        }
        })
    })
    </script>
                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  ÂõûÂà∞È°µÈù¢È°∂ÈÉ®
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="È°µËÑö" >
        
          
          <a href="../ZJU/%E4%B9%A0%E6%A6%82.html" class="md-footer__link md-footer__link--prev" aria-label="‰∏ä‰∏ÄÈ°µ: ‰π†Ê¶Ç">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                ‰∏ä‰∏ÄÈ°µ
              </span>
              <div class="md-ellipsis">
                ‰π†Ê¶Ç
              </div>
            </div>
          </a>
        
        
          
          <a href="ECE448.html" class="md-footer__link md-footer__link--next" aria-label="‰∏ã‰∏ÄÈ°µ: ECE448/CS440 Artificial Intelligence">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                ‰∏ã‰∏ÄÈ°µ
              </span>
              <div class="md-ellipsis">
                ECE448/CS440 Artificial Intelligence
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024-2025 <a href="https://github.com/CindyZhou2003/mymkdocs"  target="_blank" rel="noopener">Cindy</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/CindyZhou2003/mymkdocs" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["content.code.annotate", "navigation.indexes", "navigation.expand", "toc.follow", "navigation.top", "search.suggest", "navigation.footer", "navigation.tabs", "navigation.tracking", "navigation.instant.progress", "content.code.copy", "search.highlight", "search.share", "content.code.annotate", "navigation.tabs"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
      
        <script src="../js/katex.js"></script>
      
        <script src="../js/tablesort.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>